"""add transcription and summary tables

Revision ID: efc32c8c8df9
Revises: a22c096070a4
Create Date: 2025-11-05 11:31:17.543889

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "efc32c8c8df9"
down_revision: Union[str, Sequence[str], None] = "a22c096070a4"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "transcriptions",
        sa.Column(
            "video_id", sa.UUID(), nullable=False, comment="Clave foránea al video transcrito"
        ),
        sa.Column("text", sa.Text(), nullable=False, comment="Texto completo de la transcripción"),
        sa.Column(
            "language",
            sa.String(length=10),
            nullable=False,
            comment="Código ISO 639-1 del idioma detectado",
        ),
        sa.Column(
            "model_used",
            sa.String(length=50),
            nullable=False,
            comment="Modelo Whisper usado ('whisper-base', 'whisper-small', etc.)",
        ),
        sa.Column(
            "duration_seconds",
            sa.Integer(),
            nullable=True,
            comment="Duración del audio transcrito en segundos",
        ),
        sa.Column(
            "segments",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
            comment="Segmentos con timestamps en formato JSON (opcional)",
        ),
        sa.Column(
            "confidence_score",
            sa.Float(),
            nullable=True,
            comment="Puntuación de confianza promedio (0.0-1.0)",
        ),
        sa.Column("id", sa.UUID(), nullable=False, comment="Clave primaria (UUID v4)"),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
            comment="Timestamp de cuándo se creó el registro",
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
            comment="Timestamp de cuándo se modificó por última vez",
        ),
        sa.ForeignKeyConstraint(["video_id"], ["videos.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("video_id"),
    )
    op.create_index("ix_transcriptions_language", "transcriptions", ["language"], unique=False)
    op.create_index("ix_transcriptions_video_id", "transcriptions", ["video_id"], unique=False)
    op.create_table(
        "summaries",
        sa.Column(
            "transcription_id",
            sa.UUID(),
            nullable=False,
            comment="Clave foránea a la transcripción resumida",
        ),
        sa.Column("summary_text", sa.Text(), nullable=False, comment="Texto del resumen generado"),
        sa.Column(
            "keywords",
            sa.ARRAY(sa.String(length=100)),
            nullable=True,
            comment="Lista de palabras clave extraídas del contenido",
        ),
        sa.Column(
            "category",
            sa.String(length=100),
            nullable=True,
            comment="Categoría del contenido ('framework', 'language', 'tool', 'concept')",
        ),
        sa.Column(
            "model_used",
            sa.String(length=50),
            nullable=False,
            comment="Modelo LLM usado para generar el resumen",
        ),
        sa.Column(
            "tokens_used",
            sa.Integer(),
            nullable=True,
            comment="Número total de tokens consumidos (input + output)",
        ),
        sa.Column(
            "input_tokens",
            sa.Integer(),
            nullable=True,
            comment="Tokens de la transcripción enviada",
        ),
        sa.Column(
            "output_tokens", sa.Integer(), nullable=True, comment="Tokens del resumen generado"
        ),
        sa.Column(
            "processing_time_ms",
            sa.Integer(),
            nullable=True,
            comment="Tiempo de procesamiento en milisegundos",
        ),
        sa.Column(
            "extra_metadata",
            postgresql.JSONB(astext_type=sa.Text()),
            nullable=True,
            comment="Metadata adicional del proceso de generación (temperatura, etc.)",
        ),
        sa.Column("id", sa.UUID(), nullable=False, comment="Clave primaria (UUID v4)"),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
            comment="Timestamp de cuándo se creó el registro",
        ),
        sa.Column(
            "updated_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
            comment="Timestamp de cuándo se modificó por última vez",
        ),
        sa.ForeignKeyConstraint(["transcription_id"], ["transcriptions.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("transcription_id"),
    )
    op.create_index("ix_summaries_category", "summaries", ["category"], unique=False)
    op.create_index(
        "ix_summaries_transcription_id", "summaries", ["transcription_id"], unique=False
    )
    # ### end Alembic commands ###
    # ==================== ÍNDICES AVANZADOS (manual) ====================

    # Habilitar extensión pg_trgm para full-text search con trigram
    op.execute("CREATE EXTENSION IF NOT EXISTS pg_trgm")

    # Índice GIN para búsqueda eficiente en array de keywords
    op.execute(
        """
        CREATE INDEX idx_summaries_keywords
        ON summaries USING gin(keywords)
    """
    )

    # Full-text search con trigram en transcripciones
    # Permite búsquedas tipo: "encuentra transcripciones con 'FastAPI'"
    op.execute(
        """
        CREATE INDEX idx_transcriptions_text_fts
        ON transcriptions USING gin(text gin_trgm_ops)
    """
    )

    # Full-text search con trigram en resúmenes
    op.execute(
        """
        CREATE INDEX idx_summaries_text_fts
        ON summaries USING gin(summary_text gin_trgm_ops)
    """
    )


def downgrade() -> None:
    """Downgrade schema."""
    # Eliminar índices avanzados primero (antes de las tablas)
    op.execute("DROP INDEX IF EXISTS idx_summaries_text_fts")
    op.execute("DROP INDEX IF EXISTS idx_transcriptions_text_fts")
    op.execute("DROP INDEX IF EXISTS idx_summaries_keywords")
    # NOTE: No eliminamos pg_trgm por si otras tablas la usan

    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index("ix_summaries_transcription_id", table_name="summaries")
    op.drop_index("ix_summaries_category", table_name="summaries")
    op.drop_table("summaries")
    op.drop_index("ix_transcriptions_video_id", table_name="transcriptions")
    op.drop_index("ix_transcriptions_language", table_name="transcriptions")
    op.drop_table("transcriptions")
    # ### end Alembic commands ###
