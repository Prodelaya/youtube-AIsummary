# Gu√≠a de Desarrollo: Sistema de M√©tricas Prometheus

**Proyecto:** youtube-AIsummary
**Paso:** 22 - Sistema de M√©tricas
**√öltima actualizaci√≥n:** 15/11/2025

---

## üìã Tabla de Contenidos

1. [Introducci√≥n](#introducci√≥n)
2. [Arquitectura del Sistema](#arquitectura-del-sistema)
3. [M√≥dulo Centralizado de M√©tricas](#m√≥dulo-centralizado-de-m√©tricas)
4. [Tipos de M√©tricas](#tipos-de-m√©tricas)
5. [Categor√≠as de M√©tricas](#categor√≠as-de-m√©tricas)
6. [C√≥mo A√±adir Nuevas M√©tricas](#c√≥mo-a√±adir-nuevas-m√©tricas)
7. [Mejores Pr√°cticas](#mejores-pr√°cticas)
8. [Troubleshooting](#troubleshooting)

---

## Introducci√≥n

Este proyecto implementa un sistema de **observabilidad** basado en Prometheus para monitorizar:

- Rendimiento de la API (FastAPI)
- Procesamiento de videos (pipeline completo)
- Tareas as√≠ncronas (Celery)
- Cache (Redis)
- Base de datos (PostgreSQL)
- Sistema operativo (CPU, RAM, disco)

### Beneficios

‚úÖ **Monitorizaci√≥n en tiempo real** de todos los componentes
‚úÖ **Detecci√≥n temprana** de cuellos de botella y errores
‚úÖ **An√°lisis hist√≥rico** con retenci√≥n de 15 d√≠as
‚úÖ **Alerting** (futuro) basado en m√©tricas cr√≠ticas
‚úÖ **Dashboards** visuales en Grafana

---

## Arquitectura del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI App   ‚îÇ
‚îÇ  (Puerto 8000)  ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ  /metrics       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  (texto plano)  ‚îÇ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                         ‚îÇ Scrape cada 15s
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  Prometheus     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  (Puerto 9090)  ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ  TSDB (15 d√≠as) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Queries (PromQL)
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Grafana      ‚îÇ
‚îÇ  (Puerto 3000)  ‚îÇ
‚îÇ                 ‚îÇ
‚îÇ   Dashboards    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos

1. **Aplicaci√≥n** genera m√©tricas usando `src/core/metrics.py`
2. **Prometheus** hace scraping de `/metrics` cada 15 segundos
3. **TSDB** almacena series temporales con retenci√≥n de 15 d√≠as
4. **Grafana** consulta Prometheus con PromQL y muestra dashboards

---

## M√≥dulo Centralizado de M√©tricas

**Ubicaci√≥n:** `src/core/metrics.py`

### ¬øPor Qu√© Centralizado?

‚ùå **Antes (Descentralizado):**
```python
# En cache_service.py
cache_hits = Counter("cache_hits_total", ...)

# En video_service.py
cache_hits = Counter("cache_hits_total", ...)  # ‚ö†Ô∏è DUPLICADO!
```

**Error:** `ValueError: Duplicated timeseries in CollectorRegistry`

‚úÖ **Ahora (Centralizado):**
```python
# src/core/metrics.py
class PrometheusMetrics:
    def __init__(self):
        self.cache_hits_total = Counter("cache_hits_total", ...)

# En cualquier m√≥dulo
from src.core.metrics import metrics
metrics.cache_hits_total.labels(cache_type="summary").inc()
```

### Patr√≥n Singleton

El m√≥dulo usa **Singleton** para garantizar una √∫nica instancia global:

```python
class PrometheusMetrics:
    _instance: Optional['PrometheusMetrics'] = None

    def __new__(cls, registry: Optional[CollectorRegistry] = None):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, registry: Optional[CollectorRegistry] = None):
        if self._initialized:
            return

        self._registry = registry or REGISTRY
        self._init_http_metrics()
        self._init_video_metrics()
        # ...
        self._initialized = True

# Instancia global
metrics = PrometheusMetrics()
```

**Ventajas:**
- ‚úÖ Una √∫nica definici√≥n de cada m√©trica
- ‚úÖ Compartida por toda la aplicaci√≥n
- ‚úÖ Testeable con registros customizados

---

## Tipos de M√©tricas

Prometheus soporta 4 tipos de m√©tricas. Cada una tiene un prop√≥sito espec√≠fico.

### 1. Counter (Contador)

**Definici√≥n:** Valor que **solo puede incrementar** (nunca decrece).

**Cu√°ndo usar:**
- N√∫mero total de requests HTTP
- N√∫mero total de videos procesados
- N√∫mero total de errores

**Ejemplo:**
```python
# Definici√≥n
self.http_requests_total = Counter(
    'http_requests_total',
    'Total de requests HTTP recibidos',
    ['method', 'endpoint', 'status'],
    registry=self._registry
)

# Uso
metrics.http_requests_total.labels(
    method="GET",
    endpoint="/api/videos",
    status="200"
).inc()  # Incrementa en 1

metrics.http_requests_total.labels(
    method="POST",
    endpoint="/api/videos",
    status="201"
).inc(5)  # Incrementa en 5
```

**Convenciones de nombres:**
- ‚úÖ Termina en `_total`: `http_requests_total`
- ‚úÖ Usa plural: `errors_total`, `requests_total`

### 2. Gauge (Indicador)

**Definici√≥n:** Valor que puede **subir y bajar**.

**Cu√°ndo usar:**
- CPU usage (%)
- Memoria RAM usada
- Tareas Celery en cola
- Conexiones activas

**Ejemplo:**
```python
# Definici√≥n
self.celery_queue_size = Gauge(
    'celery_queue_size',
    'N√∫mero de tareas pendientes en cola Celery',
    ['queue_name'],
    registry=self._registry
)

# Uso
metrics.celery_queue_size.labels(queue_name="video_processing").set(42)
metrics.celery_queue_size.labels(queue_name="video_processing").inc()   # +1
metrics.celery_queue_size.labels(queue_name="video_processing").dec(5)  # -5
```

**Convenciones de nombres:**
- ‚úÖ Sin sufijo especial: `celery_queue_size`, `memory_usage_bytes`
- ‚úÖ Usa unidades claras: `_bytes`, `_percent`

### 3. Histogram (Histograma)

**Definici√≥n:** Distribuye observaciones en **buckets predefinidos**.

**Cu√°ndo usar:**
- Latencias de requests HTTP
- Tiempos de procesamiento
- Tama√±os de archivos

**Ejemplo:**
```python
# Definici√≥n
self.http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'Duraci√≥n de requests HTTP',
    ['method', 'endpoint'],
    buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
    registry=self._registry
)

# Uso
import time
start = time.time()
# ... procesar request ...
duration = time.time() - start
metrics.http_request_duration_seconds.labels(
    method="GET",
    endpoint="/api/videos"
).observe(duration)
```

**M√©tricas generadas autom√°ticamente:**
```
http_request_duration_seconds_bucket{le="0.005"} 150
http_request_duration_seconds_bucket{le="0.01"} 200
http_request_duration_seconds_bucket{le="+Inf"} 250
http_request_duration_seconds_sum 12.34
http_request_duration_seconds_count 250
```

**Queries √∫tiles:**
```promql
# Percentil 95 de latencia
histogram_quantile(0.95, http_request_duration_seconds_bucket)

# Latencia promedio
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])
```

**Convenciones de nombres:**
- ‚úÖ Termina en unidad de medida: `_seconds`, `_bytes`

### 4. Summary (Resumen)

**Definici√≥n:** Similar a Histogram pero calcula **cuantiles en el cliente**.

**Cu√°ndo usar:**
- Cuando necesitas cuantiles precisos (p50, p90, p99)
- Cuando no conoces el rango de valores de antemano

**Ejemplo:**
```python
# Definici√≥n
self.cache_operation_duration_seconds = Summary(
    'cache_operation_duration_seconds',
    'Duraci√≥n de operaciones de cache',
    ['operation'],
    registry=self._registry
)

# Uso
import time
start = time.time()
# ... operaci√≥n de cache ...
duration = time.time() - start
metrics.cache_operation_duration_seconds.labels(
    operation="get"
).observe(duration)
```

**M√©tricas generadas autom√°ticamente:**
```
cache_operation_duration_seconds_sum{operation="get"} 45.67
cache_operation_duration_seconds_count{operation="get"} 1000
```

**Diferencias Histogram vs Summary:**

| Caracter√≠stica | Histogram | Summary |
|----------------|-----------|---------|
| C√°lculo de cuantiles | Servidor (Prometheus) | Cliente (Python) |
| Agregaci√≥n | ‚úÖ Posible | ‚ùå No posible |
| Precisi√≥n | Aproximada | Exacta |
| Overhead CPU | Bajo | Alto |
| **Recomendaci√≥n** | **Preferir** | Solo si necesitas cuantiles exactos |

---

## Categor√≠as de M√©tricas

El sistema tiene **8 categor√≠as** de m√©tricas:

### 1. HTTP Metrics (`_init_http_metrics`)

Monitoriza requests HTTP de FastAPI.

```python
# Counters
http_requests_total            # Total de requests
http_requests_failed_total     # Requests fallidos (4xx/5xx)

# Histograms
http_request_duration_seconds  # Latencia de requests
http_request_size_bytes        # Tama√±o de request body
http_response_size_bytes       # Tama√±o de response body
```

**Uso t√≠pico:**
```python
# Al inicio del request
start_time = time.time()

# Al final del request
duration = time.time() - start_time
metrics.http_request_duration_seconds.labels(
    method="POST",
    endpoint="/api/videos"
).observe(duration)

metrics.http_requests_total.labels(
    method="POST",
    endpoint="/api/videos",
    status="201"
).inc()
```

### 2. Video Processing Metrics (`_init_video_metrics`)

Monitoriza el pipeline de procesamiento de videos.

```python
# Counters
videos_processed_total         # Total de videos procesados
audio_downloads_total          # Descargas de audio
transcriptions_total           # Transcripciones
summaries_total                # Res√∫menes generados

# Histograms
video_processing_duration_seconds  # Duraci√≥n por fase
audio_file_size_bytes          # Tama√±o de archivos de audio
transcript_length_chars        # Longitud de transcripciones
summary_length_chars           # Longitud de res√∫menes

# Gauge
active_video_processing        # Videos proces√°ndose ahora
```

**Uso t√≠pico:**
```python
# Al inicio del procesamiento
metrics.active_video_processing.inc()
start_download = time.time()

# Despu√©s de descargar audio
download_duration = time.time() - start_download
metrics.video_processing_duration_seconds.labels(
    phase="download"
).observe(download_duration)

metrics.audio_downloads_total.labels(status="success").inc()

# Al finalizar
metrics.active_video_processing.dec()
metrics.videos_processed_total.labels(status="completed").inc()
```

### 3. Celery Metrics (`_init_celery_metrics`)

Monitoriza tareas as√≠ncronas de Celery.

```python
# Counters
celery_task_total              # Total de tareas ejecutadas
celery_task_retries_total      # Total de reintentos

# Histograms
celery_task_duration_seconds   # Duraci√≥n de tareas

# Gauges
celery_active_tasks            # Tareas ejecut√°ndose ahora
celery_queue_size              # Tareas pendientes en cola
```

**Uso t√≠pico:**
```python
# Al inicio de la tarea
start_time = time.time()
metrics.celery_active_tasks.labels(task_name="process_video").inc()

# Al finalizar con √©xito
duration = time.time() - start_time
metrics.celery_task_duration_seconds.labels(
    task_name="process_video"
).observe(duration)

metrics.celery_task_total.labels(
    task_name="process_video",
    status="success"
).inc()

metrics.celery_active_tasks.labels(task_name="process_video").dec()

# Al hacer retry
if self.request.retries > 0:
    metrics.celery_task_retries_total.labels(
        task_name="process_video"
    ).inc()
```

### 4. Cache Metrics (`_init_cache_metrics`)

Monitoriza operaciones de cache (Redis).

```python
# Counters
cache_hits_total               # Cache hits
cache_misses_total             # Cache misses

# Summaries
cache_operation_duration_seconds  # Duraci√≥n de ops de cache

# Gauge
cache_size_bytes               # Tama√±o del cache
```

**Uso t√≠pico:**
```python
# Cache hit
metrics.cache_hits_total.labels(cache_type="summary").inc()

# Cache miss
metrics.cache_misses_total.labels(cache_type="summary").inc()

# Actualizar tama√±o
metrics.cache_size_bytes.labels(cache_type="summary").set(1024 * 1024 * 50)
```

**Hit rate (en Prometheus):**
```promql
sum(rate(cache_hits_total[5m])) /
(sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])))
```

### 5. Database Metrics (`_init_database_metrics`)

Monitoriza operaciones de base de datos.

```python
# Counters
db_queries_total               # Total de queries
db_connection_errors_total     # Errores de conexi√≥n

# Histograms
db_query_duration_seconds      # Duraci√≥n de queries

# Gauge
db_connections_active          # Conexiones activas
```

### 6. API Errors Metrics (`_init_api_errors_metrics`)

Monitoriza errores de la API.

```python
# Counters
api_errors_total               # Total de errores por tipo
api_validation_errors_total    # Errores de validaci√≥n
```

**Uso t√≠pico:**
```python
try:
    # ... c√≥digo ...
except VideoNotFoundError:
    metrics.api_errors_total.labels(
        error_type="VideoNotFoundError",
        endpoint="/api/videos/{id}"
    ).inc()
    raise

except ValidationError:
    metrics.api_validation_errors_total.labels(
        field="youtube_url"
    ).inc()
    raise
```

### 7. External Services Metrics (`_init_external_services_metrics`)

Monitoriza llamadas a APIs externas.

```python
# Counters
external_api_requests_total    # Total de requests a APIs externas

# Histograms
external_api_duration_seconds  # Duraci√≥n de requests
```

**Uso t√≠pico:**
```python
start_time = time.time()
try:
    response = await openai_client.chat.completions.create(...)
    duration = time.time() - start_time

    metrics.external_api_duration_seconds.labels(
        service="openai",
        operation="chat_completion"
    ).observe(duration)

    metrics.external_api_requests_total.labels(
        service="openai",
        operation="chat_completion",
        status="success"
    ).inc()
except Exception:
    metrics.external_api_requests_total.labels(
        service="openai",
        operation="chat_completion",
        status="error"
    ).inc()
    raise
```

### 8. System Metrics (`_init_system_metrics`)

Monitoriza recursos del sistema.

```python
# Gauges
cpu_usage_percent              # Uso de CPU
memory_usage_bytes             # Memoria RAM usada
disk_usage_bytes               # Espacio en disco usado
```

**Nota:** Estas m√©tricas se obtienen t√≠picamente de **Node Exporter** (ver `prometheus-operations.md`).

---

## C√≥mo A√±adir Nuevas M√©tricas

### Paso 1: Identificar el Tipo de M√©trica

Preg√∫ntate:

1. **¬øEl valor solo puede crecer?** ‚Üí `Counter`
   - Ejemplo: Total de errores, requests procesados

2. **¬øEl valor puede subir y bajar?** ‚Üí `Gauge`
   - Ejemplo: Conexiones activas, memoria usada

3. **¬øNecesitas distribuci√≥n de valores?** ‚Üí `Histogram`
   - Ejemplo: Latencias, tama√±os de archivos

4. **¬øNecesitas cuantiles exactos?** ‚Üí `Summary` (raramente)
   - Preferir `Histogram` en la mayor√≠a de casos

### Paso 2: Definir la M√©trica en `src/core/metrics.py`

```python
class PrometheusMetrics:
    def _init_my_new_category_metrics(self):
        """M√©tricas para mi nueva categor√≠a."""

        # Counter
        self.my_events_total = Counter(
            'my_events_total',
            'Total de eventos de mi categor√≠a',
            ['event_type', 'status'],
            registry=self._registry
        )

        # Histogram
        self.my_operation_duration_seconds = Histogram(
            'my_operation_duration_seconds',
            'Duraci√≥n de operaciones de mi categor√≠a',
            ['operation_type'],
            buckets=(0.1, 0.5, 1.0, 5.0, 10.0, 30.0, 60.0),
            registry=self._registry
        )

        # Gauge
        self.my_active_items = Gauge(
            'my_active_items',
            'Items activos de mi categor√≠a',
            ['item_type'],
            registry=self._registry
        )

    def __init__(self, registry: Optional[CollectorRegistry] = None):
        # ...
        self._init_my_new_category_metrics()
        # ...
```

### Paso 3: Usar la M√©trica en el C√≥digo

```python
# En tu servicio
from src.core.metrics import metrics
import time

class MyService:
    async def process_item(self, item_type: str):
        # Incrementar gauge al inicio
        metrics.my_active_items.labels(item_type=item_type).inc()

        # Medir duraci√≥n
        start_time = time.time()

        try:
            # ... tu l√≥gica ...

            # √âxito
            metrics.my_events_total.labels(
                event_type="process",
                status="success"
            ).inc()

        except Exception as e:
            # Error
            metrics.my_events_total.labels(
                event_type="process",
                status="error"
            ).inc()
            raise

        finally:
            # Siempre registrar duraci√≥n y decrementar gauge
            duration = time.time() - start_time
            metrics.my_operation_duration_seconds.labels(
                operation_type="process"
            ).observe(duration)

            metrics.my_active_items.labels(item_type=item_type).dec()
```

### Paso 4: Crear Tests

```python
# En tests/core/test_metrics.py
class TestMyNewCategoryMetrics:
    def test_my_events_total_exists(self):
        assert hasattr(metrics, 'my_events_total')
        assert isinstance(metrics.my_events_total, Counter)

    def test_my_events_total_labels(self):
        # Verificar que acepta los labels correctos
        metrics.my_events_total.labels(
            event_type="process",
            status="success"
        ).inc()

        # No deber√≠a fallar

    def test_my_operation_duration_histogram(self):
        assert hasattr(metrics, 'my_operation_duration_seconds')
        assert isinstance(metrics.my_operation_duration_seconds, Histogram)

        # Observar un valor
        metrics.my_operation_duration_seconds.labels(
            operation_type="process"
        ).observe(1.5)
```

### Paso 5: Validar en Prometheus

1. Arrancar servicios: `docker-compose up -d`
2. Arrancar app: `poetry run uvicorn src.api.main:app --reload`
3. Acceder a `http://localhost:8000/metrics`
4. Buscar tus m√©tricas: `my_events_total`, `my_operation_duration_seconds`
5. Acceder a Prometheus: `http://localhost:9090`
6. Ejecutar query: `rate(my_events_total[5m])`

---

## Mejores Pr√°cticas

### 1. Nombres de M√©tricas

‚úÖ **Buenas pr√°cticas:**
```python
http_requests_total              # Plural + _total
video_processing_duration_seconds  # Unidad clara
cache_hits_total                 # Verbo + sustantivo
```

‚ùå **Malas pr√°cticas:**
```python
request                          # Singular
video_time                       # Unidad ambigua
hits                             # Contexto poco claro
```

**Convenciones:**
- Snake_case min√∫sculas
- Prefijo del dominio: `http_`, `celery_`, `db_`
- Sufijos est√°ndar: `_total`, `_seconds`, `_bytes`, `_percent`
- Nombres descriptivos y sin ambig√ºedad

### 2. Labels (Etiquetas)

‚úÖ **Buenas pr√°cticas:**
```python
# Baja cardinalidad
metrics.http_requests_total.labels(
    method="GET",           # ~10 valores posibles
    endpoint="/api/videos", # ~50 endpoints
    status="200"            # ~20 c√≥digos HTTP
).inc()
# Cardinalidad total: 10 √ó 50 √ó 20 = 10,000 series
```

‚ùå **Malas pr√°cticas:**
```python
# ‚ö†Ô∏è ALTA CARDINALIDAD - NUNCA HACER ESTO
metrics.http_requests_total.labels(
    user_id="123e4567-...",      # Millones de usuarios
    video_id="456f7890-...",     # Millones de videos
    timestamp="2025-11-15T10:30" # Infinitos valores
).inc()
# Cardinalidad total: ‚àû ‚Üí CRASH de Prometheus
```

**Reglas de oro:**
- M√°ximo **10,000 series** por m√©trica (idealmente < 1,000)
- Evitar IDs √∫nicos (user_id, video_id, request_id)
- Evitar timestamps o valores continuos
- Preferir **categor√≠as** en lugar de valores √∫nicos

**Tabla de cardinalidad aceptable:**

| Label | Valores t√≠picos | Cardinalidad | ‚úÖ/‚ùå |
|-------|-----------------|--------------|------|
| `method` | GET, POST, PUT, DELETE | ~10 | ‚úÖ |
| `status` | 200, 201, 400, 404, 500 | ~20 | ‚úÖ |
| `endpoint` | /api/videos, /api/summaries | ~50 | ‚úÖ |
| `error_type` | VideoNotFoundError, ... | ~30 | ‚úÖ |
| `user_id` | UUID √∫nico por usuario | 1,000,000+ | ‚ùå |
| `timestamp` | Valor continuo | ‚àû | ‚ùå |

### 3. Granularidad de M√©tricas

**No sobre-instrumentar:**

‚ùå **Demasiadas m√©tricas:**
```python
# Una m√©trica por cada funci√≥n
video_download_start_total
video_download_end_total
video_download_validate_total
video_download_cleanup_total
# ...50 m√©tricas m√°s
```

‚úÖ **M√©tricas consolidadas:**
```python
# Una m√©trica con labels
video_processing_duration_seconds{phase="download"}
video_processing_duration_seconds{phase="transcription"}
video_processing_duration_seconds{phase="summary"}
video_processing_duration_seconds{phase="total"}
```

**Regla del 80/20:**
- 20% de m√©tricas cubren 80% de necesidades
- Empezar con m√©tricas de alto nivel
- A√±adir detalle solo cuando se detecta un problema espec√≠fico

### 4. Documentaci√≥n de M√©tricas

**Siempre incluir docstring descriptivo:**

```python
self.http_request_duration_seconds = Histogram(
    'http_request_duration_seconds',
    'Duraci√≥n de requests HTTP desde que se recibe hasta que se env√≠a respuesta. '
    'Incluye tiempo de procesamiento, DB queries y llamadas externas. '
    'Labels: method (GET/POST/etc), endpoint (ruta de la API)',
    ['method', 'endpoint'],
    buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0),
    registry=self._registry
)
```

### 5. Gesti√≥n de Errores

**Siempre registrar m√©tricas en bloques `try/finally`:**

```python
start_time = time.time()
metrics.active_video_processing.inc()

try:
    # ... procesamiento ...
    metrics.videos_processed_total.labels(status="success").inc()
except Exception as e:
    metrics.videos_processed_total.labels(status="error").inc()
    metrics.api_errors_total.labels(
        error_type=type(e).__name__,
        endpoint="/api/videos"
    ).inc()
    raise
finally:
    # Siempre se ejecuta
    duration = time.time() - start_time
    metrics.video_processing_duration_seconds.labels(
        phase="total"
    ).observe(duration)
    metrics.active_video_processing.dec()
```

### 6. Buckets de Histogramas

**Adaptar buckets al rango esperado de valores:**

```python
# Para latencias de API (milisegundos a segundos)
buckets=(0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0)

# Para procesamiento de videos (segundos a minutos)
buckets=(1.0, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0, 600.0)

# Para tama√±os de archivos (KB a MB)
buckets=(1024, 10240, 102400, 1048576, 10485760, 104857600)
```

**Reglas:**
- Incluir valores t√≠picos (p50, p90, p99)
- Distribuci√≥n logar√≠tmica (√ó2, √ó5, √ó10)
- Siempre incluye `+Inf` (autom√°tico)

---

## Troubleshooting

### Problema 1: Error "Duplicated timeseries"

**Error:**
```
ValueError: Duplicated timeseries in CollectorRegistry: {'cache_hits_total', 'cache_hits_created'}
```

**Causa:**
Est√°s registrando la misma m√©trica dos veces en el mismo registry.

**Soluci√≥n:**
```python
# ‚ùå MAL: Crear m√©trica local
cache_hits = Counter("cache_hits_total", ...)

# ‚úÖ BIEN: Usar m√©trica centralizada
from src.core.metrics import metrics
metrics.cache_hits_total.labels(...).inc()
```

### Problema 2: M√©tricas no aparecen en `/metrics`

**Causas posibles:**

1. **No has importado `metrics`:**
   ```python
   # En src/api/main.py
   from src.core.metrics import metrics  # ‚Üê Importante
   ```

2. **No has registrado la m√©trica:**
   - Verifica que la m√©trica est√° en `src/core/metrics.py`
   - Verifica que el m√©todo `_init_*` est√° siendo llamado en `__init__`

3. **No has usado la m√©trica:**
   - Las m√©tricas solo aparecen despu√©s del primer uso
   - Ejemplo: `metrics.my_metric.labels(...).inc()` debe ejecutarse al menos una vez

**Debug:**
```bash
# Ver todas las m√©tricas disponibles
curl http://localhost:8000/metrics | grep "my_metric"

# Ver si la m√©trica est√° en el registry
python -c "from src.core.metrics import metrics; print(metrics.my_metric)"
```

### Problema 3: Prometheus no scrapea m√©tricas

**Causas posibles:**

1. **Servicio FastAPI no est√° corriendo:**
   ```bash
   curl http://localhost:8000/metrics
   # Debe retornar m√©tricas, no error de conexi√≥n
   ```

2. **Prometheus no puede alcanzar FastAPI:**
   ```yaml
   # En prometheus.yml, verificar target
   static_configs:
     - targets: ['host.docker.internal:8000']  # Linux/WSL
     # - targets: ['host.docker.internal:8000']  # macOS/Windows
   ```

3. **Verificar estado en Prometheus:**
   - Acceder a `http://localhost:9090/targets`
   - Verificar que `fastapi` tiene estado `UP`

**Soluci√≥n:**
```bash
# Verificar conectividad desde container de Prometheus
docker exec -it iamonitor_prometheus wget -O- http://host.docker.internal:8000/metrics
```

### Problema 4: Cardinalidad demasiado alta

**S√≠ntoma:**
Prometheus consume mucha RAM o se vuelve lento.

**Diagn√≥stico:**
```promql
# Ver m√©tricas con m√°s series
topk(10, count by (__name__)({__name__=~".+"}))
```

**Soluci√≥n:**
- Revisar labels con alta cardinalidad (IDs √∫nicos)
- Reemplazar IDs por categor√≠as
- Usar `relabel_config` en Prometheus para eliminar labels

### Problema 5: Tests fallan con "Duplicated timeseries"

**Causa:**
El singleton de `PrometheusMetrics` persiste entre tests.

**Soluci√≥n:**
```python
# En tests/core/test_metrics.py
import pytest
from prometheus_client import CollectorRegistry

@pytest.fixture(autouse=True)
def reset_metrics():
    """Reset metrics singleton antes de cada test."""
    from src.core.metrics import PrometheusMetrics
    PrometheusMetrics._instance = None
    yield
    PrometheusMetrics._instance = None
```

---

## Recursos Adicionales

- [Prometheus Best Practices](https://prometheus.io/docs/practices/naming/)
- [Prometheus Python Client](https://github.com/prometheus/client_python)
- [PromQL Cheat Sheet](prometheus-queries.md)
- [Gu√≠a de Operaciones](prometheus-operations.md)

---

**Siguiente:** [Queries PromQL √∫tiles](prometheus-queries.md)
