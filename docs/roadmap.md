# üó∫Ô∏è ROADMAP DETALLADO - IA MONITOR
**Versi√≥n:** 1.0
**Actualizado:** Octubre 2025
**Metodolog√≠a:** Incremental con validaci√≥n paso a paso

---

## üìñ √çNDICE
- Visi√≥n General
- Fase 0: Planning & Setup (1 d√≠a)
- Fase 1: Infraestructura Base (2-3 d√≠as)
- Fase 2: Pipeline Core (1 semana)
- Fase 3: API REST + Bot Telegram (5-6 d√≠as)
- Fase 4: Workers Async (2-3 d√≠as)
- Fase 5: Observabilidad (2 d√≠as)
- Fase 6: Testing & CI (2 d√≠as)
- Fase 7: Deployment (2-3 d√≠as)
- Timeline Semanal
---

## üéØ VISI√ìN GENERAL

### Objetivo del Proyecto
Crear un agregador inteligente con bot de Telegram multi-usuario que autom√°ticamente:
- Recopila contenidos sobre IA en desarrollo software (YouTube, RSS, podcasts)
- Transcribe audios usando Whisper (local, gratuito)
- Resume textos usando DeepSeek API (bajo coste, sin l√≠mites)
- Distribuye res√∫menes personalizados v√≠a Bot de Telegram interactivo
- Cada usuario elige sus canales y gestiona su historial

### Doble Prop√≥sito
- **Utilidad real:** Bot multi-usuario donde cada persona elige sus canales de inter√©s
- **Portfolio profesional:** Demostrar backend Python moderno con IA funcional y arquitectura multi-usuario

### Stack Tecnol√≥gico
- **Backend:** FastAPI (sync endpoints) + PostgreSQL + Redis
- **Workers:** Celery para tareas en background (scraping, transcripci√≥n, distribuci√≥n)
- **Bot:** python-telegram-bot con inline keyboards y commands interactivos
- **IA:** Whisper (transcripci√≥n local) + DeepSeek API (res√∫menes)
- **DevOps:** Docker, GitHub Actions, Prometheus + Grafana

---

## üìã FASE 0: PLANNING & SETUP (1 d√≠a)

### Paso 1: Documento de Arquitectura (Project Designer)
**¬øQu√© hacer?**
- Crear `docs/architecture.md` usando el prompt Project Designer
- Decisiones t√©cnicas justificadas (Whisper local vs APIs de pago, DeepSeek vs ApyHub/LangChain - ADR-009, Celery vs BackgroundTasks)
- Diagrama Mermaid de arquitectura completa (componentes + flujos)
- Estructura de directorios definitiva
- Roadmap de features priorizadas por fases

**¬øPor qu√© primero?**
- Define QU√â construir y C√ìMO antes de escribir una l√≠nea de c√≥digo
- Evita refactors masivos posteriores (ej: cambiar de MongoDB a PostgreSQL en semana 3)
- Justifica decisiones t√©cnicas ante reclutadores (portfolio = arquitectura pensada)
- Detecta dependencias cr√≠ticas temprano (ej: limitaciones de APIs externas que motivaron migraci√≥n a DeepSeek)

**Entregable:**
- `docs/architecture.md` completo con diagramas
- Stack t√©cnico con tabla de pros/contras
- Flujos de procesamiento documentados

**Git:**
```bash
git commit -m "docs: add initial architecture document with diagrams"
```
**Nos da paso a:** Crear estructura del repositorio basada en arquitectura definida.

---

### Paso 2: Estructura del Repositorio
**¬øQu√© hacer?**
- Crear carpetas seg√∫n arquitectura: `src/api/`, `src/services/`, `src/models/`, `src/repositories/`, `src/tasks/`, `tests/`
- Inicializar Git con `.gitignore` (Python, Docker, secretos)
- README b√°sico con descripci√≥n, badges placeholders (CI, coverage)
- `.env.example` con template de variables (sin valores reales)
- `docs/ADR/` para Architecture Decision Records

**¬øPor qu√© esta estructura?**
- Separaci√≥n clara: API / Servicios / Datos (Clean Architecture)
- Tests desde d√≠a 1 = cultura de calidad
- `.env.example` documenta qu√© variables necesita el proyecto
- ADRs justifican decisiones importantes (por qu√© Whisper local, no Deepgram API)

**Entregable:**
- Carpetas vac√≠as pero con `__init__.py`
- README con descripci√≥n del proyecto
- `.gitignore` configurado

**Git:**
```bash
git init
git add .
git commit -m "chore: initial project structure with Clean Architecture"
git remote add origin <tu-repo>
git push -u origin main
```
**Nos da paso a:** Configurar gestor de dependencias reproducible.

---

### Paso 3: Poetry Setup + Dependencias Base
**¬øQu√© hacer?**
- Inicializar Poetry con `poetry init`
- Instalar dependencias core: FastAPI, SQLAlchemy, Alembic, PostgreSQL driver, Redis, Celery
- Instalar dependencias IA: Whisper, yt-dlp (descarga YouTube), httpx (cliente HTTP async)
- Dev dependencies: pytest, black, ruff, mypy, pytest-cov

**¬øPor qu√© ahora?**
- Dependencias fijadas en `poetry.lock` = reproducible en cualquier m√°quina
- Instalar todo de golpe evita conflictos de versiones despu√©s
- Poetry gestiona entornos virtuales autom√°ticamente

**Entregable:**
- `pyproject.toml` con todas las dependencias
- `poetry.lock` generado

**Git:**
```bash
git add pyproject.toml poetry.lock
git commit -m "chore: add Poetry dependencies for FastAPI, Whisper, and testing"
```
**Nos da paso a:** Levantar infraestructura local (BD + cache).

---

## üèóÔ∏è FASE 1: INFRAESTRUCTURA BASE (2-3 d√≠as)

### Paso 4: Docker Compose (Postgres + Redis)
**¬øQu√© hacer?**
- Crear `docker-compose.yml` con servicios: Postgres 15, Redis 7
- Configurar vol√∫menes para persistencia de datos
- Puertos expuestos: Postgres 5432, Redis 6379
- Variables de entorno para usuario/password de BD

**¬øPor qu√© Docker?**
- BD lista en 1 comando (`docker-compose up -d`)
- Mismo entorno en dev/staging/prod (no "funciona en mi m√°quina")
- No contamina sistema local (se borra f√°cilmente)

**Validaci√≥n:**
- `docker-compose up -d` arranca sin errores
- Conexi√≥n a Postgres exitosa con `psql`
- Redis responde a `redis-cli ping` con `PONG`

**Git:**
```bash
git commit -m "feat: add Docker Compose with Postgres and Redis"
```
**Nos da paso a:** Configurar variables de entorno de la aplicaci√≥n.

---

### Paso 5: Config + Variables de Entorno
**¬øQu√© hacer?**
- Crear `src/core/config.py` usando Pydantic Settings
- Validar variables obligatorias: `DATABASE_URL`, `REDIS_URL`, `DEEPSEEK_API_KEY`
- `.env.example` con plantilla (este S√ç va a Git)
- `.env` real (este NO va a Git, usuario debe crearlo copiando el example)

**¬øPor qu√© Pydantic Settings?**
- Validaci√≥n autom√°tica al arrancar (si falta variable, app no inicia)
- Tipado fuerte (no strings m√°gicos)
- 12-factor app compliant (configuraci√≥n fuera del c√≥digo)

**Validaci√≥n:**
- App falla si `.env` no existe (comportamiento esperado)
- App arranca correctamente con `.env` v√°lido

**Git:**
```bash
git add src/core/config.py .env.example
git commit -m "feat: add configuration management with Pydantic Settings"
```
**Nos da paso a:** Crear API base funcional.

---

### Paso 6: FastAPI Base + Health Check
**¬øQu√© hacer?**
- Crear `src/api/main.py` con aplicaci√≥n FastAPI m√≠nima
- Endpoint `/health` que devuelve `{"status": "ok"}`
- Endpoint `/` que devuelve mensaje de bienvenida
- Configurar documentaci√≥n autom√°tica en `/api/docs`

**¬øPor qu√© health check?**
- Valida que FastAPI funciona correctamente
- Necesario para monitoreo futuro (Prometheus, Kubernetes probes)
- Primera victoria r√°pida (motivaci√≥n para continuar)

**Validaci√≥n:**
- `uvicorn src.api.main:app` arranca sin errores
- `curl localhost:8000/health` responde 200 OK
- Swagger UI accesible en `localhost:8000/api/docs`

**Test:**
- Crear `tests/test_health.py` con test del endpoint health
- `pytest tests/test_health.py -v` debe pasar

**Git:**
```bash
git commit -m "feat: add FastAPI base with health endpoint"
git commit -m "test: add health endpoint test"
```
**Nos da paso a:** Configurar ORM y sistema de migraciones.

---

### Paso 7: ORM + Migraciones (Alembic)
**¬øQu√© hacer?**
- Configurar SQLAlchemy `engine` y `sessionmaker` en `src/core/database.py`
- Inicializar Alembic con `alembic init migrations`
- Configurar `alembic.ini` para usar `DATABASE_URL` desde `.env`
- Crear primer modelo: `Source` (tabla de fuentes: YouTube channels, RSS feeds)
- Generar migraci√≥n autom√°tica: `alembic revision --autogenerate`
- Aplicar migraci√≥n: `alembic upgrade head`

**¬øPor qu√© migraciones?**
- Schema de BD versionado (como Git pero para la base de datos)
- Rollback posible si algo falla (`alembic downgrade`)
- Colaboraci√≥n sin romper datos de otros desarrolladores
- Historial de cambios en schema documentado

**Validaci√≥n:**
- Tabla `sources` existe en Postgres
- Tabla `alembic_version` registra la migraci√≥n
- `alembic current` muestra versi√≥n actual

**Git:**
```bash
git commit -m "feat: add SQLAlchemy ORM setup"
git commit -m "feat: add Alembic migrations"
git commit -m "feat: add Source model with first migration"
```
**Nos da paso a:** Implementar servicios core del pipeline.

---

## üß© FASE 2: PIPELINE CORE (1 semana)

### Paso 8: Integraci√≥n DeepSeek (Res√∫menes)
**¬øQu√© hacer?**
- Crear `src/services/summarization_service.py`
- Implementar m√©todo `summarize_text()` que llama a DeepSeek API
- Usar SDK de OpenAI (compatible con DeepSeek)
- Implementar sistema de prompts en `src/services/prompts/`
- Manejo de errores: timeout, respuestas inv√°lidas

**¬øPor qu√© primero?**
- Es el componente externo cr√≠tico del sistema
- Si DeepSeek est√° ca√≠do o cambia API, mejor descubrirlo YA
- Lo m√°s r√°pido de validar (no requiere BD ni otros servicios)
- API s√≠ncrona simple (SDK compatible con OpenAI)

**Validaci√≥n:**
- Test de integraci√≥n que llama a API real con texto de prueba
- Resumen generado correctamente en espa√±ol
- Sistema de prompts funciona correctamente

**Git:**
```bash
git commit -m "feat: add DeepSeek summarization service with OpenAI SDK"
git commit -m "feat: add prompt engineering system"
git commit -m "test: add DeepSeek integration test"
```
**Nos da paso a:** Implementar descarga de audios.

---

### Paso 9: Descarga de Audio (yt-dlp)
**¬øQu√© hacer?**
- Crear `src/services/downloader_service.py`
- Implementar `download_audio()` que descarga audio de YouTube en MP3
- Implementar `get_video_metadata()` para obtener info sin descargar
- Configurar carpeta temporal `/tmp/ia-monitor/downloads`
- Extraer mejor calidad de audio disponible

**¬øPor qu√© despu√©s de DeepSeek?**
- No depende de DeepSeek (servicios aislados)
- Genera archivos que el siguiente paso (transcripci√≥n) consumir√°

**Validaci√≥n:**
- Descargar video test de 30 segundos funciona
- Archivo MP3 generado existe y pesa >10KB
- Metadata extra√≠da correctamente (t√≠tulo, duraci√≥n, autor)

**Git:**
```bash
git commit -m "feat: add YouTube audio downloader with yt-dlp"
git commit -m "test: add downloader service test with sample video"
```
**Nos da paso a:** Implementar transcripci√≥n local.

---

### Paso 10: Transcripci√≥n (Whisper Local)
**¬øQu√© hacer?**
- Crear `src/services/transcription_service.py`
- Cargar modelo Whisper (usar **base** para balance velocidad/precisi√≥n)
- Implementar `transcribe_audio()` que convierte MP3 a texto
- Soportar idioma espa√±ol por defecto, configurable
- Implementar variante con **timestamps** (para features futuras)

**¬øPor qu√© Whisper local?**
- Gratuito (vs Deepgram $0.006/min que escala r√°pido)
- Privacidad (audio no sale del servidor)
- Portfolio impresionante (demuestra manejo de modelos ML reales)
- Sin l√≠mites (procesar 1000 videos no cuesta nada)

**Validaci√≥n:**
- Primera ejecuci√≥n descarga modelo (2-3 min, normal)
- Transcripci√≥n de audio de 30s tarda <1 minuto
- Texto generado tiene sentido y est√° en espa√±ol

**Git:**
```bash
git commit -m "feat: add Whisper transcription service"
git commit -m "test: add transcription test with sample audio"
```
**Nos da paso a:** Conectar todos los servicios en un pipeline.

---

### Paso 11: Modelos de BD Completos (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Crear modelo `Transcription` con relaci√≥n 1:1 a Video
- Crear modelo `Summary` con relaci√≥n 1:1 a Transcription
- Crear modelo `TelegramUser` con relaci√≥n M:N a Source
- Generar y aplicar migraciones Alembic
- Actualizar `Video` model con relaci√≥n a `Transcription`

**Estado:**
- ‚úÖ Modelos creados con tipado completo: Source, Video, Transcription, Summary, TelegramUser
- ‚úÖ Relaciones definidas (Video ‚Üí Transcription ‚Üí Summary)
- ‚úÖ Tabla intermedia `user_source_subscriptions` para suscripciones
- ‚úÖ Migraci√≥n aplicada con √≠ndices GIN y full-text search
- ‚úÖ Campos de tracking en Summary para Telegram
- ‚úÖ Exports actualizados en `__init__.py`

**Git:**
```bash
# Ya commiteado:
feat(models): add Transcription and Summary models
feat(models): add TelegramUser model with M:N subscriptions
feat(db): add migration for all tables with relationships
```
**Nos da paso a:** Implementar Repository Pattern.

---

### Paso 12: Repository Pattern (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Crear `src/repositories/base_repository.py` gen√©rico con TypeVar[T]
- Implementar CRUD s√≠ncrono: `create`, `get_by_id`, `list_all`, `update`, `delete`
- Crear `SourceRepository` con m√©todos espec√≠ficos
- Crear `VideoRepository` con queries por estado
- Crear `TranscriptionRepository` con b√∫squeda por video
- Crear `SummaryRepository` con filtros y b√∫squeda full-text
- Crear `TelegramUserRepository` con queries de suscripciones

**¬øPor qu√© s√≠ncronos?** (ADR-011)
- Celery workers son 99% del uso de BD (s√≠ncronos por dise√±o)
- API REST: <10 req/d√≠a (uso ocasional)
- Implementaci√≥n m√°s simple (2 d√≠as vs 4 d√≠as async)
- SQLAlchemy ORM funciona mejor en modo sync

**Estado:**
- ‚úÖ BaseRepository gen√©rico con TypeVar[T]
- ‚úÖ 5 repositories especializados implementados
- ‚úÖ M√©todos de b√∫squeda avanzada (full-text, filtros, paginaci√≥n)
- ‚úÖ Exception handling personalizado

**Git:**
```bash
# Ya commiteado:
feat(repositories): add BaseRepository with generic CRUD
feat(repositories): add SourceRepository and VideoRepository
feat(repositories): add TranscriptionRepository and SummaryRepository
feat(repositories): add TelegramUserRepository
```
**Nos da paso a:** Servicios de negocio y API REST.

---

### Paso 13: Servicios de Negocio (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Implementar `VideoProcessingService` como orquestador del pipeline
- Integrar descarga, transcripci√≥n y resumen en flujo unificado
- Manejo de errores con excepciones personalizadas
- Tracking de estado de procesamiento

**Estado:**
- ‚úÖ `DownloaderService` - descarga de audio con yt-dlp
- ‚úÖ `TranscriptionService` - transcripci√≥n con Whisper
- ‚úÖ `SummarizationService` - res√∫menes con DeepSeek API
- ‚úÖ `VideoProcessingService` - orquestador del pipeline completo

**Git:**
```bash
# Ya commiteado:
feat(services): add video processing orchestrator
feat(services): integrate downloader, transcription and summarization
```
**Nos da paso a:** Implementar API REST completa.

---

## üåê FASE 3: API REST + BOT TELEGRAM MULTI-USUARIO (5-6 d√≠as)

### Paso 14: API REST Completa (‚úÖ COMPLETADO)
**Contexto:** Backend completo con 18 endpoints para gesti√≥n de videos, transcripciones, res√∫menes y estad√≠sticas.

**¬øQu√© hacer?**
- Crear schemas Pydantic v2 en `src/api/schemas/`
- Implementar `src/api/routes/videos.py` (10 endpoints):
  - CRUD completo de videos
  - Procesamiento as√≠ncrono (encolar, reintentar)
  - Estad√≠sticas por video
- Implementar `src/api/routes/transcriptions.py` (2 endpoints):
  - Listado paginado
  - Detalle de transcripci√≥n
- Implementar `src/api/routes/summaries.py` (4 endpoints):
  - Listado paginado con cursor
  - Detalle de resumen
  - B√∫squeda full-text con ranking
  - Soft delete
- Implementar `src/api/routes/stats.py` (2 endpoints):
  - Estad√≠sticas globales del sistema
  - Estad√≠sticas por fuente
- Configurar dependency injection para repos
- Exception handlers globales
- Metadata OpenAPI enriquecida

**Estado:**
- ‚úÖ **18 endpoints implementados y documentados**
- ‚úÖ Schemas Pydantic v2 con validaci√≥n
- ‚úÖ Paginaci√≥n cursor-based
- ‚úÖ Exception handlers globales
- ‚úÖ OpenAPI docs con ejemplos y descripciones
- ‚úÖ Dependency injection para repositories

**Git:**
```bash
# Ya commiteado:
feat(api): add videos endpoints with CRUD and processing
feat(api): add transcriptions endpoints
feat(api): add summaries endpoints with full-text search
feat(api): add stats endpoints
test(api): add comprehensive API test suite
```
**Nos da paso a:** Implementar Bot de Telegram multi-usuario.

---

### Paso 15: Bot de Telegram - Setup B√°sico (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Instalar `python-telegram-bot` con Poetry
- Crear `src/bot/telegram_bot.py` con configuraci√≥n b√°sica
- Implementar command `/start` con mensaje de bienvenida
- Implementar command `/help` con lista de comandos
- Registrar usuario autom√°ticamente en `/start` (v√≠a TelegramUserRepository)
- Configurar webhook o polling seg√∫n entorno

**¬øPor qu√© primero?**
- Valida que bot funciona antes de a√±adir complejidad
- Configura infraestructura b√°sica (token, permisos)
- Primera interacci√≥n con usuarios

**Estado:**
- ‚úÖ `python-telegram-bot v22.5` instalado
- ‚úÖ Bot principal configurado en modo polling
- ‚úÖ Handler `/start` con registro autom√°tico de usuarios
- ‚úÖ Handler `/help` con lista de comandos
- ‚úÖ Error handler global con logging estructurado
- ‚úÖ 6 tests unitarios (todos pasan)
- ‚úÖ Bot validado en Telegram (@yt_IAinformer_bot)

**Archivos creados:**
- `src/bot/__init__.py`
- `src/bot/telegram_bot.py` (154 l√≠neas)
- `src/bot/handlers/start.py` (136 l√≠neas)
- `src/bot/handlers/help.py` (49 l√≠neas)
- `tests/bot/conftest.py` (127 l√≠neas)
- `tests/bot/test_handlers.py` (6 tests)

**Decisiones t√©cnicas:**
- Uso de `asyncio.to_thread()` para bridge async/sync (handlers ‚Üí repositories)
- Polling mode para desarrollo, infraestructura lista para webhook
- Registro idempotente de usuarios (ejecutar `/start` 2 veces no duplica)

**Git:**
```bash
git commit -m "feat(bot): add telegram bot basic setup with polling mode"
git commit -m "feat(bot): add /start handler with automatic user registration"
git commit -m "feat(bot): add /help handler with command list"
git commit -m "test(bot): add comprehensive handler tests (6 tests)"
git commit -m "chore: add python-telegram-bot dependency"
```
**Nos da paso a:** Commands interactivos de suscripciones.

---

### Paso 16: Bot de Telegram - Suscripciones Interactivas (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Implementar command `/sources` con inline keyboard
- Mostrar lista de canales con botones ‚úÖ/‚ùå (suscrito/no suscrito)
- Implementar callback_query handler para toggle de suscripciones
- Actualizar teclado din√°micamente tras cada toggle
- Consumir API interna para obtener sources y gestionar suscripciones

**¬øPor qu√© inline keyboards?**
- UX superior (botones vs escribir comandos)
- Feedback visual inmediato (‚úÖ/‚ùå)
- Reduce errores del usuario (no tipear nombres de canales)

**Estado:**
- ‚úÖ Handler `/sources` con inline keyboard implementado
- ‚úÖ Callback handler `toggle_subscription_callback` funcional
- ‚úÖ Toggle idempotente con manejo de race conditions
- ‚úÖ Actualizaci√≥n din√°mica de texto y botones (contador + emojis)
- ‚úÖ Integrado en telegram_bot.py con CallbackQueryHandler
- ‚úÖ Tests comprehensivos (test_sources_handler.py)

**Archivos creados:**
- `src/bot/handlers/sources.py` (348 l√≠neas)
- `tests/bot/test_sources_handler.py`

**Git:**
```bash
git commit -m "feat(bot): add interactive /sources subscription management"
```
**Nos da paso a:** Commands de consulta de hist√≥rico.

---

### Paso 17: Bot de Telegram - Historial y B√∫squeda
**¬øQu√© hacer?**
- Implementar command `/recent` ‚Äî √öltimos 10 res√∫menes de canales suscritos
- Implementar command `/search <query>` ‚Äî Buscar en hist√≥rico por keyword
- Formatear mensajes con:
  - üìπ T√≠tulo del video
  - üîó Link de YouTube
  - ‚è±Ô∏è Duraci√≥n
  - üè∑Ô∏è Tags (#FastAPI #Python)
  - üìù Resumen
- A√±adir bot√≥n inline "Reenviar" por resumen
- Consumir API interna para queries filtradas

**¬øPor qu√© estos commands?**
- `/recent` = acceso r√°pido a √∫ltimas novedades
- `/search` = recuperar informaci√≥n antigua f√°cilmente
- Formato enriquecido = mensajes √∫tiles y visualmente claros

**Validaci√≥n:**
- `/recent` muestra s√≥lo res√∫menes de canales suscritos
- `/search FastAPI` encuentra res√∫menes relevantes
- Links de YouTube funcionan correctamente
- Bot√≥n "Reenviar" reenvia el mensaje

**Git:**
```bash
git commit -m "feat(bot): add /recent command with formatted messages"
git commit -m "feat(bot): add /search command with keyword filtering"
git commit -m "test(bot): add history and search tests"
```
**Nos da paso a:** Worker de distribuci√≥n personalizada.

---

### Paso 18: Worker de Distribuci√≥n Personalizada (ADR-010)
**¬øQu√© hacer?**
- Crear `src/tasks/distribute_summaries.py`
- Implementar tarea Celery `distribute_summary(summary_id: str)`
- L√≥gica:
  1. Obtener resumen de BD
  2. Consultar usuarios suscritos al canal (M:N query)
  3. Para cada usuario suscrito:
     - Formatear mensaje con üìπ t√≠tulo, üîó link, üìù resumen
     - Enviar v√≠a Bot API
     - Registrar `telegram_message_id` en BD
  4. Actualizar `summary.sent_to_telegram = True`
- Manejo de errores: reintentar si falla env√≠o

**¬øPor qu√© worker separado?**
- Env√≠o a N usuarios puede tardar (rate limits de Telegram)
- No bloquea pipeline de transcripci√≥n/resumen
- Reintentos autom√°ticos si usuario tiene bot bloqueado

**Validaci√≥n:**
- Resumen generado se env√≠a solo a usuarios suscritos al canal
- Campo `telegram_message_ids` se actualiza correctamente
- Bot no env√≠a duplicados

**Git:**
```bash
git commit -m "feat(worker): add personalized distribution to Telegram users"
git commit -m "test(worker): add distribution tests with mock users"
```
**Nos da paso a:** Sistema de rate limiting para API de res√∫menes.

---

## ‚ö° FASE 4: WORKERS ASYNC (2-3 d√≠as)

### Paso 19: Celery Setup
**¬øQu√© hacer?**
- Configurar Celery en `src/core/celery_app.py` con Redis como broker
- Crear tarea `src/tasks/process_content_task.py` que ejecuta el pipeline completo
- Configurar Celery Beat para tareas programadas (scraping peri√≥dico de fuentes)
- Script de inicio de worker: `celery -A src.core.celery_app worker`

**¬øPor qu√© Celery?**
- Procesamiento async = API responde inmediato, trabajo en background
- Transcripci√≥n de 1 video tarda 5-10 min (no puede bloquear endpoint HTTP)
- Reintentos autom√°ticos si falla
- Escalable (m√∫ltiples workers en paralelo)

**Validaci√≥n:**
- Worker arranca sin errores
- Tarea encolada se ejecuta correctamente
- Logs muestran progreso del procesamiento

**Git:**
```bash
git commit -m "feat: add Celery configuration with Redis broker"
git commit -m "feat: add process_content async task"
```
**Nos da paso a:** Automatizar procesamiento peri√≥dico.

---

### Paso 20: Jobs Programados (Celery Beat)
**¬øQu√© hacer?**
- Configurar Celery Beat scheduler
- Crear tarea `sync_sources_task.py` que:
  - Consulta fuentes activas en BD
  - Busca nuevos contenidos (√∫ltimos videos de canal YouTube, nuevos posts de RSS)
  - Encola procesamiento de contenidos nuevos
- Programar ejecuci√≥n: cada 6 horas

**¬øPor qu√© automatizaci√≥n?**
- Sistema aut√≥nomo = sin intervenci√≥n manual
- Mantiene res√∫menes actualizados autom√°ticamente
- Demuestra orquestaci√≥n de workers (punto fuerte en portfolio)

**Validaci√≥n:**
- Beat scheduler arranca y programa tareas
- Tarea se ejecuta en horario configurado
- Nuevos contenidos detectados y procesados

**Git:**
```bash
git commit -m "feat: add Celery Beat for scheduled tasks"
git commit -m "feat: add sync_sources periodic task"
```
**Nos da paso a:** Implementar monitoreo y observabilidad.

---

## üìä FASE 5: OBSERVABILIDAD (2 d√≠as)

### Paso 21: Logging Estructurado
**¬øQu√© hacer?**
- Configurar **structlog** para logs estructurados
- Logs en formato JSON con campos: timestamp, level, message, context
- Diferentes niveles por entorno: DEBUG en dev, INFO en prod
- Logs de cada servicio identificados claramente
- Rotar logs diariamente, mantener √∫ltimos 7 d√≠as

**¬øPor qu√© logging estructurado?**
- Debuggear producci√≥n sin logs = adivinar
- JSON logs = f√°cil de parsear con herramientas (Loki, ELK)
- Context enriquecido (source_id, duration, etc.) ayuda a troubleshooting

**Validaci√≥n:**
- Logs generados en formato JSON v√°lido
- Diferentes servicios loggean correctamente
- Rotaci√≥n funciona (archivos por d√≠a)

**Git:**
```bash
git commit -m "feat: add structured logging with structlog"
```
**Nos da paso a:** Agregar m√©tricas para monitoreo.

---

### Paso 22: M√©tricas (Prometheus)
**¬øQu√© hacer?**
- Instalar `prometheus-client` para Python
- Exponer endpoint `/metrics` en FastAPI
- M√©tricas custom:
  - `summaries_generated_total` (contador)
  - `transcription_duration_seconds` (histograma)
  - `deepseek_api_calls_total` (contador)
  - `pipeline_errors_total` (contador por tipo)
- Configurar scraping de Prometheus en `docker-compose.yml`

**¬øPor qu√© m√©tricas?**
- Detectar problemas antes que usuarios se quejen
- Graficar rendimiento en Grafana
- SLOs medibles (ej: 95% de transcripciones <10min)

**Validaci√≥n:**
- Endpoint `/metrics` expone m√©tricas en formato Prometheus
- Prometheus scrapea m√©tricas correctamente
- Valores se actualizan en tiempo real

**Git:**
```bash
git commit -m "feat: add Prometheus metrics instrumentation"
git commit -m "feat: add Prometheus to Docker Compose"
```
**Nos da paso a:** Visualizar m√©tricas en dashboard.

---

### Paso 23: Grafana Dashboard ‚úÖ COMPLETADO (15/11/2025)
**¬øQu√© hacer?**
- ‚úÖ Agregar Grafana 10.2.0 a `docker-compose.yml`
- ‚úÖ Configurar datasource Prometheus con provisioning autom√°tico
- ‚úÖ Crear 3 dashboards con 22 paneles totales:
  - **System Overview** (8 paneles): Videos processed, success rate, cache hit rate, API requests, queue size, resources, error rate
  - **API Performance** (6 paneles): Request rate, status codes, latency p95/p50, slowest endpoints, active requests
  - **Video Processing Pipeline** (8 paneles): Status distribution, throughput, processing duration by phase, errors
- ‚úÖ Alertas visuales con thresholds configurados
- ‚úÖ Documentaci√≥n completa (grafana-dashboards-guide.md - 664 l√≠neas)

**¬øPor qu√© Grafana?**
- Visualizaci√≥n clara de salud del sistema en tiempo real
- Alertas visuales (ej: success rate <80% = panel rojo)
- Portfolio impresionante (no solo c√≥digo, tambi√©n ops)
- Monitoreo proactivo vs reactivo

**Validaci√≥n:**
- ‚úÖ Dashboard accesible en `localhost:3000`
- ‚úÖ 3 dashboards con 22 paneles muestran datos reales
- ‚úÖ Gr√°ficos se actualizan autom√°ticamente cada 15s
- ‚úÖ Persistencia verificada (restart no pierde configuraci√≥n)
- ‚úÖ Provisioning autom√°tico funcional

**Implementaci√≥n:**
- Grafana en Docker con l√≠mites de recursos (256MB)
- Provisioning autom√°tico de datasources y dashboards
- Queries PromQL optimizadas (histogram_quantile, rate, topk)
- Alertas visuales con colores semaf√≥ricos
- Volumen persistente para configuraci√≥n

**Documentaci√≥n:**
- `docs/grafana-dashboards-guide.md` (gu√≠a completa con troubleshooting)
- `docs/completitud/paso-23-grafana-dashboard.md` (documento t√©cnico)
- `PASO-23-RESUMEN.md` (resumen ejecutivo)

**Git:**
```bash
git commit -m "feat(monitoring): add Grafana dashboards with 22 panels (Paso 23)

- Add Grafana 10.2.0 to docker-compose with provisioning
- Create 3 dashboards: System Overview, API Performance, Video Processing
- Configure 22 panels with visual alerts and thresholds
- Add comprehensive documentation (grafana-dashboards-guide.md)
- Implement auto-provisioning for datasources and dashboards

ü§ñ Generated with Claude Code"
```
**Nos da paso a:** Implementar medidas de seguridad cr√≠ticas antes del testing.

---

### üîí Paso 23.5: Seguridad Cr√≠tica ‚úÖ COMPLETADO (17/11/2025)

**Contexto:**
Tras la auditor√≠a de seguridad (ref: `docs/security-audit-report.md`), se identificaron **2 vulnerabilidades cr√≠ticas** y **3 importantes** que impiden deployment seguro en producci√≥n. Este paso implementa las **Fases 1 y 2** del Plan de Mitigaci√≥n.

**¬øPor qu√© AHORA (antes del Paso 24)?**
- ‚úÖ Tests de seguridad se integran desde el inicio (Paso 24)
- ‚úÖ CI/CD validar√° configuraci√≥n segura desde el primer deploy (Paso 25)
- ‚úÖ Evita reescritura masiva de tests posterior (ahorro 4-6 d√≠as)
- ‚úÖ Elimina riesgo de deployment accidental inseguro
- ‚úÖ Portfolio demuestra que seguridad es prioritaria, no afterthought

**Duraci√≥n estimada:** 3 d√≠as (Fase 1: 2 d√≠as, Fase 2: 1 d√≠a)

---

#### **Fase 1: Mitigaciones Cr√≠ticas P0 (2 d√≠as)**

**¬øQu√© hacer?**

1. **HC-001: Sistema de Autenticaci√≥n JWT**
   - Crear modelo `User` con roles (`admin`, `user`, `bot`)
   - Migraci√≥n Alembic para tabla `users` con √≠ndices
   - Crear m√≥dulo `src/api/auth/` con:
     - `jwt.py` - Generaci√≥n y validaci√≥n de tokens JWT
     - `dependencies.py` - `get_current_user()`, `require_admin()`
     - `routes.py` - Endpoints `/auth/login`, `/auth/refresh`
   - Crear `src/repositories/user_repository.py`
   - Aplicar `Depends(get_current_user)` en endpoints de modificaci√≥n
   - Aplicar `Depends(require_admin)` en endpoints DELETE
   - Configurar CORS restrictivo (solo dominios espec√≠ficos en prod)

2. **HC-002: Mitigaci√≥n de Prompt Injection**
   - Reforzar system prompt con instrucciones anti-injection
   - Crear `src/services/input_sanitizer.py`:
     - Clase `InputSanitizer` con patrones de detecci√≥n
     - M√©todos `sanitize_title()` y `sanitize_transcription()`
     - Detecci√≥n de patrones: `IGNORE`, `REVEAL`, `EXECUTE`, etc.
   - Integrar en `SummarizationService`:
     - Sanitizar `title` y `transcription` antes de enviar a DeepSeek
     - Logging de intentos de injection detectados
   - Implementar output validation:
     - Validar longitud razonable del resumen
     - Verificar idioma espa√±ol (heur√≠stica b√°sica)
     - Detectar system prompt leaks

3. **HI-001: Configuraci√≥n Segura por Defecto**
   - Modificar `src/core/config.py`:
     - `ENVIRONMENT`: sin default (Field(...)) - obligatorio
     - `DEBUG`: default=False (seguro por defecto)
     - `CORS_ORIGINS`: restrictivo en producci√≥n
   - Agregar validaci√≥n en `src/api/main.py` (lifespan):
     - Si `is_production`: assert DEBUG=False, CORS‚â†["*"], etc.
     - App no arranca si configuraci√≥n insegura en prod
   - Actualizar `.env.example` con valores seguros

**Validaci√≥n Fase 1:**
- ‚úÖ Endpoint DELETE requiere token JWT v√°lido + rol admin
- ‚úÖ POST `/videos/{id}/process` requiere autenticaci√≥n
- ‚úÖ InputSanitizer detecta >90% de patrones de OWASP LLM Top 10
- ‚úÖ App falla al arrancar con DEBUG=True en ENVIRONMENT=production
- ‚úÖ Tests b√°sicos de autenticaci√≥n pasan (5 tests)

**Git Fase 1:**
```bash
git commit -m "feat(security): add JWT authentication with role-based access (HC-001)

- Create User model with admin/user/bot roles
- Implement /auth/login and /auth/refresh endpoints
- Add get_current_user and require_admin dependencies
- Apply authentication to all modification endpoints
- Restrict CORS to specific domains in production

Ref: docs/security-audit-report.md#HC-001"

git commit -m "feat(security): add InputSanitizer for prompt injection mitigation (HC-002)

- Create InputSanitizer with pattern detection
- Sanitize title and transcription before sending to LLM
- Implement output validation for LLM responses
- Add logging for detected injection attempts

Ref: docs/security-audit-report.md#HC-002"

git commit -m "fix(config): enforce secure defaults and production validation (HI-001)

- Make ENVIRONMENT required (no default)
- Change DEBUG default to False
- Add startup validation for production config
- Update .env.example with secure values

Ref: docs/security-audit-report.md#HI-001"
```

---

#### **Fase 2: Hardening P1 (1 d√≠a)**

**¬øQu√© hacer?**

4. **HI-002: Rate Limiting con SlowAPI**
   - Instalar `slowapi` con Poetry
   - Configurar limiter en `src/api/main.py`:
     - Backend Redis para compartir contador entre workers
     - Key function: `get_remote_address`
   - Aplicar l√≠mites por endpoint:
     - `POST /videos/{id}/process`: 5/min por IP
     - `DELETE /summaries/{id}`: 10/min por IP
     - `GET /summaries`: 100/min por IP
     - `POST /summaries/search`: 30/min por IP
   - Exception handler para `RateLimitExceeded`

5. **HC-002 (continuaci√≥n): Output Validation Estricta**
   - Forzar JSON output con `response_format={"type": "json_object"}`
   - Validar estructura del JSON (campos obligatorios)
   - Verificar que no contiene system prompt leaked

6. **Tests de Seguridad B√°sicos**
   - Crear `tests/security/` (nueva carpeta)
   - Implementar `test_authentication.py`:
     - Test login exitoso retorna token
     - Test token inv√°lido retorna 401
     - Test endpoint protegido sin token retorna 401
     - Test endpoint DELETE sin rol admin retorna 403
     - Test refresh token funciona
   - Implementar `test_prompt_injection.py`:
     - 10 casos adversariales (IGNORE, REVEAL, etc.)
     - Verificar que InputSanitizer detecta patrones
     - Test E2E: resumen no contiene instrucciones inyectadas
   - Implementar `test_rate_limiting.py`:
     - Test l√≠mite excedido retorna 429
     - Test reset tras esperar per√≠odo
     - Test l√≠mites diferentes por endpoint

**Validaci√≥n Fase 2:**
- ‚úÖ Rate limiting bloquea >5 req/min en `/process`
- ‚úÖ LLM output valida estructura JSON correctamente
- ‚úÖ Tests de seguridad pasan (18+ tests totales)
- ‚úÖ Coverage de m√≥dulos de seguridad >85%

**Git Fase 2:**
```bash
git commit -m "feat(security): add rate limiting with SlowAPI (HI-002)

- Install slowapi with Redis backend
- Configure rate limits on critical endpoints
- Add exception handler for rate limit exceeded

Ref: docs/security-audit-report.md#HI-002"

git commit -m "feat(security): enforce strict JSON output validation (HC-002)

- Force JSON response format from DeepSeek
- Validate required fields in summary output
- Detect system prompt leaks in responses

Ref: docs/security-audit-report.md#HC-002"

git commit -m "test(security): add comprehensive security test suite

- Add tests/security/ directory
- Implement authentication tests (5 tests)
- Implement prompt injection tests (10+ adversarial cases)
- Implement rate limiting tests (3 tests)
- Achieve >85% coverage on security modules

Ref: docs/security-audit-report.md#plan-de-mitigacion"
```

---

**¬øPor qu√© este orden de implementaci√≥n?**

1. **Autenticaci√≥n primero** - Es la base de seguridad, otros componentes dependen de ella
2. **Prompt Injection despu√©s** - Independiente de auth, se puede desarrollar en paralelo conceptualmente
3. **Config segura inmediatamente** - Previene arranques accidentales inseguros
4. **Rate Limiting al final** - Requiere auth implementada para l√≠mites por usuario
5. **Tests continuamente** - Se escriben junto con cada feature

---

**Entregables del Paso 23.5:**

```
src/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ auth/                         # ‚Üê NUEVO
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ jwt.py                    # Generaci√≥n/validaci√≥n JWT
‚îÇ       ‚îú‚îÄ‚îÄ dependencies.py           # get_current_user, require_admin
‚îÇ       ‚îî‚îÄ‚îÄ routes.py                 # /auth/login, /auth/refresh
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ user.py                       # ‚Üê NUEVO (modelo User)
‚îú‚îÄ‚îÄ repositories/
‚îÇ   ‚îî‚îÄ‚îÄ user_repository.py            # ‚Üê NUEVO
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ input_sanitizer.py            # ‚Üê NUEVO (anti-injection)
‚îÇ   ‚îî‚îÄ‚îÄ output_validator.py           # ‚Üê NUEVO (validaci√≥n LLM)
‚îî‚îÄ‚îÄ core/
    ‚îú‚îÄ‚îÄ config.py                     # ‚Üê MODIFICADO (valores seguros)
    ‚îî‚îÄ‚îÄ security.py                   # ‚Üê NUEVO (password hashing, utils)

tests/
‚îî‚îÄ‚îÄ security/                         # ‚Üê NUEVO
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ test_authentication.py        # 5 tests
    ‚îú‚îÄ‚îÄ test_prompt_injection.py      # 10+ tests
    ‚îî‚îÄ‚îÄ test_rate_limiting.py         # 3 tests

migrations/
‚îî‚îÄ‚îÄ versions/
    ‚îî‚îÄ‚îÄ xxxx_add_users_table.py       # ‚Üê NUEVO

.env.example                          # ‚Üê MODIFICADO (nuevas vars)
```

---

**Configuraci√≥n Nueva (.env):**

```bash
# ==================== SEGURIDAD (NUEVO) ====================
# JWT Configuration
JWT_SECRET_KEY=your-secret-key-min-32-chars  # CAMBIAR EN PRODUCCI√ìN
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_STORAGE_URI=${REDIS_URL}

# Security Flags
ENVIRONMENT=production  # Obligatorio en producci√≥n
DEBUG=false             # NUNCA true en producci√≥n
CORS_ORIGINS=https://yourdomain.com
```

---

**Dependencias Nuevas (Poetry):**

```bash
poetry add python-jose[cryptography]  # JWT
poetry add passlib[bcrypt]            # Password hashing
poetry add slowapi                    # Rate limiting
```

---

**Impacto en Paso 24 (Suite de Tests):**

El Paso 24 ahora incluir√°:
- ‚úÖ Tests de autenticaci√≥n (ya implementados en 23.5)
- ‚úÖ Tests de seguridad (ya implementados en 23.5)
- ‚ö° Tests unitarios de servicios
- ‚ö° Tests de integraci√≥n de API (con autenticaci√≥n)
- ‚ö° Tests E2E del pipeline
- ‚ö° Coverage >80% (incluyendo m√≥dulos de seguridad)

---

**Impacto en Paso 25 (CI/CD):**

El Paso 25 ahora incluir√° validaciones de seguridad:
- ‚úÖ Tests de seguridad en CI/CD
- ‚úÖ Validaci√≥n de configuraci√≥n (DEBUG=false en main)
- ‚úÖ `pip-audit` para dependencias vulnerables
- ‚úÖ Fallar si coverage de seguridad <90%

---

**Criterios de Aceptaci√≥n del Paso 23.5:**

- [ ] **HC-001:** Autenticaci√≥n JWT funcionando
  - [ ] Endpoint `/auth/login` retorna token v√°lido
  - [ ] Token inv√°lido retorna 401 en endpoints protegidos
  - [ ] Endpoints DELETE requieren rol admin
  - [ ] CORS restrictivo en producci√≥n

- [ ] **HC-002:** Prompt Injection mitigado
  - [ ] InputSanitizer detecta >90% de patrones OWASP
  - [ ] System prompt reforzado
  - [ ] Output validation rechaza respuestas an√≥malas
  - [ ] Logging de intentos de injection

- [ ] **HI-001:** Configuraci√≥n segura
  - [ ] ENVIRONMENT obligatorio (sin default)
  - [ ] DEBUG=False por defecto
  - [ ] App no arranca con config insegura en prod

- [ ] **HI-002:** Rate Limiting funcionando
  - [ ] SlowAPI configurado con Redis
  - [ ] L√≠mites aplicados en endpoints cr√≠ticos
  - [ ] Exceso de l√≠mite retorna 429

- [ ] **Tests:** Suite de seguridad completa
  - [ ] 18+ tests de seguridad pasan
  - [ ] Coverage de m√≥dulos de seguridad >85%
  - [ ] Tests integrados en CI

---

**Documentaci√≥n Asociada:**

- `docs/security-audit-report.md` (ya existe - 1575 l√≠neas)
- `docs/ADR/ADR-012-jwt-authentication.md` (a crear)
- `docs/ADR/ADR-013-prompt-injection-mitigation.md` (a crear)
- `.env.example` (actualizar con nuevas variables)

---

**Nos da paso a:** Paso 24 - Suite de Tests Completa (ahora incluye tests de seguridad desde el inicio).

---

## ‚úÖ FASE 6: TESTING & CI/CD (2 d√≠as)

### Paso 24: Suite de Tests Completa
**¬øQu√© hacer?**
- Tests unitarios en `tests/unit/` para servicios y repositories
- Tests de integraci√≥n en `tests/integration/` para API y BD
- Tests E2E en `tests/e2e/` para pipeline completo
- Configurar fixtures pytest para datos de prueba
- Objetivo: >80% de cobertura en l√≥gica cr√≠tica

**¬øPor qu√© cobertura alta?**
- Sin tests, cada cambio es ruleta rusa
- Tests = confianza para refactorizar
- Coverage >80% = se√±al de calidad profesional

**Validaci√≥n:**
- `pytest tests/ -v` todos los tests pasan
- `pytest --cov=src` muestra cobertura >80%
- Tests r√°pidos (<2 min total)

**Git:**
```bash
git commit -m "test: add comprehensive test suite with >80% coverage"
```
**Nos da paso a:** Automatizar tests con CI.

---

### Paso 25: GitHub Actions (CI/CD)
**¬øQu√© hacer?**
- Crear `.github/workflows/test.yml`:
  - Trigger en `push` y `pull_request`
  - Setup Python 3.11 + Poetry
  - Levantar Postgres y Redis con `services`
  - Ejecutar `pytest` con coverage
  - Fallar si coverage <80%
- Crear `.github/workflows/lint.yml`:
  - Black, ruff, mypy
  - Fallar si hay errores de formato o tipado

**¬øPor qu√© CI automatizado?**
- Previene merges que rompen tests
- Code review autom√°tico de formato
- Badge verde en README = proyecto mantenido

**Validaci√≥n:**
- Push a rama trigger workflows
- Workflows pasan con c√≥digo actual
- Badge en README muestra estado

**Git:**
```bash
git commit -m "ci: add GitHub Actions for tests and linting"
```
**Nos da paso a:** Preparar deployment a producci√≥n.

---

## üöÄ FASE 7: DEPLOYMENT (2-3 d√≠as)

### Paso 26: Dockerfile Optimizado
**¬øQu√© hacer?**
- Crear Dockerfile multi-stage (builder + runtime)
- Stage 1: Instalar dependencias con Poetry
- Stage 2: Copiar solo lo necesario (sin dev dependencies)
- Usuario no-root por seguridad
- Health check integrado en container

**¬øPor qu√© multi-stage?**
- Imagen final m√°s peque√±a (500MB vs 2GB)
- Menos superficie de ataque (sin compiladores)
- Build cache eficiente

**Validaci√≥n:**
- `docker build -t ia-monitor .` exitoso
- `docker run ia-monitor` arranca correctamente
- Imagen <600MB

**Git:**
```bash
git commit -m "feat: add optimized multi-stage Dockerfile"
```
**Nos da paso a:** Orquestar todos los servicios.

---

### Paso 27: Docker Compose Producci√≥n
**¬øQu√© hacer?**
- Crear `docker-compose.prod.yml` con todos los servicios:
  - API (FastAPI)
  - Worker (Celery worker)
  - Beat (Celery scheduler)
  - Postgres (con volumen persistente)
  - Redis
  - Prometheus
  - Grafana
- Configurar restart policies
- L√≠mites de recursos (CPU, RAM)

**¬øPor qu√© separar dev y prod?**
- Dev usa hot-reload, prod no
- Prod tiene health checks y limits
- Prod usa secretos desde variables, no `.env`

**Validaci√≥n:**
- `docker-compose -f docker-compose.prod.yml up -d` levanta todo
- Todos los servicios saludables
- API accesible desde fuera del container

**Git:**
```bash
git commit -m "feat: add production Docker Compose configuration"
```
**Nos da paso a:** Scripts de deployment.

---

### Paso 28: Scripts de Deployment
**¬øQu√© hacer?**
- Crear `scripts/deploy.sh` que:
  - Pull √∫ltimos cambios de Git
  - Build nueva imagen Docker
  - Stop containers antiguos
  - Start nuevos containers
  - Health check post-deployment
  - Rollback autom√°tico si falla
- Crear `scripts/backup_db.sh` para backups autom√°ticos
- Configurar `cron` job para backups diarios

**¬øPor qu√© scripts?**
- Deployment manual = errores humanos
- Scripts = reproducible y documentado
- Rollback autom√°tico = recovery r√°pido

**Validaci√≥n:**
- Script ejecuta sin errores
- Deployment se completa en <5 minutos
- Rollback funciona si se simula error

**Git:**
```bash
git commit -m "feat: add deployment and backup scripts"
```
**Nos da paso a:** Automatizar deployment.

---

### Paso 29: CD Autom√°tico (GitHub Actions)
**¬øQu√© hacer?**
- Crear `.github/workflows/deploy.yml`:
  - Trigger solo en push a `main`
  - Ejecutar despu√©s de tests exitosos
  - SSH a servidor de producci√≥n
  - Ejecutar script de deployment
  - Notificar en Slack/Discord si falla

**¬øPor qu√© CD?**
- Push a main = deployment autom√°tico
- Sin intervenci√≥n manual
- Faster time to production

**Validaci√≥n:**
- Merge a `main` trigger deployment
- Cambios visibles en producci√≥n en <10 minutos
- Notificaci√≥n recibida

**Git:**
```bash
git commit -m "ci: add continuous deployment workflow"
```
**Nos da paso a:** Documentaci√≥n final.

---

### Paso 30: Documentaci√≥n Final
**¬øQu√© hacer?**
- README completo con:
  - Descripci√≥n del proyecto y valor
  - Arquitectura (diagrama)
  - Instalaci√≥n local paso a paso
  - Endpoints API documentados
  - Decisiones t√©cnicas importantes (links a ADRs)
  - Badges (CI status, coverage, license)
- Actualizar `docs/ADR/` con decisiones finales
- Screenshots de Grafana dashboard
- Video demo de 2 minutos (opcional pero impresionante)

**¬øPor qu√© documentaci√≥n curada?**
- Onboarding de recruiters en <5 minutos
- Proyecto sin docs = proyecto amateur
- ADRs demuestran pensamiento arquitect√≥nico

**Git:**
```bash
git commit -m "docs: complete README with architecture and setup guide"
git commit -m "docs: finalize ADRs for key technical decisions"
```

---

## üìÖ TIMELINE SEMANAL

### ‚úÖ Semana 1: Fundaci√≥n (COMPLETADA)
- **Lunes:** Architecture doc + Git setup + Poetry ‚úÖ
- **Martes:** Docker Compose + Config + FastAPI base ‚úÖ
- **Mi√©rcoles:** ORM + Migraciones + Source model ‚úÖ
- **Jueves:** DeepSeek integration + Tests ‚úÖ
- **Viernes:** Downloader service + Whisper setup ‚úÖ

### ‚úÖ Semana 2: Pipeline Completo + Modelos (COMPLETADA)
- **Lunes:** Transcription service + Pipeline orchestrator ‚úÖ
- **Martes:** Modelos BD completos (Video, Transcription, Summary, TelegramUser) ‚úÖ
- **Mi√©rcoles:** Repository Pattern completo (Base + 5 especializados) ‚úÖ
- **Jueves:** Servicios de negocio (VideoProcessingService) ‚úÖ
- **Viernes:** Schemas Pydantic v2 + API base ‚úÖ

### ‚úÖ Semana 3: API REST Completa (COMPLETADA)
- **Lunes:** Endpoints Videos (10 endpoints CRUD + processing) ‚úÖ
- **Martes:** Endpoints Transcriptions y Summaries (6 endpoints) ‚úÖ
- **Mi√©rcoles:** Endpoints Stats (2 endpoints) + Exception handlers ‚úÖ
- **Jueves:** OpenAPI metadata + Tests API ‚úÖ
- **Viernes:** Refinamiento y documentaci√≥n API ‚úÖ

### ‚úÖ Semana 4: Bot Telegram Multi-Usuario (COMPLETADA)
- **Lunes:** Bot - Setup b√°sico + /start + /help ‚úÖ
- **Martes:** Bot - Suscripciones interactivas con inline keyboards ‚úÖ
- **Mi√©rcoles:** Bot - Historial y b√∫squeda (/recent, /search) ‚úÖ
- **Jueves:** Worker de distribuci√≥n personalizada (ADR-010) ‚úÖ
- **Viernes:** Logging estructurado ‚úÖ

### ‚úÖ Semana 5: Observabilidad (COMPLETADA)
- **Lunes:** M√©tricas Prometheus + Monitoreo de costos DeepSeek ‚úÖ
- **Martes:** Dashboard Grafana completo (Paso 22-23) ‚úÖ
- **Mi√©rcoles-Viernes:** *(D√≠as disponibles para Paso 23.5)*

### üìç Semana 5 (ACTUALIZADA): Seguridad Cr√≠tica + Testing
- **Lunes (18/11):** Paso 23.5 Fase 1 - HC-001 Autenticaci√≥n JWT ‚Üê üìç SIGUIENTE
- **Martes (19/11):** Paso 23.5 Fase 1 - HC-002 Prompt Injection + HI-001 Config Segura
- **Mi√©rcoles (20/11):** Paso 23.5 Fase 2 - HI-002 Rate Limiting + Tests Seguridad
- **Jueves-Viernes (21-22/11):** Paso 24 - Suite de Tests Completa (incluye tests de seguridad ya implementados)

### Semana 6: Deployment & Docs
- **Lunes:** Dockerfile + Docker Compose prod
- **Martes:** Scripts de deployment + Backups
- **Mi√©rcoles:** CD autom√°tico + Validaci√≥n
- **Jueves:** Documentaci√≥n final + ADRs
- **Viernes:** Optimizaciones + Demo video

**Total:** ~5 semanas trabajando 3-4h/d√≠a
---

## ‚úÖ REGLAS DE ORO

### 1. Commits Peque√±os y Descriptivos
- ‚ùå `git commit -m "todo listo"`
- ‚úÖ `git commit -m "feat(api): add summaries endpoint with pagination"`

### 2. Tests ANTES de Merge
- Cada feature debe tener tests antes de merge a main
- Coverage nunca debe bajar del 80%

### 3. Documentaci√≥n Sincronizada
- README siempre actualizado con features nuevas
- ADRs para decisiones importantes

### 4. Branch Strategy
```text
main              ‚Üê Solo c√≥digo funcional + tests
  ‚îú‚îÄ feat/Deepseek-integration
  ‚îú‚îÄ feat/whisper-transcription
  ‚îî‚îÄ feat/celery-workers
```

### 5. Validaci√≥n Paso a Paso
- No avanzar al siguiente paso sin validar el actual
- "Funciona en mi m√°quina" no es suficiente (Docker soluciona esto)

---

¬°√âxito con el proyecto! üöÄ
