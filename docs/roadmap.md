# üó∫Ô∏è ROADMAP DETALLADO - IA MONITOR
**Versi√≥n:** 1.0
**Actualizado:** Octubre 2025
**Metodolog√≠a:** Incremental con validaci√≥n paso a paso

---

## üìñ √çNDICE
- Visi√≥n General
- Fase 0: Planning & Setup (1 d√≠a)
- Fase 1: Infraestructura Base (2-3 d√≠as)
- Fase 2: Pipeline Core (1 semana)
- Fase 3: API REST + Bot Telegram (5-6 d√≠as)
- Fase 4: Workers Async (2-3 d√≠as)
- Fase 5: Observabilidad (2 d√≠as)
- Fase 6: Testing & CI (2 d√≠as)
- Fase 7: Deployment (2-3 d√≠as)
- Timeline Semanal
---

## üéØ VISI√ìN GENERAL

### Objetivo del Proyecto
Crear un agregador inteligente con bot de Telegram multi-usuario que autom√°ticamente:
- Recopila contenidos sobre IA en desarrollo software (YouTube, RSS, podcasts)
- Transcribe audios usando Whisper (local, gratuito)
- Resume textos usando DeepSeek API (bajo coste, sin l√≠mites)
- Distribuye res√∫menes personalizados v√≠a Bot de Telegram interactivo
- Cada usuario elige sus canales y gestiona su historial

### Doble Prop√≥sito
- **Utilidad real:** Bot multi-usuario donde cada persona elige sus canales de inter√©s
- **Portfolio profesional:** Demostrar backend Python moderno con IA funcional y arquitectura multi-usuario

### Stack Tecnol√≥gico
- **Backend:** FastAPI (sync endpoints) + PostgreSQL + Redis
- **Workers:** Celery para tareas en background (scraping, transcripci√≥n, distribuci√≥n)
- **Bot:** python-telegram-bot con inline keyboards y commands interactivos
- **IA:** Whisper (transcripci√≥n local) + DeepSeek API (res√∫menes)
- **DevOps:** Docker, GitHub Actions, Prometheus + Grafana

---

## üìã FASE 0: PLANNING & SETUP (1 d√≠a)

### Paso 1: Documento de Arquitectura (Project Designer)
**¬øQu√© hacer?**
- Crear `docs/architecture.md` usando el prompt Project Designer
- Decisiones t√©cnicas justificadas (Whisper local vs APIs de pago, DeepSeek vs ApyHub/LangChain - ADR-009, Celery vs BackgroundTasks)
- Diagrama Mermaid de arquitectura completa (componentes + flujos)
- Estructura de directorios definitiva
- Roadmap de features priorizadas por fases

**¬øPor qu√© primero?**
- Define QU√â construir y C√ìMO antes de escribir una l√≠nea de c√≥digo
- Evita refactors masivos posteriores (ej: cambiar de MongoDB a PostgreSQL en semana 3)
- Justifica decisiones t√©cnicas ante reclutadores (portfolio = arquitectura pensada)
- Detecta dependencias cr√≠ticas temprano (ej: limitaciones de APIs externas que motivaron migraci√≥n a DeepSeek)

**Entregable:**
- `docs/architecture.md` completo con diagramas
- Stack t√©cnico con tabla de pros/contras
- Flujos de procesamiento documentados

**Git:**
```bash
git commit -m "docs: add initial architecture document with diagrams"
```
**Nos da paso a:** Crear estructura del repositorio basada en arquitectura definida.

---

### Paso 2: Estructura del Repositorio
**¬øQu√© hacer?**
- Crear carpetas seg√∫n arquitectura: `src/api/`, `src/services/`, `src/models/`, `src/repositories/`, `src/tasks/`, `tests/`
- Inicializar Git con `.gitignore` (Python, Docker, secretos)
- README b√°sico con descripci√≥n, badges placeholders (CI, coverage)
- `.env.example` con template de variables (sin valores reales)
- `docs/ADR/` para Architecture Decision Records

**¬øPor qu√© esta estructura?**
- Separaci√≥n clara: API / Servicios / Datos (Clean Architecture)
- Tests desde d√≠a 1 = cultura de calidad
- `.env.example` documenta qu√© variables necesita el proyecto
- ADRs justifican decisiones importantes (por qu√© Whisper local, no Deepgram API)

**Entregable:**
- Carpetas vac√≠as pero con `__init__.py`
- README con descripci√≥n del proyecto
- `.gitignore` configurado

**Git:**
```bash
git init
git add .
git commit -m "chore: initial project structure with Clean Architecture"
git remote add origin <tu-repo>
git push -u origin main
```
**Nos da paso a:** Configurar gestor de dependencias reproducible.

---

### Paso 3: Poetry Setup + Dependencias Base
**¬øQu√© hacer?**
- Inicializar Poetry con `poetry init`
- Instalar dependencias core: FastAPI, SQLAlchemy, Alembic, PostgreSQL driver, Redis, Celery
- Instalar dependencias IA: Whisper, yt-dlp (descarga YouTube), httpx (cliente HTTP async)
- Dev dependencies: pytest, black, ruff, mypy, pytest-cov

**¬øPor qu√© ahora?**
- Dependencias fijadas en `poetry.lock` = reproducible en cualquier m√°quina
- Instalar todo de golpe evita conflictos de versiones despu√©s
- Poetry gestiona entornos virtuales autom√°ticamente

**Entregable:**
- `pyproject.toml` con todas las dependencias
- `poetry.lock` generado

**Git:**
```bash
git add pyproject.toml poetry.lock
git commit -m "chore: add Poetry dependencies for FastAPI, Whisper, and testing"
```
**Nos da paso a:** Levantar infraestructura local (BD + cache).

---

## üèóÔ∏è FASE 1: INFRAESTRUCTURA BASE (2-3 d√≠as)

### Paso 4: Docker Compose (Postgres + Redis)
**¬øQu√© hacer?**
- Crear `docker-compose.yml` con servicios: Postgres 15, Redis 7
- Configurar vol√∫menes para persistencia de datos
- Puertos expuestos: Postgres 5432, Redis 6379
- Variables de entorno para usuario/password de BD

**¬øPor qu√© Docker?**
- BD lista en 1 comando (`docker-compose up -d`)
- Mismo entorno en dev/staging/prod (no "funciona en mi m√°quina")
- No contamina sistema local (se borra f√°cilmente)

**Validaci√≥n:**
- `docker-compose up -d` arranca sin errores
- Conexi√≥n a Postgres exitosa con `psql`
- Redis responde a `redis-cli ping` con `PONG`

**Git:**
```bash
git commit -m "feat: add Docker Compose with Postgres and Redis"
```
**Nos da paso a:** Configurar variables de entorno de la aplicaci√≥n.

---

### Paso 5: Config + Variables de Entorno
**¬øQu√© hacer?**
- Crear `src/core/config.py` usando Pydantic Settings
- Validar variables obligatorias: `DATABASE_URL`, `REDIS_URL`, `DEEPSEEK_API_KEY`
- `.env.example` con plantilla (este S√ç va a Git)
- `.env` real (este NO va a Git, usuario debe crearlo copiando el example)

**¬øPor qu√© Pydantic Settings?**
- Validaci√≥n autom√°tica al arrancar (si falta variable, app no inicia)
- Tipado fuerte (no strings m√°gicos)
- 12-factor app compliant (configuraci√≥n fuera del c√≥digo)

**Validaci√≥n:**
- App falla si `.env` no existe (comportamiento esperado)
- App arranca correctamente con `.env` v√°lido

**Git:**
```bash
git add src/core/config.py .env.example
git commit -m "feat: add configuration management with Pydantic Settings"
```
**Nos da paso a:** Crear API base funcional.

---

### Paso 6: FastAPI Base + Health Check
**¬øQu√© hacer?**
- Crear `src/api/main.py` con aplicaci√≥n FastAPI m√≠nima
- Endpoint `/health` que devuelve `{"status": "ok"}`
- Endpoint `/` que devuelve mensaje de bienvenida
- Configurar documentaci√≥n autom√°tica en `/api/docs`

**¬øPor qu√© health check?**
- Valida que FastAPI funciona correctamente
- Necesario para monitoreo futuro (Prometheus, Kubernetes probes)
- Primera victoria r√°pida (motivaci√≥n para continuar)

**Validaci√≥n:**
- `uvicorn src.api.main:app` arranca sin errores
- `curl localhost:8000/health` responde 200 OK
- Swagger UI accesible en `localhost:8000/api/docs`

**Test:**
- Crear `tests/test_health.py` con test del endpoint health
- `pytest tests/test_health.py -v` debe pasar

**Git:**
```bash
git commit -m "feat: add FastAPI base with health endpoint"
git commit -m "test: add health endpoint test"
```
**Nos da paso a:** Configurar ORM y sistema de migraciones.

---

### Paso 7: ORM + Migraciones (Alembic)
**¬øQu√© hacer?**
- Configurar SQLAlchemy `engine` y `sessionmaker` en `src/core/database.py`
- Inicializar Alembic con `alembic init migrations`
- Configurar `alembic.ini` para usar `DATABASE_URL` desde `.env`
- Crear primer modelo: `Source` (tabla de fuentes: YouTube channels, RSS feeds)
- Generar migraci√≥n autom√°tica: `alembic revision --autogenerate`
- Aplicar migraci√≥n: `alembic upgrade head`

**¬øPor qu√© migraciones?**
- Schema de BD versionado (como Git pero para la base de datos)
- Rollback posible si algo falla (`alembic downgrade`)
- Colaboraci√≥n sin romper datos de otros desarrolladores
- Historial de cambios en schema documentado

**Validaci√≥n:**
- Tabla `sources` existe en Postgres
- Tabla `alembic_version` registra la migraci√≥n
- `alembic current` muestra versi√≥n actual

**Git:**
```bash
git commit -m "feat: add SQLAlchemy ORM setup"
git commit -m "feat: add Alembic migrations"
git commit -m "feat: add Source model with first migration"
```
**Nos da paso a:** Implementar servicios core del pipeline.

---

## üß© FASE 2: PIPELINE CORE (1 semana)

### Paso 8: Integraci√≥n DeepSeek (Res√∫menes)
**¬øQu√© hacer?**
- Crear `src/services/summarization_service.py`
- Implementar m√©todo `summarize_text()` que llama a DeepSeek API
- Usar SDK de OpenAI (compatible con DeepSeek)
- Implementar sistema de prompts en `src/services/prompts/`
- Manejo de errores: timeout, respuestas inv√°lidas

**¬øPor qu√© primero?**
- Es el componente externo cr√≠tico del sistema
- Si DeepSeek est√° ca√≠do o cambia API, mejor descubrirlo YA
- Lo m√°s r√°pido de validar (no requiere BD ni otros servicios)
- API s√≠ncrona simple (SDK compatible con OpenAI)

**Validaci√≥n:**
- Test de integraci√≥n que llama a API real con texto de prueba
- Resumen generado correctamente en espa√±ol
- Sistema de prompts funciona correctamente

**Git:**
```bash
git commit -m "feat: add DeepSeek summarization service with OpenAI SDK"
git commit -m "feat: add prompt engineering system"
git commit -m "test: add DeepSeek integration test"
```
**Nos da paso a:** Implementar descarga de audios.

---

### Paso 9: Descarga de Audio (yt-dlp)
**¬øQu√© hacer?**
- Crear `src/services/downloader_service.py`
- Implementar `download_audio()` que descarga audio de YouTube en MP3
- Implementar `get_video_metadata()` para obtener info sin descargar
- Configurar carpeta temporal `/tmp/ia-monitor/downloads`
- Extraer mejor calidad de audio disponible

**¬øPor qu√© despu√©s de DeepSeek?**
- No depende de DeepSeek (servicios aislados)
- Genera archivos que el siguiente paso (transcripci√≥n) consumir√°

**Validaci√≥n:**
- Descargar video test de 30 segundos funciona
- Archivo MP3 generado existe y pesa >10KB
- Metadata extra√≠da correctamente (t√≠tulo, duraci√≥n, autor)

**Git:**
```bash
git commit -m "feat: add YouTube audio downloader with yt-dlp"
git commit -m "test: add downloader service test with sample video"
```
**Nos da paso a:** Implementar transcripci√≥n local.

---

### Paso 10: Transcripci√≥n (Whisper Local)
**¬øQu√© hacer?**
- Crear `src/services/transcription_service.py`
- Cargar modelo Whisper (usar **base** para balance velocidad/precisi√≥n)
- Implementar `transcribe_audio()` que convierte MP3 a texto
- Soportar idioma espa√±ol por defecto, configurable
- Implementar variante con **timestamps** (para features futuras)

**¬øPor qu√© Whisper local?**
- Gratuito (vs Deepgram $0.006/min que escala r√°pido)
- Privacidad (audio no sale del servidor)
- Portfolio impresionante (demuestra manejo de modelos ML reales)
- Sin l√≠mites (procesar 1000 videos no cuesta nada)

**Validaci√≥n:**
- Primera ejecuci√≥n descarga modelo (2-3 min, normal)
- Transcripci√≥n de audio de 30s tarda <1 minuto
- Texto generado tiene sentido y est√° en espa√±ol

**Git:**
```bash
git commit -m "feat: add Whisper transcription service"
git commit -m "test: add transcription test with sample audio"
```
**Nos da paso a:** Conectar todos los servicios en un pipeline.

---

### Paso 11: Modelos de BD Completos (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Crear modelo `Transcription` con relaci√≥n 1:1 a Video
- Crear modelo `Summary` con relaci√≥n 1:1 a Transcription
- Crear modelo `TelegramUser` con relaci√≥n M:N a Source
- Generar y aplicar migraciones Alembic
- Actualizar `Video` model con relaci√≥n a `Transcription`

**Estado:**
- ‚úÖ Modelos creados con tipado completo: Source, Video, Transcription, Summary, TelegramUser
- ‚úÖ Relaciones definidas (Video ‚Üí Transcription ‚Üí Summary)
- ‚úÖ Tabla intermedia `user_source_subscriptions` para suscripciones
- ‚úÖ Migraci√≥n aplicada con √≠ndices GIN y full-text search
- ‚úÖ Campos de tracking en Summary para Telegram
- ‚úÖ Exports actualizados en `__init__.py`

**Git:**
```bash
# Ya commiteado:
feat(models): add Transcription and Summary models
feat(models): add TelegramUser model with M:N subscriptions
feat(db): add migration for all tables with relationships
```
**Nos da paso a:** Implementar Repository Pattern.

---

### Paso 12: Repository Pattern (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Crear `src/repositories/base_repository.py` gen√©rico con TypeVar[T]
- Implementar CRUD s√≠ncrono: `create`, `get_by_id`, `list_all`, `update`, `delete`
- Crear `SourceRepository` con m√©todos espec√≠ficos
- Crear `VideoRepository` con queries por estado
- Crear `TranscriptionRepository` con b√∫squeda por video
- Crear `SummaryRepository` con filtros y b√∫squeda full-text
- Crear `TelegramUserRepository` con queries de suscripciones

**¬øPor qu√© s√≠ncronos?** (ADR-011)
- Celery workers son 99% del uso de BD (s√≠ncronos por dise√±o)
- API REST: <10 req/d√≠a (uso ocasional)
- Implementaci√≥n m√°s simple (2 d√≠as vs 4 d√≠as async)
- SQLAlchemy ORM funciona mejor en modo sync

**Estado:**
- ‚úÖ BaseRepository gen√©rico con TypeVar[T]
- ‚úÖ 5 repositories especializados implementados
- ‚úÖ M√©todos de b√∫squeda avanzada (full-text, filtros, paginaci√≥n)
- ‚úÖ Exception handling personalizado

**Git:**
```bash
# Ya commiteado:
feat(repositories): add BaseRepository with generic CRUD
feat(repositories): add SourceRepository and VideoRepository
feat(repositories): add TranscriptionRepository and SummaryRepository
feat(repositories): add TelegramUserRepository
```
**Nos da paso a:** Servicios de negocio y API REST.

---

### Paso 13: Servicios de Negocio (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Implementar `VideoProcessingService` como orquestador del pipeline
- Integrar descarga, transcripci√≥n y resumen en flujo unificado
- Manejo de errores con excepciones personalizadas
- Tracking de estado de procesamiento

**Estado:**
- ‚úÖ `DownloaderService` - descarga de audio con yt-dlp
- ‚úÖ `TranscriptionService` - transcripci√≥n con Whisper
- ‚úÖ `SummarizationService` - res√∫menes con DeepSeek API
- ‚úÖ `VideoProcessingService` - orquestador del pipeline completo

**Git:**
```bash
# Ya commiteado:
feat(services): add video processing orchestrator
feat(services): integrate downloader, transcription and summarization
```
**Nos da paso a:** Implementar API REST completa.

---

## üåê FASE 3: API REST + BOT TELEGRAM MULTI-USUARIO (5-6 d√≠as)

### Paso 14: API REST Completa (‚úÖ COMPLETADO)
**Contexto:** Backend completo con 18 endpoints para gesti√≥n de videos, transcripciones, res√∫menes y estad√≠sticas.

**¬øQu√© hacer?**
- Crear schemas Pydantic v2 en `src/api/schemas/`
- Implementar `src/api/routes/videos.py` (10 endpoints):
  - CRUD completo de videos
  - Procesamiento as√≠ncrono (encolar, reintentar)
  - Estad√≠sticas por video
- Implementar `src/api/routes/transcriptions.py` (2 endpoints):
  - Listado paginado
  - Detalle de transcripci√≥n
- Implementar `src/api/routes/summaries.py` (4 endpoints):
  - Listado paginado con cursor
  - Detalle de resumen
  - B√∫squeda full-text con ranking
  - Soft delete
- Implementar `src/api/routes/stats.py` (2 endpoints):
  - Estad√≠sticas globales del sistema
  - Estad√≠sticas por fuente
- Configurar dependency injection para repos
- Exception handlers globales
- Metadata OpenAPI enriquecida

**Estado:**
- ‚úÖ **18 endpoints implementados y documentados**
- ‚úÖ Schemas Pydantic v2 con validaci√≥n
- ‚úÖ Paginaci√≥n cursor-based
- ‚úÖ Exception handlers globales
- ‚úÖ OpenAPI docs con ejemplos y descripciones
- ‚úÖ Dependency injection para repositories

**Git:**
```bash
# Ya commiteado:
feat(api): add videos endpoints with CRUD and processing
feat(api): add transcriptions endpoints
feat(api): add summaries endpoints with full-text search
feat(api): add stats endpoints
test(api): add comprehensive API test suite
```
**Nos da paso a:** Implementar Bot de Telegram multi-usuario.

---

### Paso 15: Bot de Telegram - Setup B√°sico (‚úÖ COMPLETADO)
**¬øQu√© hacer?**
- Instalar `python-telegram-bot` con Poetry
- Crear `src/bot/telegram_bot.py` con configuraci√≥n b√°sica
- Implementar command `/start` con mensaje de bienvenida
- Implementar command `/help` con lista de comandos
- Registrar usuario autom√°ticamente en `/start` (v√≠a TelegramUserRepository)
- Configurar webhook o polling seg√∫n entorno

**¬øPor qu√© primero?**
- Valida que bot funciona antes de a√±adir complejidad
- Configura infraestructura b√°sica (token, permisos)
- Primera interacci√≥n con usuarios

**Estado:**
- ‚úÖ `python-telegram-bot v22.5` instalado
- ‚úÖ Bot principal configurado en modo polling
- ‚úÖ Handler `/start` con registro autom√°tico de usuarios
- ‚úÖ Handler `/help` con lista de comandos
- ‚úÖ Error handler global con logging estructurado
- ‚úÖ 6 tests unitarios (todos pasan)
- ‚úÖ Bot validado en Telegram (@yt_IAinformer_bot)

**Archivos creados:**
- `src/bot/__init__.py`
- `src/bot/telegram_bot.py` (154 l√≠neas)
- `src/bot/handlers/start.py` (136 l√≠neas)
- `src/bot/handlers/help.py` (49 l√≠neas)
- `tests/bot/conftest.py` (127 l√≠neas)
- `tests/bot/test_handlers.py` (6 tests)

**Decisiones t√©cnicas:**
- Uso de `asyncio.to_thread()` para bridge async/sync (handlers ‚Üí repositories)
- Polling mode para desarrollo, infraestructura lista para webhook
- Registro idempotente de usuarios (ejecutar `/start` 2 veces no duplica)

**Git:**
```bash
git commit -m "feat(bot): add telegram bot basic setup with polling mode"
git commit -m "feat(bot): add /start handler with automatic user registration"
git commit -m "feat(bot): add /help handler with command list"
git commit -m "test(bot): add comprehensive handler tests (6 tests)"
git commit -m "chore: add python-telegram-bot dependency"
```
**Nos da paso a:** Commands interactivos de suscripciones.

---

### Paso 16: Bot de Telegram - Suscripciones Interactivas
**¬øQu√© hacer?**
- Implementar command `/sources` con inline keyboard
- Mostrar lista de canales con botones ‚úÖ/‚ùå (suscrito/no suscrito)
- Implementar callback_query handler para toggle de suscripciones
- Actualizar teclado din√°micamente tras cada toggle
- Consumir API interna para obtener sources y gestionar suscripciones

**¬øPor qu√© inline keyboards?**
- UX superior (botones vs escribir comandos)
- Feedback visual inmediato (‚úÖ/‚ùå)
- Reduce errores del usuario (no tipear nombres de canales)

**Validaci√≥n:**
- `/sources` muestra teclado con canales disponibles
- Click en bot√≥n actualiza suscripci√≥n en BD
- Teclado se actualiza reflejando nuevo estado

**Git:**
```bash
git commit -m "feat(bot): add /sources command with inline keyboard"
git commit -m "feat(bot): add subscription toggle callback handlers"
git commit -m "test(bot): add subscription toggle tests"
```
**Nos da paso a:** Commands de consulta de hist√≥rico.

---

### Paso 17: Bot de Telegram - Historial y B√∫squeda
**¬øQu√© hacer?**
- Implementar command `/recent` ‚Äî √öltimos 10 res√∫menes de canales suscritos
- Implementar command `/search <query>` ‚Äî Buscar en hist√≥rico por keyword
- Formatear mensajes con:
  - üìπ T√≠tulo del video
  - üîó Link de YouTube
  - ‚è±Ô∏è Duraci√≥n
  - üè∑Ô∏è Tags (#FastAPI #Python)
  - üìù Resumen
- A√±adir bot√≥n inline "Reenviar" por resumen
- Consumir API interna para queries filtradas

**¬øPor qu√© estos commands?**
- `/recent` = acceso r√°pido a √∫ltimas novedades
- `/search` = recuperar informaci√≥n antigua f√°cilmente
- Formato enriquecido = mensajes √∫tiles y visualmente claros

**Validaci√≥n:**
- `/recent` muestra s√≥lo res√∫menes de canales suscritos
- `/search FastAPI` encuentra res√∫menes relevantes
- Links de YouTube funcionan correctamente
- Bot√≥n "Reenviar" reenvia el mensaje

**Git:**
```bash
git commit -m "feat(bot): add /recent command with formatted messages"
git commit -m "feat(bot): add /search command with keyword filtering"
git commit -m "test(bot): add history and search tests"
```
**Nos da paso a:** Worker de distribuci√≥n personalizada.

---

### Paso 18: Worker de Distribuci√≥n Personalizada (ADR-010)
**¬øQu√© hacer?**
- Crear `src/tasks/distribute_summaries.py`
- Implementar tarea Celery `distribute_summary(summary_id: str)`
- L√≥gica:
  1. Obtener resumen de BD
  2. Consultar usuarios suscritos al canal (M:N query)
  3. Para cada usuario suscrito:
     - Formatear mensaje con üìπ t√≠tulo, üîó link, üìù resumen
     - Enviar v√≠a Bot API
     - Registrar `telegram_message_id` en BD
  4. Actualizar `summary.sent_to_telegram = True`
- Manejo de errores: reintentar si falla env√≠o

**¬øPor qu√© worker separado?**
- Env√≠o a N usuarios puede tardar (rate limits de Telegram)
- No bloquea pipeline de transcripci√≥n/resumen
- Reintentos autom√°ticos si usuario tiene bot bloqueado

**Validaci√≥n:**
- Resumen generado se env√≠a solo a usuarios suscritos al canal
- Campo `telegram_message_ids` se actualiza correctamente
- Bot no env√≠a duplicados

**Git:**
```bash
git commit -m "feat(worker): add personalized distribution to Telegram users"
git commit -m "test(worker): add distribution tests with mock users"
```
**Nos da paso a:** Sistema de rate limiting para API de res√∫menes.

---

## ‚ö° FASE 4: WORKERS ASYNC (2-3 d√≠as)

### Paso 19: Celery Setup
**¬øQu√© hacer?**
- Configurar Celery en `src/core/celery_app.py` con Redis como broker
- Crear tarea `src/tasks/process_content_task.py` que ejecuta el pipeline completo
- Configurar Celery Beat para tareas programadas (scraping peri√≥dico de fuentes)
- Script de inicio de worker: `celery -A src.core.celery_app worker`

**¬øPor qu√© Celery?**
- Procesamiento async = API responde inmediato, trabajo en background
- Transcripci√≥n de 1 video tarda 5-10 min (no puede bloquear endpoint HTTP)
- Reintentos autom√°ticos si falla
- Escalable (m√∫ltiples workers en paralelo)

**Validaci√≥n:**
- Worker arranca sin errores
- Tarea encolada se ejecuta correctamente
- Logs muestran progreso del procesamiento

**Git:**
```bash
git commit -m "feat: add Celery configuration with Redis broker"
git commit -m "feat: add process_content async task"
```
**Nos da paso a:** Automatizar procesamiento peri√≥dico.

---

### Paso 20: Jobs Programados (Celery Beat)
**¬øQu√© hacer?**
- Configurar Celery Beat scheduler
- Crear tarea `sync_sources_task.py` que:
  - Consulta fuentes activas en BD
  - Busca nuevos contenidos (√∫ltimos videos de canal YouTube, nuevos posts de RSS)
  - Encola procesamiento de contenidos nuevos
- Programar ejecuci√≥n: cada 6 horas

**¬øPor qu√© automatizaci√≥n?**
- Sistema aut√≥nomo = sin intervenci√≥n manual
- Mantiene res√∫menes actualizados autom√°ticamente
- Demuestra orquestaci√≥n de workers (punto fuerte en portfolio)

**Validaci√≥n:**
- Beat scheduler arranca y programa tareas
- Tarea se ejecuta en horario configurado
- Nuevos contenidos detectados y procesados

**Git:**
```bash
git commit -m "feat: add Celery Beat for scheduled tasks"
git commit -m "feat: add sync_sources periodic task"
```
**Nos da paso a:** Implementar monitoreo y observabilidad.

---

## üìä FASE 5: OBSERVABILIDAD (2 d√≠as)

### Paso 21: Logging Estructurado
**¬øQu√© hacer?**
- Configurar **structlog** para logs estructurados
- Logs en formato JSON con campos: timestamp, level, message, context
- Diferentes niveles por entorno: DEBUG en dev, INFO en prod
- Logs de cada servicio identificados claramente
- Rotar logs diariamente, mantener √∫ltimos 7 d√≠as

**¬øPor qu√© logging estructurado?**
- Debuggear producci√≥n sin logs = adivinar
- JSON logs = f√°cil de parsear con herramientas (Loki, ELK)
- Context enriquecido (source_id, duration, etc.) ayuda a troubleshooting

**Validaci√≥n:**
- Logs generados en formato JSON v√°lido
- Diferentes servicios loggean correctamente
- Rotaci√≥n funciona (archivos por d√≠a)

**Git:**
```bash
git commit -m "feat: add structured logging with structlog"
```
**Nos da paso a:** Agregar m√©tricas para monitoreo.

---

### Paso 22: M√©tricas (Prometheus)
**¬øQu√© hacer?**
- Instalar `prometheus-client` para Python
- Exponer endpoint `/metrics` en FastAPI
- M√©tricas custom:
  - `summaries_generated_total` (contador)
  - `transcription_duration_seconds` (histograma)
  - `deepseek_api_calls_total` (contador)
  - `pipeline_errors_total` (contador por tipo)
- Configurar scraping de Prometheus en `docker-compose.yml`

**¬øPor qu√© m√©tricas?**
- Detectar problemas antes que usuarios se quejen
- Graficar rendimiento en Grafana
- SLOs medibles (ej: 95% de transcripciones <10min)

**Validaci√≥n:**
- Endpoint `/metrics` expone m√©tricas en formato Prometheus
- Prometheus scrapea m√©tricas correctamente
- Valores se actualizan en tiempo real

**Git:**
```bash
git commit -m "feat: add Prometheus metrics instrumentation"
git commit -m "feat: add Prometheus to Docker Compose"
```
**Nos da paso a:** Visualizar m√©tricas en dashboard.

---

### Paso 23: Grafana Dashboard
**¬øQu√© hacer?**
- Agregar Grafana a `docker-compose.yml`
- Configurar datasource Prometheus
- Crear dashboard con paneles:
  - Res√∫menes generados (√∫ltimas 24h)
  - Duraci√≥n promedio de transcripci√≥n
  - Rate de errores del pipeline

**¬øPor qu√© Grafana?**
- Visualizaci√≥n clara de salud del sistema
- Alertas visuales (ej: errores >10% = panel rojo)
- Portfolio impresionante (no solo c√≥digo, tambi√©n ops)

**Validaci√≥n:**
- Dashboard accesible en `localhost:3000`
- Paneles muestran datos reales
- Gr√°ficos se actualizan autom√°ticamente

**Git:**
```bash
git commit -m "feat: add Grafana dashboard for system metrics"
```
**Nos da paso a:** Implementar suite de tests completa.

---

## ‚úÖ FASE 6: TESTING & CI/CD (2 d√≠as)

### Paso 24: Suite de Tests Completa
**¬øQu√© hacer?**
- Tests unitarios en `tests/unit/` para servicios y repositories
- Tests de integraci√≥n en `tests/integration/` para API y BD
- Tests E2E en `tests/e2e/` para pipeline completo
- Configurar fixtures pytest para datos de prueba
- Objetivo: >80% de cobertura en l√≥gica cr√≠tica

**¬øPor qu√© cobertura alta?**
- Sin tests, cada cambio es ruleta rusa
- Tests = confianza para refactorizar
- Coverage >80% = se√±al de calidad profesional

**Validaci√≥n:**
- `pytest tests/ -v` todos los tests pasan
- `pytest --cov=src` muestra cobertura >80%
- Tests r√°pidos (<2 min total)

**Git:**
```bash
git commit -m "test: add comprehensive test suite with >80% coverage"
```
**Nos da paso a:** Automatizar tests con CI.

---

### Paso 25: GitHub Actions (CI/CD)
**¬øQu√© hacer?**
- Crear `.github/workflows/test.yml`:
  - Trigger en `push` y `pull_request`
  - Setup Python 3.11 + Poetry
  - Levantar Postgres y Redis con `services`
  - Ejecutar `pytest` con coverage
  - Fallar si coverage <80%
- Crear `.github/workflows/lint.yml`:
  - Black, ruff, mypy
  - Fallar si hay errores de formato o tipado

**¬øPor qu√© CI automatizado?**
- Previene merges que rompen tests
- Code review autom√°tico de formato
- Badge verde en README = proyecto mantenido

**Validaci√≥n:**
- Push a rama trigger workflows
- Workflows pasan con c√≥digo actual
- Badge en README muestra estado

**Git:**
```bash
git commit -m "ci: add GitHub Actions for tests and linting"
```
**Nos da paso a:** Preparar deployment a producci√≥n.

---

## üöÄ FASE 7: DEPLOYMENT (2-3 d√≠as)

### Paso 26: Dockerfile Optimizado
**¬øQu√© hacer?**
- Crear Dockerfile multi-stage (builder + runtime)
- Stage 1: Instalar dependencias con Poetry
- Stage 2: Copiar solo lo necesario (sin dev dependencies)
- Usuario no-root por seguridad
- Health check integrado en container

**¬øPor qu√© multi-stage?**
- Imagen final m√°s peque√±a (500MB vs 2GB)
- Menos superficie de ataque (sin compiladores)
- Build cache eficiente

**Validaci√≥n:**
- `docker build -t ia-monitor .` exitoso
- `docker run ia-monitor` arranca correctamente
- Imagen <600MB

**Git:**
```bash
git commit -m "feat: add optimized multi-stage Dockerfile"
```
**Nos da paso a:** Orquestar todos los servicios.

---

### Paso 27: Docker Compose Producci√≥n
**¬øQu√© hacer?**
- Crear `docker-compose.prod.yml` con todos los servicios:
  - API (FastAPI)
  - Worker (Celery worker)
  - Beat (Celery scheduler)
  - Postgres (con volumen persistente)
  - Redis
  - Prometheus
  - Grafana
- Configurar restart policies
- L√≠mites de recursos (CPU, RAM)

**¬øPor qu√© separar dev y prod?**
- Dev usa hot-reload, prod no
- Prod tiene health checks y limits
- Prod usa secretos desde variables, no `.env`

**Validaci√≥n:**
- `docker-compose -f docker-compose.prod.yml up -d` levanta todo
- Todos los servicios saludables
- API accesible desde fuera del container

**Git:**
```bash
git commit -m "feat: add production Docker Compose configuration"
```
**Nos da paso a:** Scripts de deployment.

---

### Paso 28: Scripts de Deployment
**¬øQu√© hacer?**
- Crear `scripts/deploy.sh` que:
  - Pull √∫ltimos cambios de Git
  - Build nueva imagen Docker
  - Stop containers antiguos
  - Start nuevos containers
  - Health check post-deployment
  - Rollback autom√°tico si falla
- Crear `scripts/backup_db.sh` para backups autom√°ticos
- Configurar `cron` job para backups diarios

**¬øPor qu√© scripts?**
- Deployment manual = errores humanos
- Scripts = reproducible y documentado
- Rollback autom√°tico = recovery r√°pido

**Validaci√≥n:**
- Script ejecuta sin errores
- Deployment se completa en <5 minutos
- Rollback funciona si se simula error

**Git:**
```bash
git commit -m "feat: add deployment and backup scripts"
```
**Nos da paso a:** Automatizar deployment.

---

### Paso 29: CD Autom√°tico (GitHub Actions)
**¬øQu√© hacer?**
- Crear `.github/workflows/deploy.yml`:
  - Trigger solo en push a `main`
  - Ejecutar despu√©s de tests exitosos
  - SSH a servidor de producci√≥n
  - Ejecutar script de deployment
  - Notificar en Slack/Discord si falla

**¬øPor qu√© CD?**
- Push a main = deployment autom√°tico
- Sin intervenci√≥n manual
- Faster time to production

**Validaci√≥n:**
- Merge a `main` trigger deployment
- Cambios visibles en producci√≥n en <10 minutos
- Notificaci√≥n recibida

**Git:**
```bash
git commit -m "ci: add continuous deployment workflow"
```
**Nos da paso a:** Documentaci√≥n final.

---

### Paso 30: Documentaci√≥n Final
**¬øQu√© hacer?**
- README completo con:
  - Descripci√≥n del proyecto y valor
  - Arquitectura (diagrama)
  - Instalaci√≥n local paso a paso
  - Endpoints API documentados
  - Decisiones t√©cnicas importantes (links a ADRs)
  - Badges (CI status, coverage, license)
- Actualizar `docs/ADR/` con decisiones finales
- Screenshots de Grafana dashboard
- Video demo de 2 minutos (opcional pero impresionante)

**¬øPor qu√© documentaci√≥n curada?**
- Onboarding de recruiters en <5 minutos
- Proyecto sin docs = proyecto amateur
- ADRs demuestran pensamiento arquitect√≥nico

**Git:**
```bash
git commit -m "docs: complete README with architecture and setup guide"
git commit -m "docs: finalize ADRs for key technical decisions"
```

---

## üìÖ TIMELINE SEMANAL

### ‚úÖ Semana 1: Fundaci√≥n (COMPLETADA)
- **Lunes:** Architecture doc + Git setup + Poetry ‚úÖ
- **Martes:** Docker Compose + Config + FastAPI base ‚úÖ
- **Mi√©rcoles:** ORM + Migraciones + Source model ‚úÖ
- **Jueves:** DeepSeek integration + Tests ‚úÖ
- **Viernes:** Downloader service + Whisper setup ‚úÖ

### ‚úÖ Semana 2: Pipeline Completo + Modelos (COMPLETADA)
- **Lunes:** Transcription service + Pipeline orchestrator ‚úÖ
- **Martes:** Modelos BD completos (Video, Transcription, Summary, TelegramUser) ‚úÖ
- **Mi√©rcoles:** Repository Pattern completo (Base + 5 especializados) ‚úÖ
- **Jueves:** Servicios de negocio (VideoProcessingService) ‚úÖ
- **Viernes:** Schemas Pydantic v2 + API base ‚úÖ

### ‚úÖ Semana 3: API REST Completa (COMPLETADA)
- **Lunes:** Endpoints Videos (10 endpoints CRUD + processing) ‚úÖ
- **Martes:** Endpoints Transcriptions y Summaries (6 endpoints) ‚úÖ
- **Mi√©rcoles:** Endpoints Stats (2 endpoints) + Exception handlers ‚úÖ
- **Jueves:** OpenAPI metadata + Tests API ‚úÖ
- **Viernes:** Refinamiento y documentaci√≥n API ‚úÖ

### üìç Semana 4: Bot Telegram Multi-Usuario (EN PROGRESO)
- **Lunes:** Bot - Setup b√°sico + /start + /help ‚úÖ
- **Martes:** Bot - Suscripciones interactivas con inline keyboards ‚Üê üìç AQU√ç ESTAMOS
- **Mi√©rcoles:** Bot - Historial y b√∫squeda (/recent, /search)
- **Jueves:** Worker de distribuci√≥n personalizada (ADR-010)
- **Viernes:** Logging estructurado

### Semana 5: Observabilidad & Testing
- **Lunes:** M√©tricas Prometheus + Monitoreo de costos DeepSeek
- **Martes:** Dashboard Grafana completo
- **Mi√©rcoles:** Suite de tests completa (>80% coverage)
- **Jueves:** CI con GitHub Actions
- **Viernes:** Dockerfile optimizado

### Semana 6: Deployment & Docs
- **Lunes:** Dockerfile + Docker Compose prod
- **Martes:** Scripts de deployment + Backups
- **Mi√©rcoles:** CD autom√°tico + Validaci√≥n
- **Jueves:** Documentaci√≥n final + ADRs
- **Viernes:** Optimizaciones + Demo video

**Total:** ~5 semanas trabajando 3-4h/d√≠a
---

## ‚úÖ REGLAS DE ORO

### 1. Commits Peque√±os y Descriptivos
- ‚ùå `git commit -m "todo listo"`
- ‚úÖ `git commit -m "feat(api): add summaries endpoint with pagination"`

### 2. Tests ANTES de Merge
- Cada feature debe tener tests antes de merge a main
- Coverage nunca debe bajar del 80%

### 3. Documentaci√≥n Sincronizada
- README siempre actualizado con features nuevas
- ADRs para decisiones importantes

### 4. Branch Strategy
```text
main              ‚Üê Solo c√≥digo funcional + tests
  ‚îú‚îÄ feat/Deepseek-integration
  ‚îú‚îÄ feat/whisper-transcription
  ‚îî‚îÄ feat/celery-workers
```

### 5. Validaci√≥n Paso a Paso
- No avanzar al siguiente paso sin validar el actual
- "Funciona en mi m√°quina" no es suficiente (Docker soluciona esto)

---

¬°√âxito con el proyecto! üöÄ
