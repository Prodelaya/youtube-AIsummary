# ARQUITECTURA - IA MONITOR

**Version:** 1.0
**Fecha:** Octubre 2025
**Autor:** Prodelaya

---

## RESUMEN EJECUTIVO

**Proyecto:** Agregador inteligente de contenido sobre IA en desarrollo software con bot de Telegram multi-usuario
**Objetivo dual:**
- **Utilidad real:** Bot de Telegram interactivo donde cada usuario elige sus canales
- **Portfolio profesional:** Demostrar backend Python moderno con IA funcional y arquitectura multi-usuario

**Stack core:** FastAPI + PostgreSQL + Redis + Celery + Whisper (local) + DeepSeek API + Telegram Bot (python-telegram-bot)
**Deployment:** Servidor local HP EliteDesk 800 G2 con Cloudflare Tunnel
**Presupuesto:** $0 (todo gratuito/local)
**Usuarios:** Multi-usuario con preferencias individuales de suscripci√≥n a canales

---

## INDICE

1. [Infraestructura](#infraestructura)
2. [Stack Tecnologico](#stack-tecnologico)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [Flujos de Procesamiento](#flujos-de-procesamiento)
5. [Modelo de Datos](#modelo-de-datos)
6. [Estructura de Directorios](#estructura-de-directorios)
7. [Plan de Escalabilidad](#plan-de-escalabilidad)
8. [ADRs (Decisiones Arquitectonicas)](#adrs)

---

## INFRAESTRUCTURA

### Servidor: HP EliteDesk 800 G2 DM

| Componente         | Especificacion                           | Estado       | Notas                                |
| ------------------ | ---------------------------------------- | ------------ | ------------------------------------ |
| **CPU**            | Intel Core i5-6500T (4c/4t, 2.5-3.1 GHz) | ‚úÖ Suficiente | Adecuado para Whisper base           |
| **RAM**            | 8 GB DDR4 2133 MHz                       | ‚ö†Ô∏è Ajustado   | Ampliable a 32GB (~$40)              |
| **Storage**        | 256 GB NVMe SSD Samsung                  | ‚úÖ Suficiente | ~10GB proyecto + ~50GB videos temp   |
| **SO**             | Ubuntu 24.04 LTS x86-64                  | ‚úÖ Ideal      | Mismo stack que desarrollo           |
| **Red**            | Cloudflare Tunnel configurado            | ‚úÖ Operativo  | Exposicion web segura sin IP publica |
| **Disponibilidad** | 24/7 siempre encendido                   | ‚úÖ OK         | Necesario para jobs programados      |

**Veredicto:** Servidor VIABLE para MVP. Path de upgrade economico disponible.

### Capacidad de procesamiento estimada

**Carga de trabajo esperada:**
- Volumen: 5-20 videos/dia
- Duracion promedio: 10-30 minutos
- Total diario: 100-400 minutos de audio

**Rendimiento Whisper base (sin GPU):**
- Velocidad: ~2x tiempo real
- 20 videos de 20 min = 400 min audio = ~13 horas procesamiento
- Procesamiento nocturno: 22:00 - 08:00 (10 horas disponibles)

**Conclusion:** Capacidad suficiente para volumen esperado. Picos requieren cola.

---

## STACK TECNOLOGICO

### 1. Backend: FastAPI

**Comparativa de frameworks:**

| Aspecto               | FastAPI                  | Flask                  | Django         |
| --------------------- | ------------------------ | ---------------------- | -------------- |
| **Performance**       | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Async nativo       | ‚≠ê‚≠ê‚≠ê WSGI sync          | ‚≠ê‚≠ê‚≠ê WSGI sync  |
| **Documentacion API** | ‚úÖ Auto (Swagger/OpenAPI) | ‚ùå Manual               | ‚≠ê DRF          |
| **Curva aprendizaje** | ‚≠ê‚≠ê‚≠ê‚≠ê Similar a Flask     | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy simple       | ‚≠ê‚≠ê Complejo    |
| **Validacion datos**  | ‚úÖ Pydantic integrado     | ‚ùå Requires marshmallow | ‚úÖ Django Forms |
| **Ecosistema async**  | ‚úÖ Nativo                 | ‚ö†Ô∏è Via extensiones      | ‚ö†Ô∏è Desde 3.1+   |
| **Peso**              | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Ligero             | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Minimo           | ‚≠ê‚≠ê Pesado      |

**Decision:** FastAPI
- ‚úÖ Async nativo (necesario para I/O intensivo: descargas, transcripciones, APIs)
- ‚úÖ Documentacion automatica (portfolio profesional)
- ‚úÖ Validacion con Pydantic (menos bugs)
- ‚úÖ Performance superior (importante para API publica)

### 2. Database: PostgreSQL

**Comparativa de bases de datos:**

| Aspecto                | PostgreSQL        | MySQL          | MongoDB          | SQLite        |
| ---------------------- | ----------------- | -------------- | ---------------- | ------------- |
| **Transacciones ACID** | ‚úÖ Completas       | ‚úÖ Completas    | ‚ö†Ô∏è Limitadas      | ‚úÖ Basicas     |
| **JSON nativo**        | ‚úÖ JSONB indexable | ‚≠ê JSON basico  | ‚úÖ Nativo         | ‚ùå No          |
| **Full-text search**   | ‚úÖ Potente         | ‚≠ê Basico       | ‚≠ê Via Atlas      | ‚ùå Limitado    |
| **Concurrencia**       | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê MVCC        | ‚≠ê‚≠ê‚≠ê‚≠ê Row-level | ‚≠ê‚≠ê‚≠ê‚≠ê Document    | ‚≠ê‚≠ê File-level |
| **Escalabilidad**      | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente    | ‚≠ê‚≠ê‚≠ê‚≠ê Buena     | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Horizontal | ‚≠ê Local only  |
| **Recursos (8GB RAM)** | ‚≠ê‚≠ê‚≠ê‚≠ê ~500MB       | ‚≠ê‚≠ê‚≠ê‚≠ê ~400MB    | ‚≠ê‚≠ê‚≠ê ~800MB       | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ~50MB   |

**Decision:** PostgreSQL
- ‚úÖ JSONB para metadatos flexibles (transcripciones, API responses)
- ‚úÖ Full-text search para busqueda en resumenes
- ‚úÖ Relaciones complejas (sources ‚Üí videos ‚Üí transcriptions ‚Üí summaries)
- ‚úÖ Experiencia previa del desarrollador
- ‚úÖ Production-ready para futuro escalado

### 3. Cache: Redis

**Comparativa de sistemas de cache:**

| Aspecto               | Redis                 | Memcached  | Local (dict)    |
| --------------------- | --------------------- | ---------- | --------------- |
| **Persistencia**      | ‚úÖ Opcional            | ‚ùå No       | ‚ùå RAM volatil   |
| **Estructuras datos** | ‚úÖ Lists, Sets, Hashes | ‚ùå Solo K-V | ‚≠ê Python nativo |
| **Pub/Sub**           | ‚úÖ Si                  | ‚ùå No       | ‚ùå No            |
| **Broker Celery**     | ‚úÖ Nativo              | ‚ùå No       | ‚ùå No            |
| **Recursos**          | ~100MB                | ~50MB      | ~0MB            |

**Decision:** Redis
- ‚úÖ Doble proposito: cache + broker Celery (un servicio, dos funciones)
- ‚úÖ Cache de metadatos de videos
- ‚úÖ Pub/Sub para notificaciones en tiempo real (futuro)

### 4. Task Queue: Celery

**Comparativa de sistemas async:**

| Aspecto               | Celery                | FastAPI BackgroundTasks | RQ               | Dramatiq             |
| --------------------- | --------------------- | ----------------------- | ---------------- | -------------------- |
| **Complejidad setup** | ‚≠ê‚≠ê‚≠ê Media             | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Cero              | ‚≠ê‚≠ê‚≠ê‚≠ê Simple      | ‚≠ê‚≠ê‚≠ê Media            |
| **Scheduling**        | ‚úÖ Celery Beat         | ‚ùå Requires APScheduler  | ‚ùå Requires extra | ‚úÖ Si                 |
| **Monitoring**        | ‚úÖ Flower              | ‚ùå Manual                | ‚≠ê RQ Dashboard   | ‚≠ê Dramatiq Dashboard |
| **Reintentos**        | ‚úÖ Configurables       | ‚≠ê Manual                | ‚úÖ Si             | ‚úÖ Si                 |
| **Larga duracion**    | ‚úÖ Ideal               | ‚ùå No recomendado        | ‚úÖ Si             | ‚úÖ Si                 |
| **Maduro**            | ‚úÖ 2009, battle-tested | ‚úÖ Nativo FastAPI        | ‚≠ê 2011           | ‚≠ê 2016               |

**Decision:** Celery
- ‚úÖ Tareas largas (transcripcion 5-20 min por video)
- ‚úÖ Scheduling nativo (Celery Beat para scraping cada 6h)
- ‚úÖ Reintentos automaticos (APIs pueden fallar)
- ‚úÖ Monitoring con Flower (observabilidad)
- ‚úÖ Escalable (multiples workers en paralelo)

### 5. IA: Whisper (local) + DeepSeek API

**Comparativa transcripcion:**

| Servicio                  | Coste       | Precision | Velocidad     | Idiomas |
| ------------------------- | ----------- | --------- | ------------- | ------- |
| **Whisper base (local)**  | $0          | 85-90%    | 2x realtime   | 99      |
| **Whisper small (local)** | $0          | 90-95%    | 3x realtime   | 99      |
| AssemblyAI                | $0.006/min  | 95%+      | 0.2x realtime | 10+     |
| Deepgram                  | $0.0043/min | 95%+      | 0.1x realtime | 30+     |
| Google Speech-to-Text     | $0.006/min  | 95%+      | 0.3x realtime | 125     |

**Decision:** Whisper base (local)
- ‚úÖ $0 coste (requisito del proyecto)
- ‚úÖ Precision suficiente para resumenes (no necesitamos subtitulos perfectos)
- ‚úÖ Sin limites de uso
- ‚úÖ Privacidad (no enviamos audio a terceros)
- ‚ö†Ô∏è Consume ~1.5GB RAM (dentro del limite con 8GB)
- ‚ö†Ô∏è Lento pero aceptable (procesamiento nocturno)

**Comparativa resumenes:**

| Servicio              | Coste            | Limite     | Calidad         |
| --------------------- | ---------------- | ---------- | --------------- |
| **DeepSeek**          | $0.28/1M input   | Sin limite | ‚≠ê‚≠ê‚≠ê‚≠ê Buena      |
| OpenAI GPT-4          | $0.03/1K tokens  | Sin limite | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| Claude API            | $0.015/1K tokens | Sin limite | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| LangChain + local LLM | $0               | Ilimitado  | ‚≠ê‚≠ê‚≠ê Variable    |

**Decision:** DeepSeek API
- ‚úÖ Coste predecible: ~$0.16-0.45/mes para 300 videos
- ‚úÖ Sin limites artificiales de uso
- ‚úÖ Compatible con SDK OpenAI (facil integracion)
- ‚úÖ Context caching automatico (reduce costos 80%)
- ‚úÖ JSON output nativo (estructurado)

---

## ARQUITECTURA DEL SISTEMA

### Diagrama de componentes

```mermaid
graph TB
    subgraph "Usuarios Telegram"
        USER1[Usuario 1]
        USER2[Usuario 2]
        USERN[Usuario N]
    end

    subgraph "Bot Layer"
        TGBOT[Telegram Bot<br/>python-telegram-bot]
    end

    subgraph "API Layer"
        API[FastAPI API REST<br/>/users /sources /summaries]
    end

    subgraph "Application Layer"
        SERVICES[Services<br/>Business Logic]
        REPOS[Repositories<br/>Data Access]
    end

    subgraph "Data Layer"
        PG[(PostgreSQL<br/>Users + Subscriptions)]
        REDIS[(Redis<br/>Cache + Broker)]
    end

    subgraph "Worker Layer"
        WORKER1[Worker: Scraping<br/>+ Transcription]
        WORKER2[Worker: Summarization<br/>+ Distribution]
        BEAT[Celery Beat<br/>Scheduler 24h]
    end

    subgraph "External Services"
        YT[YouTube<br/>yt-dlp]
        DEEPSEEK[DeepSeek API<br/>Resumenes]
        WHISPER[Whisper Local<br/>Transcripcion]
    end

    USER1 -.->|/start /sources /recent| TGBOT
    USER2 -.->|Toggle suscripciones| TGBOT
    USERN -.->|/search| TGBOT

    TGBOT <-->|API interna| API
    API --> SERVICES
    SERVICES --> REPOS
    REPOS --> PG
    SERVICES --> REDIS

    BEAT -->|Cada 24h| REDIS
    REDIS --> WORKER1
    REDIS --> WORKER2

    WORKER1 --> YT
    WORKER1 --> WHISPER
    WORKER1 --> PG

    WORKER2 --> DEEPSEEK
    WORKER2 --> PG
    WORKER2 -.->|Envio personalizado| TGBOT

    style TGBOT fill:#0088cc
    style API fill:#4CAF50
    style PG fill:#336791
    style REDIS fill:#DC382D
    style WORKER1 fill:#37B24D
    style WORKER2 fill:#37B24D
    style WHISPER fill:#FF6B6B
    style DEEPSEEK fill:#1E88E5
```

### Descripcion de componentes

**1. Bot Layer (Telegram Bot)**
- Bot interactivo multi-usuario con python-telegram-bot
- Commands: /start, /sources, /recent, /search, /help
- Inline keyboards para toggle de suscripciones
- Env√≠o personalizado de res√∫menes seg√∫n preferencias de usuario
- Consumidor de API REST interna

**2. API Layer (FastAPI)**
- Endpoints REST para consultar resumenes filtrados por usuario
- Endpoints para gestionar fuentes (canales YouTube)
- Endpoints para gestionar usuarios y suscripciones
- Documentacion auto-generada (Swagger)
- CORS configurado para frontend (opcional futuro)

**3. Application Layer**
- **Services:** Logica de negocio (orquestacion de workers, validaciones, distribucion)
- **Repositories:** Abstraccion de acceso a datos (patron Repository)

**4. Data Layer**
- **PostgreSQL:** Datos estructurados (users, sources, videos, transcriptions, summaries, subscriptions)
- **Redis:** Cache de metadatos + broker de Celery + rate limiting

**5. Worker Layer**
- **Worker 1:** Scraping canales, descarga audio, transcripcion con Whisper
- **Worker 2:** Resumenes con DeepSeek, distribucion personalizada a usuarios suscritos
- **Celery Beat:** Scheduler para scraping periodico (cada 24h)

**6. External Services**
- **YouTube:** API + yt-dlp para obtener metadatos y descargar audio
- **Whisper:** Modelo local para transcripcion
- **DeepSeek:** LLM API para generar resumenes

---

## FLUJOS DE PROCESAMIENTO

### Flujo 1: Registro de nueva fuente (manual)

```mermaid
sequenceDiagram
    participant U as Usuario
    participant API as FastAPI
    participant DB as PostgreSQL

    U->>API: POST /api/v1/sources<br/>{channel_url, name}
    API->>API: Validar URL YouTube
    API->>DB: INSERT INTO sources
    DB-->>API: source_id
    API-->>U: 201 Created {source_id}
```

### Flujo 2: Scraping periodico (automatico)

```mermaid
sequenceDiagram
    participant BEAT as Celery Beat
    participant REDIS as Redis Queue
    participant W1 as Worker 1
    participant YT as YouTube
    participant DB as PostgreSQL

    BEAT->>REDIS: Encolar "sync_sources_task"<br/>(cada 6 horas)
    REDIS->>W1: Ejecutar tarea
    W1->>DB: SELECT * FROM sources WHERE active=true

    loop Para cada fuente
        W1->>YT: yt-dlp --get-json <channel_url>
        YT-->>W1: JSON metadata (ultimos 10 videos)

        W1->>DB: SELECT video_id FROM videos<br/>WHERE source_id AND youtube_id

        alt Video nuevo (no existe)
            W1->>DB: INSERT INTO videos<br/>(youtube_id, title, url, duration, published_at)
            W1->>REDIS: Encolar "process_video_task"<br/>(video_id)
        else Video ya existe
            W1->>W1: Skip (ya procesado)
        end
    end
```

### Flujo 3: Procesamiento de video (async)

```mermaid
sequenceDiagram
    participant REDIS as Redis Queue
    participant W1 as Worker 1
    participant YT as YouTube
    participant WHISPER as Whisper
    participant W2 as Worker 2
    participant DEEPSEEK as DeepSeek API
    participant DB as PostgreSQL

    REDIS->>W1: process_video_task(video_id)
    W1->>DB: SELECT * FROM videos WHERE id=video_id

    Note over W1: FASE 1: Descarga audio
    W1->>YT: yt-dlp -x --audio-format mp3 <video_url>
    YT-->>W1: audio.mp3
    W1->>DB: UPDATE videos SET status='downloaded'

    Note over W1: FASE 2: Transcripcion
    W1->>WHISPER: transcribe(audio.mp3, model='base')
    WHISPER-->>W1: {text, language, segments}
    W1->>DB: INSERT INTO transcriptions<br/>(video_id, text, language, model='whisper-base')
    W1->>W1: Eliminar audio.mp3 (liberar espacio)
    W1->>DB: UPDATE videos SET status='transcribed'

    Note over W1: FASE 3: Encolar resumen
    W1->>REDIS: Encolar "summarize_task"<br/>(transcription_id)

    REDIS->>W2: summarize_task(transcription_id)
    W2->>DB: SELECT text FROM transcriptions WHERE id

    Note over W2: FASE 4: Generar resumen
    W2->>DEEPSEEK: POST /chat/completions<br/>{messages: [transcription]}
    DEEPSEEK-->>W2: {summary, keywords, cost}
    W2->>DB: INSERT INTO summaries<br/>(transcription_id, summary, keywords)
    W2->>DB: UPDATE videos SET status='completed'
```

### Flujo 4: Consulta API (usuario)

```mermaid
sequenceDiagram
    participant U as Usuario
    participant API as FastAPI
    participant REDIS as Redis Cache
    participant DB as PostgreSQL

    U->>API: GET /api/v1/summaries?limit=20&offset=0
    API->>REDIS: GET summaries:page:0

    alt Cache hit
        REDIS-->>API: Cached data
        API-->>U: 200 OK [summaries]
    else Cache miss
        API->>DB: SELECT s.*, v.title, v.url<br/>FROM summaries s<br/>JOIN videos v ON s.video_id=v.id<br/>ORDER BY v.published_at DESC<br/>LIMIT 20
        DB-->>API: [summaries]
        API->>REDIS: SET summaries:page:0<br/>EXPIRE 300 (5 min)
        API-->>U: 200 OK [summaries]
    end
```

---

## MODELO DE DATOS

### Diagrama ER

```mermaid
erDiagram
    TELEGRAM_USERS ||--o{ USER_SOURCE_SUBSCRIPTIONS : subscribes
    SOURCES ||--o{ USER_SOURCE_SUBSCRIPTIONS : has_subscribers
    SOURCES ||--o{ VIDEOS : has
    VIDEOS ||--o| TRANSCRIPTIONS : has
    TRANSCRIPTIONS ||--o| SUMMARIES : has
    VIDEOS ||--o{ TAGS : has

    TELEGRAM_USERS {
        uuid id PK
        bigint telegram_id UK
        string username
        string first_name
        boolean active
        timestamp created_at
        timestamp updated_at
    }

    USER_SOURCE_SUBSCRIPTIONS {
        uuid user_id FK
        uuid source_id FK
        timestamp subscribed_at
    }

    SOURCES {
        uuid id PK
        string name
        string url
        string source_type
        boolean active
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }

    VIDEOS {
        uuid id PK
        uuid source_id FK
        string youtube_id UK
        string title
        string url
        integer duration_seconds
        string status
        timestamp published_at
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }

    TRANSCRIPTIONS {
        uuid id PK
        uuid video_id FK
        text transcription
        string language
        string model_used
        jsonb segments
        timestamp created_at
    }

    SUMMARIES {
        uuid id PK
        uuid transcription_id FK
        text summary
        string[] keywords
        string category
        boolean sent_to_telegram
        timestamp sent_at
        jsonb telegram_message_ids
        jsonb metadata
        timestamp created_at
    }

    TAGS {
        uuid id PK
        string name UK
        string category
    }
```

### Descripcion de tablas

**1. telegram_users**
- Usuarios del bot de Telegram (multi-usuario)
- `telegram_id`: ID √∫nico de Telegram (bigint, indexado)
- `username`: @username de Telegram (opcional)
- `first_name`: Nombre del usuario en Telegram
- `active`: Si el usuario tiene notificaciones activas (puede pausar)
- **Relaci√≥n M:N con sources** via user_source_subscriptions

**2. user_source_subscriptions**
- Tabla intermedia para relaci√≥n M:N (usuarios ‚Üî sources)
- Cada usuario puede suscribirse a m√∫ltiples canales
- Cada canal puede tener m√∫ltiples suscriptores
- `subscribed_at`: Timestamp de cu√°ndo se suscribi√≥

**3. sources**
- Fuentes de contenido (canales YouTube)
- `source_type`: 'youtube' (futuro: 'rss', 'podcast')
- `active`: Permite desactivar fuentes sin borrarlas
- `metadata`: Datos extra (subscriber_count, thumbnail_url, etc.)

**4. videos**
- Videos individuales obtenidos de las fuentes
- `youtube_id`: ID unico de YouTube (para evitar duplicados)
- `title`: T√≠tulo del video (para mostrar en Telegram)
- `url`: Link directo al video de YouTube (para enviar en mensajes)
- `status`: 'pending' ‚Üí 'downloading' ‚Üí 'downloaded' ‚Üí 'transcribing' ‚Üí 'transcribed' ‚Üí 'summarizing' ‚Üí 'completed' | 'failed'
- `duration_seconds`: Para estimar tiempo de procesamiento
- `metadata`: Datos extra (view_count, like_count, thumbnail_url, etc.)

**5. transcriptions**
- Transcripciones generadas por Whisper
- `model_used`: 'whisper-base' | 'whisper-small' (para tracking)
- `segments`: JSON con timestamps (futuro: busqueda temporal)

**6. summaries**
- Resumenes generados por DeepSeek
- `keywords`: Array de palabras clave extraidas
- `category`: 'framework' | 'language' | 'tool' | 'concept'
- `sent_to_telegram`: Flag de si ya fue enviado
- `sent_at`: Timestamp de env√≠o a Telegram
- `telegram_message_ids`: JSON mapeando user_id ‚Üí message_id (para reenv√≠os)
- `metadata`: Datos extra del API (tokens, cost, etc.)

**7. tags**
- Etiquetas para clasificacion (relacion N:M con videos)
- `category`: 'framework' | 'language' | 'tool' | 'concept'

### Indices principales

```sql
-- Telegram users (queries frecuentes)
CREATE UNIQUE INDEX idx_telegram_users_telegram_id ON telegram_users(telegram_id);
CREATE INDEX idx_telegram_users_active ON telegram_users(active);

-- Subscriptions (M:N queries)
CREATE INDEX idx_subscriptions_user_id ON user_source_subscriptions(user_id);
CREATE INDEX idx_subscriptions_source_id ON user_source_subscriptions(source_id);
CREATE UNIQUE INDEX idx_subscriptions_unique ON user_source_subscriptions(user_id, source_id);

-- Performance critico
CREATE INDEX idx_videos_source_id ON videos(source_id);
CREATE INDEX idx_videos_status ON videos(status);
CREATE INDEX idx_videos_published_at ON videos(published_at DESC);
CREATE INDEX idx_transcriptions_video_id ON transcriptions(video_id);
CREATE INDEX idx_summaries_transcription_id ON summaries(transcription_id);
CREATE INDEX idx_summaries_sent_to_telegram ON summaries(sent_to_telegram);

-- Full-text search
CREATE INDEX idx_summaries_summary_fts ON summaries USING gin(to_tsvector('spanish', summary));
CREATE INDEX idx_videos_title_fts ON videos USING gin(to_tsvector('spanish', title));

-- Compound indexes para queries complejas
CREATE INDEX idx_videos_source_status ON videos(source_id, status);
CREATE INDEX idx_summaries_category ON summaries(category) WHERE category IS NOT NULL;
```

## ESTRUCTURA DE DIRECTORIOS

```
youtube-AIsummary/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml                  # Tests + linting
‚îÇ       ‚îî‚îÄ‚îÄ cd.yml                  # Deployment automatico
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md             # Este documento
‚îÇ   ‚îú‚îÄ‚îÄ api.md                      # Documentacion endpoints
‚îÇ   ‚îú‚îÄ‚îÄ deployment.md               # Guia de despliegue
‚îÇ   ‚îú‚îÄ‚îÄ ADR/                        # Architecture Decision Records
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001-fastapi-vs-flask.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002-whisper-local.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 003-apyhub-limit.md
‚îÇ   ‚îú‚îÄ‚îÄ contexting-prompts/         # Prompts de contexto
‚îÇ   ‚îî‚îÄ‚îÄ professional-prompts/       # Prompts de desarrollo
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/                        # FastAPI application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # App factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py         # DI containers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summaries.py        # GET /api/v1/summaries
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.py          # CRUD /api/v1/sources
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py           # GET /health
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas/                # Pydantic models
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ summary.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ source.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ common.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                       # Configuracion central
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Settings (Pydantic BaseSettings)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py             # SQLAlchemy engine + session
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ redis.py                # Redis connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py           # Celery instance
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging.py              # Logging config
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # SQLAlchemy ORM models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # Base model + mixins
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ source.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summary.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tag.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ repositories/               # Data access layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # Generic CRUD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ source_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription_repository.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_repository.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                   # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ youtube_service.py      # yt-dlp wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ whisper_service.py      # Transcription
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summarization_service.py # DeepSeek summarization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache_service.py        # Redis cache
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                      # Celery tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sync_sources.py         # Scraping periodico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ process_video.py        # Pipeline completo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcribe.py           # Whisper task
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summarize.py            # DeepSeek task
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                      # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ validators.py           # Validaciones custom
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                 # Fixtures pytest
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_services.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_repositories.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_tasks.py
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ       ‚îî‚îÄ‚îÄ test_full_pipeline.py
‚îÇ
‚îú‚îÄ‚îÄ migrations/                     # Alembic migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îî‚îÄ‚îÄ env.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_dev.sh                # Setup entorno desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                   # Deployment produccion
‚îÇ   ‚îú‚îÄ‚îÄ backup_db.sh                # Backup PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ seed_data.py                # Datos de prueba
‚îÇ
‚îú‚îÄ‚îÄ .env                            # Variables entorno (NO commitear)
‚îú‚îÄ‚îÄ .env.example                    # Template variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ pyproject.toml                  # Poetry dependencies
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ docker-compose.yml              # Dev environment
‚îú‚îÄ‚îÄ docker-compose.prod.yml         # Production
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ alembic.ini                     # Config migraciones
```

---

## PLAN DE ESCALABILIDAD

### Etapa 1: MVP (actual - 8GB RAM)

**Capacidad:**
- 5-10 videos/dia
- Whisper base (1.5GB RAM)
- Procesamiento secuencial

**Limitaciones:**
- RAM ajustada (~6.8GB disponible)
- CPU al 100% durante transcripcion
- Sin redundancia

**Cuando escalar:** >10 videos/dia consistente O RAM >90%

---

### Etapa 2: Upgrade RAM (8GB ‚Üí 16GB) [~$40]

**Mejoras:**
- ‚úÖ Whisper small (mejor precision 90-95%)
- ‚úÖ 2 workers Celery en paralelo
- ‚úÖ Capacidad: 15-20 videos/dia
- ‚úÖ PostgreSQL con mas buffer pool

**Trigger:** Volumen >10 videos/dia por 1 semana

---

### Etapa 3: Upgrade RAM (16GB ‚Üí 32GB) [~$80 total]

**Mejoras:**
- ‚úÖ Whisper medium (precision 95%+)
- ‚úÖ 4 workers Celery en paralelo
- ‚úÖ Capacidad: 30-50 videos/dia
- ‚úÖ Cache Redis mas grande

**Trigger:** Volumen >20 videos/dia por 1 semana

---

### Etapa 4: Arquitectura hibrida (Servidor + Oracle Cloud)

**Cuando:** >50 videos/dia O CPU saturada constantemente

**Distribucion:**
```
Servidor Local (HP EliteDesk):
- FastAPI (API REST)
- PostgreSQL (base de datos)
- Redis (cache + broker)
- Celery Beat (scheduler)
- Celery Worker (resumenes ApyHub)

Oracle Cloud Always Free (4 OCPUs ARM + 24GB):
- Celery Worker dedicado (transcripciones Whisper)
- Whisper large model (precision 98%+)
- Procesamiento 4x mas rapido (ARM optimizado)
```

**Ventajas:**
- ‚úÖ Separa I/O (servidor) de CPU intensivo (cloud)
- ‚úÖ $0 coste (Oracle Always Free)
- ‚úÖ Capacidad: 100+ videos/dia

**Complejidad:** +2 semanas setup (VPN, queue distribuida, monitoring)

---

### Etapa 5: Cloud completo (si crece mucho)

**Solo si:** >200 videos/dia O necesitas SLA 99.9%

**Stack:**
- Hetzner VPS (~$10/mes, 4 vCPUs + 8GB)
- Managed PostgreSQL (~$15/mes)
- Autoscaling workers (Kubernetes)

**No recomendado a corto plazo:** Overkill para caso de uso actual

---

## ADRS (DECISIONES ARQUITECTONICAS)

### ADR-001: FastAPI vs Flask

**Contexto:**
Necesitamos un framework web para exponer API REST. Opciones: FastAPI, Flask, Django.

**Decision:** FastAPI

**Razon:**
- Async nativo (I/O bound: descargas, APIs externas)
- Documentacion auto-generada (portfolio profesional)
- Validacion Pydantic (menos bugs, mejor DX)
- Performance superior (benchmarks: 2-3x Flask)

**Consecuencias:**
- ‚úÖ Codigo mas mantenible
- ‚úÖ Testing mas facil (TestClient integrado)
- ‚ö†Ô∏è Curva aprendizaje async/await (mitigado: similar a Flask)

---

### ADR-002: Whisper local vs APIs pago

**Contexto:**
Necesitamos transcribir audio de videos. Opciones: Whisper local, AssemblyAI, Deepgram.

**Decision:** Whisper base (local)

**Razon:**
- $0 coste (requisito del proyecto)
- Precision suficiente para resumenes (85-90%)
- Sin limites de uso
- Privacidad (no enviamos audio a terceros)

**Trade-offs:**
- ‚úÖ Coste: $0 vs $2.40/dia (400 min √ó $0.006/min)
- ‚ö†Ô∏è Velocidad: 2x realtime vs 0.2x realtime (10x mas lento)
- ‚ö†Ô∏è RAM: 1.5GB vs 0GB
- ‚úÖ Precision: 85-90% vs 95%+ (suficiente para caso de uso)

**Consecuencias:**
- ‚úÖ Proyecto viable con presupuesto $0
- ‚ö†Ô∏è Procesamiento nocturno requerido (no real-time)
- üìã Path de migracion: Si crece, usar AssemblyAI o Whisper large en Oracle Cloud

---

### ADR-003: Sistema de res√∫menes con DeepSeek (hist√≥rico)

**Contexto hist√≥rico:**
Originalmente se evalu√≥ ApyHub API (l√≠mite 5 llamadas/d√≠a) pero result√≥ insuficiente para volumen esperado (10 videos/d√≠a).

**Decisi√≥n final:** Migrar a DeepSeek API (ADR-009)
- DeepSeek: $0.28/1M tokens, sin l√≠mites artificiales
- Presupuesto: $10 (suficiente para ~2-5 a√±os)
- No requiere sistema de rate limiting complejo

**Alternativas descartadas:**
- ‚ùå ApyHub: Insuficiente (5 llamadas/d√≠a)
- ‚ùå OpenAI GPT-4o-mini: M√°s caro ($0.15/1M tokens)

**Consecuencias:**
- ‚úÖ Arquitectura simplificada (sin sistema de colas complejas)
- ‚úÖ Escalabilidad real sin bloqueantes
- ‚úÖ Ver ADR-009 para detalles de implementaci√≥n

---

### ADR-004: PostgreSQL vs MongoDB

**Contexto:**
Necesitamos persistir datos estructurados (sources, videos, summaries). Opciones: PostgreSQL, MongoDB.

**Decision:** PostgreSQL

**Razon:**
- Relaciones claras (source ‚Üí videos ‚Üí transcriptions ‚Üí summaries)
- JSONB para flexibilidad en metadatos
- Full-text search nativo (busqueda en resumenes)
- Transacciones ACID (importante para estado de procesamiento)
- Experiencia previa del desarrollador

**Consecuencias:**
- ‚úÖ Consultas relacionales eficientes
- ‚úÖ Migraciones con Alembic (cambios de schema controlados)
- ‚ö†Ô∏è Menos flexible que MongoDB (mitigado con JSONB)

---

### ADR-005: Celery vs FastAPI BackgroundTasks

**Contexto:**
Necesitamos procesar tareas pesadas en background. Opciones: Celery, BackgroundTasks, RQ.

**Decision:** Celery + Celery Beat

**Razon:**
- Tareas largas (transcripcion 5-20 min)
- Scheduling nativo (scraping cada 6h)
- Reintentos automaticos
- Monitoring con Flower
- Escalable (multiples workers)

**Trade-off:**
- ‚ö†Ô∏è Complejidad: Requiere Redis + worker process
- ‚úÖ Beneficio: Produccion-ready, battle-tested

**Consecuencias:**
- ‚úÖ API responde inmediato (no bloquea)
- ‚úÖ Jobs programados sin cron
- ‚ö†Ô∏è +1 dia setup inicial (mitigado: bien documentado)

---

### ADR-006: Cloudflare Tunnel vs Nginx + Certbot

**Contexto:**
Necesitamos exponer API al exterior. Servidor detras de NAT sin IP publica.

**Decision:** Cloudflare Tunnel (ya configurado)

**Razon:**
- ‚úÖ Ya operativo (sin cambios)
- ‚úÖ HTTPS automatico
- ‚úÖ Sin abrir puertos en router
- ‚úÖ DDoS protection gratis
- ‚úÖ Capa extra de seguridad (WAF)

**Consecuencias:**
- ‚úÖ Deployment simplificado
- ‚úÖ Monitoreo trafico en Cloudflare dashboard
- ‚ö†Ô∏è Dependencia externa (mitigado: Cloudflare SLA 99.99%)

---

### ADR-007: Deployment en servidor local vs Cloud

**Contexto:**
Donde desplegar el proyecto. Opciones: Servidor local, Oracle Cloud, Hetzner VPS.

**Decision:** Servidor local (HP EliteDesk)

**Razon:**
- ‚úÖ Hardware disponible (no requiere compra)
- ‚úÖ $0 coste operativo
- ‚úÖ 24/7 disponible
- ‚úÖ Suficiente para volumen esperado (5-20 videos/dia)
- ‚úÖ Path de escalado claro (RAM upgrade ‚Üí Oracle Cloud)

**Consecuencias:**
- ‚úÖ Proyecto arranca inmediatamente
- ‚úÖ Aprendizaje deployment real (Docker, systemd)
- ‚ö†Ô∏è Sin redundancia (mitigado: backups diarios)
- üìã Futuro: Arquitectura hibrida si volumen crece

---
# ADR-008: Conservar transcripciones indefinidamente en MVP

**Contexto:**
Las transcripciones son generadas por Whisper y consumidas por ApyHub para generar res√∫menes.
Necesitamos decidir si conservarlas o eliminarlas despu√©s del resumen.

**Decisi√≥n:** Conservar transcripciones indefinidamente

**Raz√≥n:**
- Costo de almacenamiento despreciable (~18MB/a√±o para 10 videos/d√≠a)
- √ötil para debugging si res√∫menes son de baja calidad
- Habilita features futuras (b√∫squeda full-text, an√°lisis temporal)
- Simplicidad: no requiere l√≥gica adicional de limpieza

**Trade-offs:**
- ‚úÖ Espacio: ~18MB/a√±o vs 0MB (diferencia insignificante)
- ‚úÖ Features: B√∫squeda en transcripciones vs solo res√∫menes
- ‚úÖ Implementaci√≥n: 0 l√≠neas c√≥digo vs tarea de limpieza

**Consecuencias:**
- ‚úÖ MVP m√°s simple
- ‚úÖ Flexibilidad para analytics avanzado
- ‚ö†Ô∏è Migrar a borrado autom√°tico si BD crece excesivamente (>50K videos)

**Path de migraci√≥n:**
Si en el futuro necesitamos optimizar espacio, implementar Estrategia 3
(borrado diferido con retenci√≥n de 30 d√≠as).

---

### ADR-009: Migraci√≥n de ApyHub a DeepSeek

**Contexto:**
ApyHub limita a 5 llamadas/d√≠a en plan gratuito. Volumen esperado: 10 videos/d√≠a (300/mes).

**Decisi√≥n:** DeepSeek API con modelo `deepseek-chat`

**Raz√≥n:**
- ApyHub insuficiente (5 llamadas vs 10 videos diarios)
- DeepSeek: $0.28/1M tokens input + $0.42/1M output
- Costo mensual: ~$0.16-0.45 (con context caching)
- Sin l√≠mites artificiales de uso
- Compatible OpenAI SDK (migraci√≥n simple)

**Trade-offs:**
- ‚úÖ Costo: $0.45/mes vs l√≠mite bloqueante
- ‚úÖ Escalabilidad: ilimitado vs 5/d√≠a
- ‚úÖ Simplicidad: API s√≠ncrona vs job polling
- ‚ö†Ô∏è Requiere sistema de prompts (LLM gen√©rico)

**Consecuencias:**
- ‚úÖ Proyecto viable para caso de uso real
- ‚úÖ C√≥digo m√°s simple (~150 l√≠neas vs ~480)
- ‚úÖ Context caching reduce costos 80% tras primer resumen
- üìã Implementar prompt engineering para calidad √≥ptima

**Alternativas descartadas:**
- ‚ùå Mantener ApyHub: Insuficiente para producci√≥n
- ‚ùå GPT-4o-mini: M√°s caro ($0.15/1M tokens)
- ‚ùå Claude API: M√°s caro ($0.015/1K tokens)

---

### ADR-010: Bot de Telegram interactivo vs Canal broadcast

**Contexto:**
Necesitamos distribuir res√∫menes a usuarios. Opciones: Canal Telegram unidireccional vs Bot interactivo multi-usuario.

**Decisi√≥n:** Bot interactivo multi-usuario con suscripciones personalizables

**Raz√≥n:**
- ‚úÖ Cada usuario elige sus canales de inter√©s (personalizaci√≥n)
- ‚úÖ Comandos interactivos (/recent, /search, /sources)
- ‚úÖ Inline keyboards para toggle de suscripciones (UX mejorada)
- ‚úÖ API REST justificada (backend del bot)
- ‚úÖ Multi-usuario real = portfolio profesional robusto
- ‚úÖ Escalable (1 usuario ‚Üí 100 usuarios sin cambios)
- ‚úÖ Hist√≥rico accesible bajo demanda

**Trade-offs:**
- ‚úÖ Funcionalidad: Multi-usuario vs broadcast simple
- ‚ö†Ô∏è Complejidad: +2 d√≠as desarrollo (modelo TelegramUser + endpoints)
- ‚ö†Ô∏è BD: +2 tablas (telegram_users, user_source_subscriptions)
- ‚úÖ UX: Interactivo vs pasivo (mejor experiencia usuario)

**Consecuencias:**
- ‚úÖ Proyecto √∫til para m√∫ltiples personas (no solo el desarrollador)
- ‚úÖ Arquitectura escalable y profesional
- ‚úÖ API REST con prop√≥sito claro (no "por si acaso")
- üìù Requiere bot commands completos + inline keyboards
- üìù Worker de distribuci√≥n personalizada por suscripciones

**Formato de mensajes Telegram:**
```
üìπ T√≠tulo: "FastAPI async mistakes you're making"
üîó Link: https://youtube.com/watch?v=abc123
‚è±Ô∏è Duraci√≥n: 15:32
üè∑Ô∏è Tags: #FastAPI #Python #async

üìù Resumen:
[Texto del resumen generado por DeepSeek]

üí¨ /reenviar_abc123
```

---

### ADR-011: Repositories s√≠ncronos vs as√≠ncronos

**Contexto:**
Necesitamos implementar Repository Pattern. Principal uso: Celery workers (s√≠ncronos), API REST (ocasional).

**Decisi√≥n:** Repositories S√çNCRONOS con `Session`

**Raz√≥n:**
- ‚úÖ Celery workers son 99% del uso de BD (s√≠ncronos por dise√±o)
- ‚úÖ API REST: <10 req/d√≠a (uso ocasional, no requiere async)
- ‚úÖ Implementaci√≥n m√°s simple y r√°pida (2 d√≠as vs 4 d√≠as)
- ‚úÖ SQLAlchemy ORM funciona mejor en modo sync
- ‚úÖ Tests m√°s simples (fixtures s√≠ncronos)
- ‚úÖ Sin migraci√≥n de `database.py` a `AsyncSession`
- ‚úÖ Menos riesgo de bugs (stack maduro)

**Trade-offs:**
- ‚úÖ Tiempo: 2 d√≠as vs 4 d√≠as async
- ‚úÖ Complejidad: Baja vs Alta
- ‚ö†Ô∏è Throughput: ~1000 req/s vs ~2000 req/s (irrelevante para <10 req/d√≠a)
- ‚úÖ Beneficio async: 0% para este caso de uso

**Consecuencias:**
- ‚úÖ Desarrollo r√°pido y sin complicaciones
- ‚úÖ Compatible con Celery workers existentes
- ‚úÖ API endpoints usan `def` en lugar de `async def` (aceptable)
- üìù Path de migraci√≥n: Si carga API crece a >500 req/s, migrar a async

**Ejemplo de uso:**
```python
# Worker Celery (principal uso)
@shared_task
def distribute_summary(summary_id: str):
    db = SessionLocal()
    try:
        summary_repo = SummaryRepository(db)
        user_repo = TelegramUserRepository(db)
        # ... l√≥gica
    finally:
        db.close()

# Endpoint API (uso ocasional)
@router.get("/summaries")
def get_summaries(db: Session = Depends(get_db)):
    repo = SummaryRepository(db)
    return repo.list_all(limit=20)
```

---

### ADR-012: Orquestador del Pipeline (VideoProcessingService)

**Contexto:**
Necesitamos coordinar el flujo completo: URL ‚Üí Metadata ‚Üí Download ‚Üí Transcribe ‚Üí Summarize ‚Üí Cleanup. Decisiones clave: arquitectura sync/async, gesti√≥n de estados, manejo de errores, persistencia incremental.

**Decisi√≥n:** Orquestador 100% async con commits intermedios y gesti√≥n inteligente de archivos

**Raz√≥n:**

**1. Arquitectura 100% Async (vs Sync o H√≠brida)**
- ‚úÖ Preparado para Celery async tasks (roadmap paso 15)
- ‚úÖ No bloquea event loop en FastAPI endpoints
- ‚úÖ Mejor performance con I/O intensivo (descarga, API calls)
- ‚úÖ Integraci√≥n natural con servicios async (DeepSeek API)
- ‚ö†Ô∏è Servicios sync (yt-dlp, Whisper) ya son async en capa de servicio

**2. Commits Intermedios (vs Transacci√≥n √∫nica)**
- ‚úÖ Preserva trabajo costoso (transcripci√≥n = 5-8 min)
- ‚úÖ Si falla resumen, transcripci√≥n queda guardada ‚Üí retry barato
- ‚úÖ Mejor observabilidad (estados intermedios visibles en BD)
- ‚ö†Ô∏è No es at√≥mico (puede quedar en estado intermedio si crash)
- ‚úÖ Trade-off aceptable: costo de re-transcripci√≥n >> inconsistencia

**3. M√°quina de Estados Completa**
```
pending ‚Üí downloading ‚Üí downloaded ‚Üí transcribing ‚Üí transcribed ‚Üí
summarizing ‚Üí completed

En cada paso puede ir a 'failed' si hay error
```
- ‚úÖ Estados granulares para debugging
- ‚úÖ Restart solo desde 'failed' (safe)
- ‚úÖ No se puede reprocesar 'completed' (previene duplicados)
- ‚úÖ Transiciones registradas en logs estructurados

**4. Gesti√≥n Inteligente de Archivos MP3**
- ‚úÖ Borrar al completar con √©xito ‚Üí libera espacio r√°pido
- ‚úÖ Borrar en error de descarga/red ‚Üí no acumula basura
- ‚úÖ **Mantener en error de transcripci√≥n** ‚Üí debugging (Whisper puede tardar 8 min)
- ‚úÖ Borrar en error de resumen ‚Üí transcripci√≥n ya guardada en BD
- ‚úÖ Cleanup en finally block ‚Üí garantiza limpieza cuando corresponde

**5. Logging Estructurado con Contexto**
```python
logger.info(
    "video_processing_started",
    extra={
        "video_id": str(video.id),
        "youtube_id": video.youtube_id,
        "url": video.url,
        "status": video.status.value,
    }
)
```
- ‚úÖ Contexto completo en cada log (video_id siempre presente)
- ‚úÖ M√©tricas en cada fase (file_size, duration, tokens_used)
- ‚úÖ Formato estructurado ‚Üí f√°cil parseo con ELK/Loki
- ‚úÖ Niveles apropiados (INFO para pasos, ERROR para fallos)

**Trade-offs:**

| Aspecto | Elegido | Alternativa | Por qu√© |
|---------|---------|-------------|---------|
| **Async** | 100% async | Sync con asyncio.run() | Preparado para Celery, mejor integraci√≥n |
| **Commits** | Intermedios | Transacci√≥n √∫nica | Preserva trabajo costoso (transcripci√≥n) |
| **Estados** | 7 estados granulares | 3 estados simples | Mejor observabilidad y debugging |
| **Archivos** | Borrar condicional | Siempre borrar / Nunca borrar | Balance espacio/debugging |
| **Retry** | Manual desde 'failed' | Autom√°tico en servicio | Usuario decide cu√°ndo reintentar |

**Consecuencias:**

‚úÖ **Positivas:**
- Pipeline robusto con manejo completo de errores
- Progreso incremental preservado en BD
- Archivos temporales gestionados eficientemente
- Logs estructurados para observabilidad
- 93% coverage con 17 tests (11 unit + 6 integration)
- Preparado para Celery tasks

‚ö†Ô∏è **Negativas/Trade-offs:**
- M√°s complejo que orquestador sync simple
- Estados intermedios pueden quedar hu√©rfanos si crash del sistema
- Necesita limpieza manual de archivos antiguos en /tmp

üìù **Implementaci√≥n:**
- Archivo: `src/services/video_processing_service.py` (115 l√≠neas)
- M√©todo principal: `async def process_video(session, video_id) -> Video`
- M√©todos privados: `_download_audio()`, `_transcribe_audio()`, `_create_summary()`, `_cleanup_audio_file()`
- Excepciones: `VideoNotFoundError`, `InvalidVideoStateError` (heredan de `VideoProcessingError`)

**Flujo implementado:**
```python
1. Validar video existe y status in {PENDING, FAILED}
2. Download: PENDING ‚Üí DOWNLOADING ‚Üí DOWNLOADED (commit)
3. Transcribe: ‚Üí TRANSCRIBING ‚Üí crear Transcription ‚Üí TRANSCRIBED (commit)
4. Summarize: ‚Üí SUMMARIZING ‚Üí crear Summary ‚Üí COMPLETED (commit)
5. Cleanup: borrar MP3 si corresponde
6. Error: ‚Üí FAILED (commit), cleanup condicional, reraise
```

**M√©tricas de calidad:**
- Tests: 17/17 passing (11 unit + 6 integration)
- Coverage: 93% del servicio
- Integraci√≥n BD: Validada con transacciones reales
- Error handling: Testeos de fallo en cada fase

**Path de migraci√≥n futura:**
- ‚úÖ A√±adir retry autom√°tico con exponential backoff (Paso 15)
- ‚úÖ Integrar con Celery async tasks (Paso 14)
- ‚úÖ Dashboard de monitoreo de pipeline (Paso 16)
- ‚úÖ Limpieza autom√°tica de archivos antiguos (cron job)

---

## METRICAS Y OBSERVABILIDAD

**Prometheus metrics:**
- `videos_processed_total`: Counter de videos procesados
- `transcription_duration_seconds`: Histogram de tiempo de transcripcion
- `deepseek_api_calls_total`: Counter de llamadas a DeepSeek
- `deepseek_cost_usd`: Gauge de costo acumulado ($)
- `celery_task_duration_seconds`: Histogram por tipo de tarea
- `api_request_duration_seconds`: Histogram de latencia API

**Grafana dashboards:**
1. Overview: Videos/dia, tiempo procesamiento, tasa error
2. Resources: CPU, RAM, Disk I/O
3. API: Request rate, latency p50/p95/p99, errores
4. Celery: Tasks pending, processing, failed

**Alertas criticas:**
- RAM >85% por 5 min
- Disco <20GB libre
- Costo DeepSeek >$1/d√≠a (anomal√≠a)
- Tasa error Celery >10%

---

## SEGURIDAD

**Proteccion de secretos:**
- `.env` en `.gitignore` (NUNCA commitear)
- Variables de entorno en produccion (systemd EnvironmentFile)
- Tokens en Cloudflare Secrets (futuro: Vault)

**API Security:**
- CORS configurado (whitelist dominios)
- Rate limiting (10 req/s por IP)
- JWT authentication (futuro)
- Input validation (Pydantic)

**Database:**
- Usuario no-root con permisos minimos
- Conexion via Unix socket (no TCP)
- Backups cifrados con GPG

---

## TESTING

**Cobertura objetivo:** 80%+

**Estrategia:**
1. **Unit tests:** Services, repositories (mocks)
2. **Integration tests:** API endpoints (TestClient + DB test)
3. **E2E tests:** Pipeline completo (fixture videos cortos)

**Fixtures:**
- Video corto (30s) para testing transcripcion
- Transcripcion pre-generada para testing resumenes
- Base de datos test (Docker container ephemeral)

---

## DOCUMENTACION

**Documentacion tecnica:**
- Este documento (architecture.md)
- API docs (auto-generada Swagger)
- ADRs para decisiones importantes
- Deployment guide (step-by-step)

**Documentacion usuario:**
- README con quickstart
- API usage examples
- Telegram bot commands (futuro)

---

## TIMELINE DE IMPLEMENTACION

Ver [docs/roadmap.md](roadmap.md) para roadmap detallado con pasos incrementales (4 semanas estimadas).

---

## REFERENCIAS

- FastAPI docs: https://fastapi.tiangolo.com
- Celery docs: https://docs.celeryq.dev
- Whisper repo: https://github.com/openai/whisper
- DeepSeek API docs: https://api-docs.deepseek.com/
- PostgreSQL docs: https://www.postgresql.org/docs

---

**Documento vivo:** Este documento se actualiza conforme evoluciona el proyecto.

**Proxima revision:** Despues de implementar Fase 1 (Infraestructura Base)
