# ARQUITECTURA - IA MONITOR

**Version:** 1.0
**Fecha:** Octubre 2025
**Autor:** Prodelaya

---

## RESUMEN EJECUTIVO

**Proyecto:** Agregador inteligente de contenido sobre IA en desarrollo software
**Objetivo dual:**
- **Portfolio profesional:** Demostrar backend Python moderno con IA funcional

**Stack core:** FastAPI + PostgreSQL + Redis + Celery + Whisper (local) + DeepSeek API
**Deployment:** Servidor local HP EliteDesk 800 G2 con Cloudflare Tunnel
**Presupuesto:** $0 (todo gratuito/local)

---

## INDICE

1. [Infraestructura](#infraestructura)
2. [Stack Tecnologico](#stack-tecnologico)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [Flujos de Procesamiento](#flujos-de-procesamiento)
5. [Modelo de Datos](#modelo-de-datos)
6. [Rate Limiting y Sistema de Colas](#rate-limiting-y-sistema-de-colas)
7. [Estructura de Directorios](#estructura-de-directorios)
8. [Plan de Escalabilidad](#plan-de-escalabilidad)
9. [ADRs (Decisiones Arquitectonicas)](#adrs)

---

## INFRAESTRUCTURA

### Servidor: HP EliteDesk 800 G2 DM

| Componente         | Especificacion                           | Estado       | Notas                                |
| ------------------ | ---------------------------------------- | ------------ | ------------------------------------ |
| **CPU**            | Intel Core i5-6500T (4c/4t, 2.5-3.1 GHz) | ‚úÖ Suficiente | Adecuado para Whisper base           |
| **RAM**            | 8 GB DDR4 2133 MHz                       | ‚ö†Ô∏è Ajustado   | Ampliable a 32GB (~$40)              |
| **Storage**        | 256 GB NVMe SSD Samsung                  | ‚úÖ Suficiente | ~10GB proyecto + ~50GB videos temp   |
| **SO**             | Ubuntu 24.04 LTS x86-64                  | ‚úÖ Ideal      | Mismo stack que desarrollo           |
| **Red**            | Cloudflare Tunnel configurado            | ‚úÖ Operativo  | Exposicion web segura sin IP publica |
| **Disponibilidad** | 24/7 siempre encendido                   | ‚úÖ OK         | Necesario para jobs programados      |

**Veredicto:** Servidor VIABLE para MVP. Path de upgrade economico disponible.

### Capacidad de procesamiento estimada

**Carga de trabajo esperada:**
- Volumen: 5-20 videos/dia
- Duracion promedio: 10-30 minutos
- Total diario: 100-400 minutos de audio

**Rendimiento Whisper base (sin GPU):**
- Velocidad: ~2x tiempo real
- 20 videos de 20 min = 400 min audio = ~13 horas procesamiento
- Procesamiento nocturno: 22:00 - 08:00 (10 horas disponibles)

**Conclusion:** Capacidad suficiente para volumen esperado. Picos requieren cola.

---

## STACK TECNOLOGICO

### 1. Backend: FastAPI

**Comparativa de frameworks:**

| Aspecto               | FastAPI                  | Flask                  | Django         |
| --------------------- | ------------------------ | ---------------------- | -------------- |
| **Performance**       | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Async nativo       | ‚≠ê‚≠ê‚≠ê WSGI sync          | ‚≠ê‚≠ê‚≠ê WSGI sync  |
| **Documentacion API** | ‚úÖ Auto (Swagger/OpenAPI) | ‚ùå Manual               | ‚≠ê DRF          |
| **Curva aprendizaje** | ‚≠ê‚≠ê‚≠ê‚≠ê Similar a Flask     | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Muy simple       | ‚≠ê‚≠ê Complejo    |
| **Validacion datos**  | ‚úÖ Pydantic integrado     | ‚ùå Requires marshmallow | ‚úÖ Django Forms |
| **Ecosistema async**  | ‚úÖ Nativo                 | ‚ö†Ô∏è Via extensiones      | ‚ö†Ô∏è Desde 3.1+   |
| **Peso**              | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Ligero             | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Minimo           | ‚≠ê‚≠ê Pesado      |

**Decision:** FastAPI
- ‚úÖ Async nativo (necesario para I/O intensivo: descargas, transcripciones, APIs)
- ‚úÖ Documentacion automatica (portfolio profesional)
- ‚úÖ Validacion con Pydantic (menos bugs)
- ‚úÖ Performance superior (importante para API publica)

### 2. Database: PostgreSQL

**Comparativa de bases de datos:**

| Aspecto                | PostgreSQL        | MySQL          | MongoDB          | SQLite        |
| ---------------------- | ----------------- | -------------- | ---------------- | ------------- |
| **Transacciones ACID** | ‚úÖ Completas       | ‚úÖ Completas    | ‚ö†Ô∏è Limitadas      | ‚úÖ Basicas     |
| **JSON nativo**        | ‚úÖ JSONB indexable | ‚≠ê JSON basico  | ‚úÖ Nativo         | ‚ùå No          |
| **Full-text search**   | ‚úÖ Potente         | ‚≠ê Basico       | ‚≠ê Via Atlas      | ‚ùå Limitado    |
| **Concurrencia**       | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê MVCC        | ‚≠ê‚≠ê‚≠ê‚≠ê Row-level | ‚≠ê‚≠ê‚≠ê‚≠ê Document    | ‚≠ê‚≠ê File-level |
| **Escalabilidad**      | ‚≠ê‚≠ê‚≠ê‚≠ê Excelente    | ‚≠ê‚≠ê‚≠ê‚≠ê Buena     | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Horizontal | ‚≠ê Local only  |
| **Recursos (8GB RAM)** | ‚≠ê‚≠ê‚≠ê‚≠ê ~500MB       | ‚≠ê‚≠ê‚≠ê‚≠ê ~400MB    | ‚≠ê‚≠ê‚≠ê ~800MB       | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ~50MB   |

**Decision:** PostgreSQL
- ‚úÖ JSONB para metadatos flexibles (transcripciones, API responses)
- ‚úÖ Full-text search para busqueda en resumenes
- ‚úÖ Relaciones complejas (sources ‚Üí videos ‚Üí transcriptions ‚Üí summaries)
- ‚úÖ Experiencia previa del desarrollador
- ‚úÖ Production-ready para futuro escalado

### 3. Cache: Redis

**Comparativa de sistemas de cache:**

| Aspecto               | Redis                 | Memcached  | Local (dict)    |
| --------------------- | --------------------- | ---------- | --------------- |
| **Persistencia**      | ‚úÖ Opcional            | ‚ùå No       | ‚ùå RAM volatil   |
| **Estructuras datos** | ‚úÖ Lists, Sets, Hashes | ‚ùå Solo K-V | ‚≠ê Python nativo |
| **Pub/Sub**           | ‚úÖ Si                  | ‚ùå No       | ‚ùå No            |
| **Broker Celery**     | ‚úÖ Nativo              | ‚ùå No       | ‚ùå No            |
| **Recursos**          | ~100MB                | ~50MB      | ~0MB            |

**Decision:** Redis
- ‚úÖ Doble proposito: cache + broker Celery (un servicio, dos funciones)
- ‚úÖ Rate limiting de ApyHub API (10 llamadas/dia)
- ‚úÖ Cache de metadatos de videos
- ‚úÖ Pub/Sub para notificaciones en tiempo real (futuro)

### 4. Task Queue: Celery

**Comparativa de sistemas async:**

| Aspecto               | Celery                | FastAPI BackgroundTasks | RQ               | Dramatiq             |
| --------------------- | --------------------- | ----------------------- | ---------------- | -------------------- |
| **Complejidad setup** | ‚≠ê‚≠ê‚≠ê Media             | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Cero              | ‚≠ê‚≠ê‚≠ê‚≠ê Simple      | ‚≠ê‚≠ê‚≠ê Media            |
| **Scheduling**        | ‚úÖ Celery Beat         | ‚ùå Requires APScheduler  | ‚ùå Requires extra | ‚úÖ Si                 |
| **Monitoring**        | ‚úÖ Flower              | ‚ùå Manual                | ‚≠ê RQ Dashboard   | ‚≠ê Dramatiq Dashboard |
| **Reintentos**        | ‚úÖ Configurables       | ‚≠ê Manual                | ‚úÖ Si             | ‚úÖ Si                 |
| **Larga duracion**    | ‚úÖ Ideal               | ‚ùå No recomendado        | ‚úÖ Si             | ‚úÖ Si                 |
| **Maduro**            | ‚úÖ 2009, battle-tested | ‚úÖ Nativo FastAPI        | ‚≠ê 2011           | ‚≠ê 2016               |

**Decision:** Celery
- ‚úÖ Tareas largas (transcripcion 5-20 min por video)
- ‚úÖ Scheduling nativo (Celery Beat para scraping cada 6h)
- ‚úÖ Reintentos automaticos (APIs pueden fallar)
- ‚úÖ Monitoring con Flower (observabilidad)
- ‚úÖ Escalable (multiples workers en paralelo)

### 5. IA: Whisper (local) + ApyHub API

**Comparativa transcripcion:**

| Servicio                  | Coste       | Precision | Velocidad     | Idiomas |
| ------------------------- | ----------- | --------- | ------------- | ------- |
| **Whisper base (local)**  | $0          | 85-90%    | 2x realtime   | 99      |
| **Whisper small (local)** | $0          | 90-95%    | 3x realtime   | 99      |
| AssemblyAI                | $0.006/min  | 95%+      | 0.2x realtime | 10+     |
| Deepgram                  | $0.0043/min | 95%+      | 0.1x realtime | 30+     |
| Google Speech-to-Text     | $0.006/min  | 95%+      | 0.3x realtime | 125     |

**Decision:** Whisper base (local)
- ‚úÖ $0 coste (requisito del proyecto)
- ‚úÖ Precision suficiente para resumenes (no necesitamos subtitulos perfectos)
- ‚úÖ Sin limites de uso
- ‚úÖ Privacidad (no enviamos audio a terceros)
- ‚ö†Ô∏è Consume ~1.5GB RAM (dentro del limite con 8GB)
- ‚ö†Ô∏è Lento pero aceptable (procesamiento nocturno)

**Comparativa resumenes:**

| Servicio              | Coste            | Limite | Calidad         |
| --------------------- | ---------------- | ------ | --------------- |
| **DeepSeek**          | $0.28/1M input   | Sin limite | ‚≠ê‚≠ê‚≠ê‚≠ê Buena      |
| OpenAI GPT-4          | $0.03/1K tokens  | Sin limite | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| Claude API            | $0.015/1K tokens | Sin limite | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente |
| LangChain + local LLM | $0               | Ilimitado | ‚≠ê‚≠ê‚≠ê Variable    |

**Decision:** DeepSeek API
- ‚úÖ Coste predecible: ~$0.16-0.45/mes para 300 videos
- ‚úÖ Sin limites artificiales de uso
- ‚úÖ Compatible con SDK OpenAI (facil integracion)
- ‚úÖ Context caching automatico (reduce costos 80%)
- ‚úÖ JSON output nativo (estructurado)

---

## ARQUITECTURA DEL SISTEMA

### Diagrama de componentes

```mermaid
graph TB
    subgraph "Cliente"
        USER[Usuario/Frontend]
        TGBOT[Telegram Bot]
    end

    subgraph "API Layer"
        API[FastAPI<br/>API REST]
    end

    subgraph "Application Layer"
        SERVICES[Services<br/>Business Logic]
        REPOS[Repositories<br/>Data Access]
    end

    subgraph "Data Layer"
        PG[(PostgreSQL<br/>8GB RAM)]
        REDIS[(Redis<br/>Cache + Broker)]
    end

    subgraph "Worker Layer"
        WORKER1[Celery Worker 1<br/>Transcription]
        WORKER2[Celery Worker 2<br/>Summarization]
        BEAT[Celery Beat<br/>Scheduler]
    end

    subgraph "External Services"
        YT[YouTube]
        DEEPSEEK[DeepSeek API<br/>Summarization]
        WHISPER[Whisper Local<br/>Transcription]
    end

    USER --> API
    TGBOT --> API
    API --> SERVICES
    SERVICES --> REPOS
    REPOS --> PG
    SERVICES --> REDIS

    BEAT --> REDIS
    REDIS --> WORKER1
    REDIS --> WORKER2

    WORKER1 --> YT
    WORKER1 --> WHISPER
    WORKER1 --> PG

    WORKER2 --> DEEPSEEK
    WORKER2 --> PG

    style API fill:#4CAF50
    style PG fill:#336791
    style REDIS fill:#DC382D
    style WORKER1 fill:#37B24D
    style WORKER2 fill:#37B24D
    style WHISPER fill:#FF6B6B
    style DEEPSEEK fill:#1E88E5
```

### Descripcion de componentes

**1. API Layer (FastAPI)**
- Endpoints REST para consultar resumenes
- Endpoints para gestionar fuentes (canales YouTube)
- Autenticacion JWT (futuro)
- Documentacion auto-generada (Swagger)
- CORS configurado para frontend

**2. Application Layer**
- **Services:** Logica de negocio (orquestacion de workers, validaciones)
- **Repositories:** Abstraccion de acceso a datos (patron Repository)

**3. Data Layer**
- **PostgreSQL:** Datos estructurados (sources, videos, transcriptions, summaries)
- **Redis:** Cache de metadatos + broker de Celery + rate limiting

**4. Worker Layer**
- **Celery Worker 1:** Descarga videos, transcripcion con Whisper
- **Celery Worker 2:** Resumenes con ApyHub, clasificacion
- **Celery Beat:** Scheduler para scraping periodico (cada 6h)

**5. External Services**
- **YouTube:** API + yt-dlp para obtener metadatos y descargar audio
- **Whisper:** Modelo local para transcripcion
- **DeepSeek:** LLM API para generar resumenes

---

## FLUJOS DE PROCESAMIENTO

### Flujo 1: Registro de nueva fuente (manual)

```mermaid
sequenceDiagram
    participant U as Usuario
    participant API as FastAPI
    participant DB as PostgreSQL

    U->>API: POST /api/v1/sources<br/>{channel_url, name}
    API->>API: Validar URL YouTube
    API->>DB: INSERT INTO sources
    DB-->>API: source_id
    API-->>U: 201 Created {source_id}
```

### Flujo 2: Scraping periodico (automatico)

```mermaid
sequenceDiagram
    participant BEAT as Celery Beat
    participant REDIS as Redis Queue
    participant W1 as Worker 1
    participant YT as YouTube
    participant DB as PostgreSQL

    BEAT->>REDIS: Encolar "sync_sources_task"<br/>(cada 6 horas)
    REDIS->>W1: Ejecutar tarea
    W1->>DB: SELECT * FROM sources WHERE active=true

    loop Para cada fuente
        W1->>YT: yt-dlp --get-json <channel_url>
        YT-->>W1: JSON metadata (ultimos 10 videos)

        W1->>DB: SELECT video_id FROM videos<br/>WHERE source_id AND youtube_id

        alt Video nuevo (no existe)
            W1->>DB: INSERT INTO videos<br/>(youtube_id, title, url, duration, published_at)
            W1->>REDIS: Encolar "process_video_task"<br/>(video_id)
        else Video ya existe
            W1->>W1: Skip (ya procesado)
        end
    end
```

### Flujo 3: Procesamiento de video (async)

```mermaid
sequenceDiagram
    participant REDIS as Redis Queue
    participant W1 as Worker 1
    participant YT as YouTube
    participant WHISPER as Whisper
    participant W2 as Worker 2
    participant APYHUB as ApyHub API
    participant DB as PostgreSQL

    REDIS->>W1: process_video_task(video_id)
    W1->>DB: SELECT * FROM videos WHERE id=video_id

    Note over W1: FASE 1: Descarga audio
    W1->>YT: yt-dlp -x --audio-format mp3 <video_url>
    YT-->>W1: audio.mp3
    W1->>DB: UPDATE videos SET status='downloaded'

    Note over W1: FASE 2: Transcripcion
    W1->>WHISPER: transcribe(audio.mp3, model='base')
    WHISPER-->>W1: {text, language, segments}
    W1->>DB: INSERT INTO transcriptions<br/>(video_id, text, language, model='whisper-base')
    W1->>W1: Eliminar audio.mp3 (liberar espacio)
    W1->>DB: UPDATE videos SET status='transcribed'

    Note over W1: FASE 3: Encolar resumen
    W1->>REDIS: Encolar "summarize_task"<br/>(transcription_id)

    REDIS->>W2: summarize_task(transcription_id)
    W2->>DB: SELECT text FROM transcriptions WHERE id

    Note over W2: FASE 4: Rate limiting check
    W2->>REDIS: GET apyhub_calls_today

    alt Limite no alcanzado (<10 llamadas)
        W2->>APYHUB: POST /ai-summarize<br/>{text: transcription}
        APYHUB-->>W2: {summary, keywords}
        W2->>REDIS: INCR apyhub_calls_today<br/>EXPIRE 86400
        W2->>DB: INSERT INTO summaries<br/>(transcription_id, summary, keywords)
        W2->>DB: UPDATE videos SET status='completed'
    else Limite alcanzado (>=10 llamadas)
        W2->>DB: UPDATE videos SET status='pending_summary'
        W2->>W2: Reencolar para manana
    end
```

### Flujo 4: Consulta API (usuario)

```mermaid
sequenceDiagram
    participant U as Usuario
    participant API as FastAPI
    participant REDIS as Redis Cache
    participant DB as PostgreSQL

    U->>API: GET /api/v1/summaries?limit=20&offset=0
    API->>REDIS: GET summaries:page:0

    alt Cache hit
        REDIS-->>API: Cached data
        API-->>U: 200 OK [summaries]
    else Cache miss
        API->>DB: SELECT s.*, v.title, v.url<br/>FROM summaries s<br/>JOIN videos v ON s.video_id=v.id<br/>ORDER BY v.published_at DESC<br/>LIMIT 20
        DB-->>API: [summaries]
        API->>REDIS: SET summaries:page:0<br/>EXPIRE 300 (5 min)
        API-->>U: 200 OK [summaries]
    end
```

---

## MODELO DE DATOS

### Diagrama ER

```mermaid
erDiagram
    SOURCES ||--o{ VIDEOS : has
    VIDEOS ||--o| TRANSCRIPTIONS : has
    TRANSCRIPTIONS ||--o| SUMMARIES : has
    VIDEOS ||--o{ TAGS : has

    SOURCES {
        uuid id PK
        string name
        string url
        string source_type
        boolean active
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }

    VIDEOS {
        uuid id PK
        uuid source_id FK
        string youtube_id UK
        string title
        string url
        integer duration_seconds
        string status
        timestamp published_at
        jsonb metadata
        timestamp created_at
        timestamp updated_at
    }

    TRANSCRIPTIONS {
        uuid id PK
        uuid video_id FK
        text transcription
        string language
        string model_used
        jsonb segments
        timestamp created_at
    }

    SUMMARIES {
        uuid id PK
        uuid transcription_id FK
        text summary
        string[] keywords
        string sentiment
        jsonb metadata
        timestamp created_at
    }

    TAGS {
        uuid id PK
        string name UK
        string category
    }
```

### Descripcion de tablas

**1. sources**
- Fuentes de contenido (canales YouTube)
- `source_type`: 'youtube' (futuro: 'rss', 'podcast')
- `active`: Permite desactivar fuentes sin borrarlas
- `metadata`: Datos extra (subscriber_count, thumbnail_url, etc.)

**2. videos**
- Videos individuales obtenidos de las fuentes
- `youtube_id`: ID unico de YouTube (para evitar duplicados)
- `status`: 'pending' ‚Üí 'downloading' ‚Üí 'downloaded' ‚Üí 'transcribing' ‚Üí 'transcribed' ‚Üí 'summarizing' ‚Üí 'completed' | 'failed' | 'pending_summary'
- `duration_seconds`: Para estimar tiempo de procesamiento
- `metadata`: Datos extra (view_count, like_count, thumbnail_url, etc.)

**3. transcriptions**
- Transcripciones generadas por Whisper
- `model_used`: 'whisper-base' | 'whisper-small' (para tracking)
- `segments`: JSON con timestamps (futuro: busqueda temporal)

**4. summaries**
- Resumenes generados por ApyHub
- `keywords`: Array de palabras clave extraidas
- `sentiment`: 'positive' | 'neutral' | 'negative' (futuro)
- `metadata`: Datos extra del API (confidence, etc.)

**5. tags**
- Etiquetas para clasificacion (relacion N:M con videos)
- `category`: 'framework' | 'language' | 'tool' | 'concept'

### Indices principales

```sql
-- Performance critico
CREATE INDEX idx_videos_source_id ON videos(source_id);
CREATE INDEX idx_videos_status ON videos(status);
CREATE INDEX idx_videos_published_at ON videos(published_at DESC);
CREATE INDEX idx_transcriptions_video_id ON transcriptions(video_id);
CREATE INDEX idx_summaries_transcription_id ON summaries(transcription_id);

-- Full-text search
CREATE INDEX idx_summaries_summary_fts ON summaries USING gin(to_tsvector('spanish', summary));
CREATE INDEX idx_videos_title_fts ON videos USING gin(to_tsvector('spanish', title));

-- Rate limiting (futuro)
CREATE INDEX idx_videos_summary_status ON videos(summary_status);  -- Para cola de procesamiento
CREATE INDEX idx_videos_summary_pending ON videos(created_at) WHERE summary_status='pending';  -- Partial index
```

---

## RATE LIMITING Y SISTEMA DE COLAS

### Contexto del problema

**Limitaci√≥n cr√≠tica:** ApyHub API plan gratuito = **10 llamadas/d√≠a**

**Volumen esperado:** 5-20 videos nuevos por d√≠a

**Riesgo sin sistema de colas:**
- D√≠a con 15 videos nuevos ‚Üí Solo 10 se resumen, 5 se pierden
- Errores en API ‚Üí Reintentos desperdician cuota
- Sin priorizaci√≥n ‚Üí Videos importantes podr√≠an quedar sin resumir

### Dise√±o de soluci√≥n

#### Arquitectura del sistema de colas

```mermaid
sequenceDiagram
    participant BEAT as Celery Beat<br/>(00:30 UTC)
    participant REDIS as Redis<br/>Rate Limiter
    participant WORKER as Celery Worker
    participant DB as PostgreSQL
    participant APYHUB as ApyHub API

    Note over BEAT: Tarea programada diaria
    BEAT->>REDIS: RESET apyhub:daily_calls:2025-10-29
    REDIS-->>BEAT: OK (contador = 0)

    BEAT->>DB: SELECT * FROM videos<br/>WHERE summary_status='pending'<br/>ORDER BY created_at ASC LIMIT 10
    DB-->>BEAT: [video_1, video_2, ..., video_10]

    loop Para cada video (max 10)
        BEAT->>REDIS: GET apyhub:daily_calls:2025-10-29
        REDIS-->>BEAT: current_count

        alt current_count < 10
            BEAT->>WORKER: Encolar process_summary_task(video_id)
            WORKER->>DB: UPDATE videos SET summary_status='processing'
            WORKER->>APYHUB: POST /content/summarize
            APYHUB-->>WORKER: {job_id, status_url}

            Note over WORKER: Polling job status
            WORKER->>APYHUB: GET /job/status/{job_id}
            APYHUB-->>WORKER: {status: 'completed', result: {...}}

            WORKER->>DB: UPDATE videos SET<br/>summary_status='completed',<br/>summary_text='...',<br/>summarized_at=NOW()
            WORKER->>REDIS: INCR apyhub:daily_calls:2025-10-29
            REDIS-->>WORKER: new_count
        else current_count >= 10
            Note over BEAT: L√≠mite alcanzado, detener<br/>Videos restantes quedan 'pending'
            BEAT->>BEAT: BREAK loop
        end
    end

    Note over BEAT: Fin de procesamiento diario<br/>Videos no procesados se intentar√°n ma√±ana
```

#### Tabla de estados de resumen

| Estado       | Descripci√≥n                   | Siguiente acci√≥n                    |
| ------------ | ----------------------------- | ----------------------------------- |
| `pending`    | Video nuevo, sin procesar     | Encolar para siguiente batch diario |
| `processing` | Resumen en progreso           | Esperar finalizaci√≥n (polling)      |
| `completed`  | Resumen generado exitosamente | Ninguna (estado final)              |
| `failed`     | Fallo tras 3 intentos         | Revisi√≥n manual o descarte          |

#### Flujo de transici√≥n de estados

```
pending ‚Üí processing ‚Üí completed
    ‚îÇ                 ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (error) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚ñº
    (reintentos < 3) ‚Üí pending
    (reintentos >= 3) ‚Üí failed
```

### Componentes del sistema

#### 1. Rate Limiter (Redis)

**Archivo:** `src/services/rate_limiter.py` (futuro)

**Responsabilidades:**
- Mantener contador diario de llamadas a ApyHub
- Verificar si se puede hacer una llamada nueva
- Registrar llamadas exitosas
- Reiniciar contador autom√°ticamente cada d√≠a

**Estructura de datos en Redis:**
```python
# Clave con fecha del d√≠a
key = "apyhub:daily_calls:2025-10-29"

# Valor: contador simple (integer)
value = 7  # 7 llamadas realizadas hoy

# TTL: 24 horas (expira autom√°ticamente a medianoche)
EXPIRE apyhub:daily_calls:2025-10-29 86400
```

**M√©todos principales:**
```python
class ApyHubRateLimiter:
    DAILY_LIMIT = 10

    async def get_remaining_calls() -> int:
        """Retorna llamadas disponibles hoy (0-10)."""

    async def can_call_api() -> bool:
        """True si quedan llamadas disponibles."""

    async def record_call() -> int:
        """Incrementa contador, retorna total usado hoy."""

    async def reset_daily_counter():
        """Reinicia contador (tarea programada)."""
```

#### 2. Modelo Video extendido

**Campos adicionales necesarios:**

```python
class Video(Base):
    # ... campos existentes ...

    # === NUEVOS CAMPOS PARA SISTEMA DE COLAS ===
    summary_status: Mapped[str] = mapped_column(
        String(20),
        nullable=False,
        default="pending",
        index=True,  # IMPORTANTE: √≠ndice para queries r√°pidas
        comment="Estado: pending | processing | completed | failed"
    )

    summary_text: Mapped[str | None] = mapped_column(
        Text,
        nullable=True,
        comment="Texto del resumen generado por ApyHub"
    )

    summary_attempts: Mapped[int] = mapped_column(
        Integer,
        nullable=False,
        default=0,
        comment="N√∫mero de intentos de resumen (max 3)"
    )

    summary_error: Mapped[str | None] = mapped_column(
        Text,
        nullable=True,
        comment="√öltimo error al intentar resumir"
    )

    summarized_at: Mapped[datetime | None] = mapped_column(
        DateTime(timezone=True),
        nullable=True,
        comment="Timestamp de generaci√≥n exitosa"
    )
```

**Migraci√≥n necesaria:**
```sql
-- Alembic auto-generar√° similar a esto:
ALTER TABLE videos
    ADD COLUMN summary_status VARCHAR(20) DEFAULT 'pending' NOT NULL,
    ADD COLUMN summary_text TEXT,
    ADD COLUMN summary_attempts INTEGER DEFAULT 0 NOT NULL,
    ADD COLUMN summary_error TEXT,
    ADD COLUMN summarized_at TIMESTAMPTZ;

CREATE INDEX idx_videos_summary_status ON videos(summary_status);
CREATE INDEX idx_videos_summary_pending ON videos(created_at)
    WHERE summary_status='pending';  -- Partial index para eficiencia
```

#### 3. Tarea Celery diaria

**Archivo:** `src/tasks/daily_summarization.py` (futuro)

**Funci√≥n principal:**
```python
@shared_task(name="daily_summarization")
async def process_pending_summaries():
    """
    Procesa hasta 10 videos pendientes respetando rate limit.

    Ejecutado por Celery Beat cada d√≠a a las 00:30 UTC.

    Returns:
        Dict con estad√≠sticas: processed, success, failed, skipped
    """
```

**Configuraci√≥n Celery Beat:**
```python
# src/core/celery_app.py
from celery.schedules import crontab

app.conf.beat_schedule = {
    'daily-summarization': {
        'task': 'daily_summarization',
        'schedule': crontab(hour=0, minute=30),  # 00:30 UTC diario
        'options': {
            'expires': 3600,  # Cancelar si no ejecuta en 1h
        }
    },
}
```

### Pol√≠tica de priorizaci√≥n (futuro)

**Fase 1 (MVP):** FIFO simple (m√°s antiguos primero)
```sql
SELECT * FROM videos
WHERE summary_status = 'pending'
ORDER BY created_at ASC  -- M√°s antiguos primero
LIMIT 10;
```

**Fase 2 (optimizaci√≥n):** Prioridad por popularidad del canal
```sql
SELECT v.* FROM videos v
JOIN sources s ON v.source_id = s.id
WHERE v.summary_status = 'pending'
ORDER BY
    s.subscriber_count DESC,  -- Canales grandes primero
    v.view_count DESC,        -- Videos populares primero
    v.created_at ASC          -- Desempate: m√°s antiguos
LIMIT 10;
```

### Manejo de errores y reintentos

**Estrategia de reintentos:**

1. **Intento 1:** Inmediato (al detectar video nuevo)
2. **Intento 2:** Siguiente d√≠a (si fall√≥ el 1¬∫)
3. **Intento 3:** Siguiente d√≠a (si fall√≥ el 2¬∫)
4. **Despu√©s de 3 fallos:** `summary_status = 'failed'`

**Tipos de errores:**

| Error               | Acci√≥n                         | Consume cuota |
| ------------------- | ------------------------------ | ------------- |
| Timeout de red      | Reintentar ma√±ana              | S√≠            |
| Rate limit 429      | Detener batch, ma√±ana          | No            |
| Token inv√°lido 401  | Alertar admin, pausar          | S√≠            |
| Texto muy largo 400 | Marcar 'failed', no reintentar | S√≠            |
| Job no completa     | Reintentar ma√±ana              | S√≠            |

### M√©tricas y observabilidad

**M√©tricas Prometheus a√±adir:**

```python
from prometheus_client import Counter, Gauge, Histogram

# Contador de llamadas a ApyHub
apyhub_calls_total = Counter(
    'apyhub_api_calls_total',
    'Total de llamadas a ApyHub API',
    ['status']  # success, error, rate_limited
)

# Gauge de llamadas restantes hoy
apyhub_calls_remaining = Gauge(
    'apyhub_calls_remaining',
    'Llamadas restantes a ApyHub hoy'
)

# Gauge de videos en cola
videos_pending_summary = Gauge(
    'videos_pending_summary_total',
    'Videos esperando resumen'
)

# Histograma de duraci√≥n de resumen
summarization_duration = Histogram(
    'summarization_duration_seconds',
    'Tiempo de generaci√≥n de resumen'
)
```

**Dashboard Grafana sugerido:**

- Panel 1: Llamadas ApyHub (usadas/restantes hoy)
- Panel 2: Videos en cola (pending vs completed)
- Panel 3: Tasa de √©xito (% completed vs failed)
- Panel 4: Tiempo promedio de resumen
- Panel 5: Alertas (rate limit alcanzado, >50 videos pending)

### Ventajas del dise√±o

1. **Garant√≠a de no exceder cuota:** Hard limit en c√≥digo
2. **Sin p√©rdida de datos:** Videos quedan en cola persistente (BD)
3. **Reintentos inteligentes:** M√°ximo 3 intentos, luego descarte
4. **Escalabilidad:** Cambiar `DAILY_LIMIT = 100` si upgradeas plan
5. **Observabilidad:** M√©tricas claras de uso de cuota
6. **Pol√≠tica justa:** FIFO garantiza procesamiento equitativo

### Trade-offs aceptados

1. **Latencia variable:** Videos pueden tardar 1-3 d√≠as si hay cola
   - Mitigaci√≥n: Priorizar canales importantes (Fase 2)

2. **Complejidad a√±adida:** +3 componentes nuevos a mantener
   - Mitigaci√≥n: Tests exhaustivos, documentaci√≥n clara

3. **Dependencia cr√≠tica de Redis:** Si Redis cae, contador se pierde
   - Mitigaci√≥n: Redis con persistencia AOF activada

### Timeline de implementaci√≥n

**Orden recomendado:**

1. **Paso 15:** Implementar `ApyHubRateLimiter` (1 d√≠a)
2. **Paso 12-13:** Ampliar modelo `Video` con campos de cola (1 d√≠a)
3. **Paso 16-17:** Crear tarea Celery diaria (2 d√≠as)
4. **Paso 18:** Tests de integraci√≥n completos (1 d√≠a)
5. **Paso 19:** M√©tricas y dashboard Grafana (1 d√≠a)

**Total estimado:** ~6 d√≠as de desarrollo

**Prioridad:** Alta (cr√≠tico antes de producci√≥n)

---

## ESTRUCTURA DE DIRECTORIOS

```
youtube-AIsummary/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml                  # Tests + linting
‚îÇ       ‚îî‚îÄ‚îÄ cd.yml                  # Deployment automatico
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md             # Este documento
‚îÇ   ‚îú‚îÄ‚îÄ api.md                      # Documentacion endpoints
‚îÇ   ‚îú‚îÄ‚îÄ deployment.md               # Guia de despliegue
‚îÇ   ‚îú‚îÄ‚îÄ ADR/                        # Architecture Decision Records
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001-fastapi-vs-flask.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002-whisper-local.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 003-apyhub-limit.md
‚îÇ   ‚îú‚îÄ‚îÄ contexting-prompts/         # Prompts de contexto
‚îÇ   ‚îî‚îÄ‚îÄ professional-prompts/       # Prompts de desarrollo
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/                        # FastAPI application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # App factory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dependencies.py         # DI containers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summaries.py        # GET /api/v1/summaries
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.py          # CRUD /api/v1/sources
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py           # GET /health
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas/                # Pydantic models
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ summary.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ source.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ common.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                       # Configuracion central
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Settings (Pydantic BaseSettings)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py             # SQLAlchemy engine + session
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ redis.py                # Redis connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py           # Celery instance
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging.py              # Logging config
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # SQLAlchemy ORM models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # Base model + mixins
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ source.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ summary.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tag.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ repositories/               # Data access layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # Generic CRUD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ source_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcription_repository.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_repository.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                   # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ youtube_service.py      # yt-dlp wrapper
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ whisper_service.py      # Transcription
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ apyhub_service.py       # Summarization
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cache_service.py        # Redis cache
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                      # Celery tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sync_sources.py         # Scraping periodico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ process_video.py        # Pipeline completo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transcribe.py           # Whisper task
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summarize.py            # ApyHub task
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                      # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ rate_limiter.py         # ApyHub rate limit
‚îÇ       ‚îî‚îÄ‚îÄ validators.py           # Validaciones custom
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                 # Fixtures pytest
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_services.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_repositories.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_tasks.py
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ       ‚îî‚îÄ‚îÄ test_full_pipeline.py
‚îÇ
‚îú‚îÄ‚îÄ migrations/                     # Alembic migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îî‚îÄ‚îÄ env.py
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_dev.sh                # Setup entorno desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                   # Deployment produccion
‚îÇ   ‚îú‚îÄ‚îÄ backup_db.sh                # Backup PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ seed_data.py                # Datos de prueba
‚îÇ
‚îú‚îÄ‚îÄ .env                            # Variables entorno (NO commitear)
‚îú‚îÄ‚îÄ .env.example                    # Template variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ pyproject.toml                  # Poetry dependencies
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ docker-compose.yml              # Dev environment
‚îú‚îÄ‚îÄ docker-compose.prod.yml         # Production
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ alembic.ini                     # Config migraciones
```

---

## PLAN DE ESCALABILIDAD

### Etapa 1: MVP (actual - 8GB RAM)

**Capacidad:**
- 5-10 videos/dia
- Whisper base (1.5GB RAM)
- Procesamiento secuencial

**Limitaciones:**
- RAM ajustada (~6.8GB disponible)
- CPU al 100% durante transcripcion
- Sin redundancia

**Cuando escalar:** >10 videos/dia consistente O RAM >90%

---

### Etapa 2: Upgrade RAM (8GB ‚Üí 16GB) [~$40]

**Mejoras:**
- ‚úÖ Whisper small (mejor precision 90-95%)
- ‚úÖ 2 workers Celery en paralelo
- ‚úÖ Capacidad: 15-20 videos/dia
- ‚úÖ PostgreSQL con mas buffer pool

**Trigger:** Volumen >10 videos/dia por 1 semana

---

### Etapa 3: Upgrade RAM (16GB ‚Üí 32GB) [~$80 total]

**Mejoras:**
- ‚úÖ Whisper medium (precision 95%+)
- ‚úÖ 4 workers Celery en paralelo
- ‚úÖ Capacidad: 30-50 videos/dia
- ‚úÖ Cache Redis mas grande

**Trigger:** Volumen >20 videos/dia por 1 semana

---

### Etapa 4: Arquitectura hibrida (Servidor + Oracle Cloud)

**Cuando:** >50 videos/dia O CPU saturada constantemente

**Distribucion:**
```
Servidor Local (HP EliteDesk):
- FastAPI (API REST)
- PostgreSQL (base de datos)
- Redis (cache + broker)
- Celery Beat (scheduler)
- Celery Worker (resumenes ApyHub)

Oracle Cloud Always Free (4 OCPUs ARM + 24GB):
- Celery Worker dedicado (transcripciones Whisper)
- Whisper large model (precision 98%+)
- Procesamiento 4x mas rapido (ARM optimizado)
```

**Ventajas:**
- ‚úÖ Separa I/O (servidor) de CPU intensivo (cloud)
- ‚úÖ $0 coste (Oracle Always Free)
- ‚úÖ Capacidad: 100+ videos/dia

**Complejidad:** +2 semanas setup (VPN, queue distribuida, monitoring)

---

### Etapa 5: Cloud completo (si crece mucho)

**Solo si:** >200 videos/dia O necesitas SLA 99.9%

**Stack:**
- Hetzner VPS (~$10/mes, 4 vCPUs + 8GB)
- Managed PostgreSQL (~$15/mes)
- Autoscaling workers (Kubernetes)

**No recomendado a corto plazo:** Overkill para caso de uso actual

---

## ADRS (DECISIONES ARQUITECTONICAS)

### ADR-001: FastAPI vs Flask

**Contexto:**
Necesitamos un framework web para exponer API REST. Opciones: FastAPI, Flask, Django.

**Decision:** FastAPI

**Razon:**
- Async nativo (I/O bound: descargas, APIs externas)
- Documentacion auto-generada (portfolio profesional)
- Validacion Pydantic (menos bugs, mejor DX)
- Performance superior (benchmarks: 2-3x Flask)

**Consecuencias:**
- ‚úÖ Codigo mas mantenible
- ‚úÖ Testing mas facil (TestClient integrado)
- ‚ö†Ô∏è Curva aprendizaje async/await (mitigado: similar a Flask)

---

### ADR-002: Whisper local vs APIs pago

**Contexto:**
Necesitamos transcribir audio de videos. Opciones: Whisper local, AssemblyAI, Deepgram.

**Decision:** Whisper base (local)

**Razon:**
- $0 coste (requisito del proyecto)
- Precision suficiente para resumenes (85-90%)
- Sin limites de uso
- Privacidad (no enviamos audio a terceros)

**Trade-offs:**
- ‚úÖ Coste: $0 vs $2.40/dia (400 min √ó $0.006/min)
- ‚ö†Ô∏è Velocidad: 2x realtime vs 0.2x realtime (10x mas lento)
- ‚ö†Ô∏è RAM: 1.5GB vs 0GB
- ‚úÖ Precision: 85-90% vs 95%+ (suficiente para caso de uso)

**Consecuencias:**
- ‚úÖ Proyecto viable con presupuesto $0
- ‚ö†Ô∏è Procesamiento nocturno requerido (no real-time)
- üìã Path de migracion: Si crece, usar AssemblyAI o Whisper large en Oracle Cloud

---

### ADR-003: Limite ApyHub 10 llamadas/dia

**Contexto:**
ApyHub API gratuita tiene limite 10 llamadas/dia. Volumen esperado: 5-20 videos/dia.

**Decision:** Priorizar videos por popularidad + reencolar fallidos

**Estrategia:**
1. Videos de canales con >100K suscriptores ‚Üí Prioridad alta
2. Videos con >10K vistas ‚Üí Prioridad media
3. Resto ‚Üí Prioridad baja
4. Si se alcanza limite, reencolar para el dia siguiente (Celery countdown=86400)

**Alternativas consideradas:**
- ‚ùå LLM local (Llama 3.1): Requiere GPU (no disponible)
- ‚ùå OpenAI GPT-4o-mini: $0.15/1M tokens (~$0.05/video, $1.50/mes para 30 videos)
- ‚≠ê **Futuro:** Migrar a GPT-4o-mini si volumen >10 videos/dia consistente

**Consecuencias:**
- ‚úÖ MVP funcional con limite gratuito
- ‚ö†Ô∏è Algunos videos tardaran 1-2 dias en resumirse
- ‚úÖ Path claro de upgrade: ApyHub ‚Üí GPT-4o-mini (~$2/mes)

---

### ADR-004: PostgreSQL vs MongoDB

**Contexto:**
Necesitamos persistir datos estructurados (sources, videos, summaries). Opciones: PostgreSQL, MongoDB.

**Decision:** PostgreSQL

**Razon:**
- Relaciones claras (source ‚Üí videos ‚Üí transcriptions ‚Üí summaries)
- JSONB para flexibilidad en metadatos
- Full-text search nativo (busqueda en resumenes)
- Transacciones ACID (importante para estado de procesamiento)
- Experiencia previa del desarrollador

**Consecuencias:**
- ‚úÖ Consultas relacionales eficientes
- ‚úÖ Migraciones con Alembic (cambios de schema controlados)
- ‚ö†Ô∏è Menos flexible que MongoDB (mitigado con JSONB)

---

### ADR-005: Celery vs FastAPI BackgroundTasks

**Contexto:**
Necesitamos procesar tareas pesadas en background. Opciones: Celery, BackgroundTasks, RQ.

**Decision:** Celery + Celery Beat

**Razon:**
- Tareas largas (transcripcion 5-20 min)
- Scheduling nativo (scraping cada 6h)
- Reintentos automaticos
- Monitoring con Flower
- Escalable (multiples workers)

**Trade-off:**
- ‚ö†Ô∏è Complejidad: Requiere Redis + worker process
- ‚úÖ Beneficio: Produccion-ready, battle-tested

**Consecuencias:**
- ‚úÖ API responde inmediato (no bloquea)
- ‚úÖ Jobs programados sin cron
- ‚ö†Ô∏è +1 dia setup inicial (mitigado: bien documentado)

---

### ADR-006: Cloudflare Tunnel vs Nginx + Certbot

**Contexto:**
Necesitamos exponer API al exterior. Servidor detras de NAT sin IP publica.

**Decision:** Cloudflare Tunnel (ya configurado)

**Razon:**
- ‚úÖ Ya operativo (sin cambios)
- ‚úÖ HTTPS automatico
- ‚úÖ Sin abrir puertos en router
- ‚úÖ DDoS protection gratis
- ‚úÖ Capa extra de seguridad (WAF)

**Consecuencias:**
- ‚úÖ Deployment simplificado
- ‚úÖ Monitoreo trafico en Cloudflare dashboard
- ‚ö†Ô∏è Dependencia externa (mitigado: Cloudflare SLA 99.99%)

---

### ADR-007: Deployment en servidor local vs Cloud

**Contexto:**
Donde desplegar el proyecto. Opciones: Servidor local, Oracle Cloud, Hetzner VPS.

**Decision:** Servidor local (HP EliteDesk)

**Razon:**
- ‚úÖ Hardware disponible (no requiere compra)
- ‚úÖ $0 coste operativo
- ‚úÖ 24/7 disponible
- ‚úÖ Suficiente para volumen esperado (5-20 videos/dia)
- ‚úÖ Path de escalado claro (RAM upgrade ‚Üí Oracle Cloud)

**Consecuencias:**
- ‚úÖ Proyecto arranca inmediatamente
- ‚úÖ Aprendizaje deployment real (Docker, systemd)
- ‚ö†Ô∏è Sin redundancia (mitigado: backups diarios)
- üìã Futuro: Arquitectura hibrida si volumen crece

---
# ADR-008: Conservar transcripciones indefinidamente en MVP

**Contexto:**
Las transcripciones son generadas por Whisper y consumidas por ApyHub para generar res√∫menes.
Necesitamos decidir si conservarlas o eliminarlas despu√©s del resumen.

**Decisi√≥n:** Conservar transcripciones indefinidamente

**Raz√≥n:**
- Costo de almacenamiento despreciable (~18MB/a√±o para 10 videos/d√≠a)
- √ötil para debugging si res√∫menes son de baja calidad
- Habilita features futuras (b√∫squeda full-text, an√°lisis temporal)
- Simplicidad: no requiere l√≥gica adicional de limpieza

**Trade-offs:**
- ‚úÖ Espacio: ~18MB/a√±o vs 0MB (diferencia insignificante)
- ‚úÖ Features: B√∫squeda en transcripciones vs solo res√∫menes
- ‚úÖ Implementaci√≥n: 0 l√≠neas c√≥digo vs tarea de limpieza

**Consecuencias:**
- ‚úÖ MVP m√°s simple
- ‚úÖ Flexibilidad para analytics avanzado
- ‚ö†Ô∏è Migrar a borrado autom√°tico si BD crece excesivamente (>50K videos)

**Path de migraci√≥n:**
Si en el futuro necesitamos optimizar espacio, implementar Estrategia 3
(borrado diferido con retenci√≥n de 30 d√≠as).

---

### ADR-009: Migraci√≥n de ApyHub a DeepSeek

**Contexto:**
ApyHub limita a 5 llamadas/d√≠a en plan gratuito. Volumen esperado: 10 videos/d√≠a (300/mes).

**Decisi√≥n:** DeepSeek API con modelo `deepseek-chat`

**Raz√≥n:**
- ApyHub insuficiente (5 llamadas vs 10 videos diarios)
- DeepSeek: $0.28/1M tokens input + $0.42/1M output
- Costo mensual: ~$0.16-0.45 (con context caching)
- Sin l√≠mites artificiales de uso
- Compatible OpenAI SDK (migraci√≥n simple)

**Trade-offs:**
- ‚úÖ Costo: $0.45/mes vs l√≠mite bloqueante
- ‚úÖ Escalabilidad: ilimitado vs 5/d√≠a
- ‚úÖ Simplicidad: API s√≠ncrona vs job polling
- ‚ö†Ô∏è Requiere sistema de prompts (LLM gen√©rico)

**Consecuencias:**
- ‚úÖ Proyecto viable para caso de uso real
- ‚úÖ C√≥digo m√°s simple (~150 l√≠neas vs ~480)
- ‚úÖ Context caching reduce costos 80% tras primer resumen
- üìã Implementar prompt engineering para calidad √≥ptima

**Alternativas descartadas:**
- ‚ùå Mantener ApyHub: Insuficiente para producci√≥n
- ‚ùå GPT-4o-mini: M√°s caro ($0.15/1M tokens)
- ‚ùå Claude API: M√°s caro ($0.015/1K tokens)

---

## METRICAS Y OBSERVABILIDAD

**Prometheus metrics:**
- `videos_processed_total`: Counter de videos procesados
- `transcription_duration_seconds`: Histogram de tiempo de transcripcion
- `apyhub_calls_remaining`: Gauge de llamadas disponibles
- `celery_task_duration_seconds`: Histogram por tipo de tarea
- `api_request_duration_seconds`: Histogram de latencia API

**Grafana dashboards:**
1. Overview: Videos/dia, tiempo procesamiento, tasa error
2. Resources: CPU, RAM, Disk I/O
3. API: Request rate, latency p50/p95/p99, errores
4. Celery: Tasks pending, processing, failed

**Alertas criticas:**
- RAM >85% por 5 min
- Disco <20GB libre
- ApyHub rate limit alcanzado
- Tasa error Celery >10%

---

## SEGURIDAD

**Proteccion de secretos:**
- `.env` en `.gitignore` (NUNCA commitear)
- Variables de entorno en produccion (systemd EnvironmentFile)
- Tokens en Cloudflare Secrets (futuro: Vault)

**API Security:**
- CORS configurado (whitelist dominios)
- Rate limiting (10 req/s por IP)
- JWT authentication (futuro)
- Input validation (Pydantic)

**Database:**
- Usuario no-root con permisos minimos
- Conexion via Unix socket (no TCP)
- Backups cifrados con GPG

---

## TESTING

**Cobertura objetivo:** 80%+

**Estrategia:**
1. **Unit tests:** Services, repositories (mocks)
2. **Integration tests:** API endpoints (TestClient + DB test)
3. **E2E tests:** Pipeline completo (fixture videos cortos)

**Fixtures:**
- Video corto (30s) para testing transcripcion
- Transcripcion pre-generada para testing resumenes
- Base de datos test (Docker container ephemeral)

---

## DOCUMENTACION

**Documentacion tecnica:**
- Este documento (architecture.md)
- API docs (auto-generada Swagger)
- ADRs para decisiones importantes
- Deployment guide (step-by-step)

**Documentacion usuario:**
- README con quickstart
- API usage examples
- Telegram bot commands (futuro)

---

## TIMELINE DE IMPLEMENTACION

Ver [docs/roadmap.md](roadmap.md) para roadmap detallado con pasos incrementales (4 semanas estimadas).

---

## REFERENCIAS

- FastAPI docs: https://fastapi.tiangolo.com
- Celery docs: https://docs.celeryq.dev
- Whisper repo: https://github.com/openai/whisper
- ApyHub API docs: https://apyhub.com/docs
- PostgreSQL docs: https://www.postgresql.org/docs

---

**Documento vivo:** Este documento se actualiza conforme evoluciona el proyecto.

**Proxima revision:** Despues de implementar Fase 1 (Infraestructura Base)
