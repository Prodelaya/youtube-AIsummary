# Estrategia de Cach√© con Redis - YouTube AI Summary

## üìã √çndice

1. [Visi√≥n General](#visi√≥n-general)
2. [Arquitectura de Cach√©](#arquitectura-de-cach√©)
3. [Decisiones de Dise√±o](#decisiones-de-dise√±o)
4. [Claves y Estructuras de Datos](#claves-y-estructuras-de-datos)
5. [Pol√≠ticas de TTL](#pol√≠ticas-de-ttl)
6. [Estrategias de Invalidaci√≥n](#estrategias-de-invalidaci√≥n)
7. [Fallback y Resiliencia](#fallback-y-resiliencia)
8. [M√©tricas y Monitoreo](#m√©tricas-y-monitoreo)

---

## üéØ Visi√≥n General

### Objetivos

- **Reducir latencia:** Mejorar tiempos de respuesta de API y Bot de Telegram en 3-5x
- **Reducir carga en PostgreSQL:** Disminuir queries repetitivas en res√∫menes frecuentes
- **Optimizar recursos:** Usar cach√© inteligente para servidor con recursos limitados (8GB RAM, i5-6500T)
- **Mantener datos frescos:** Balance entre performance y actualizaci√≥n de datos

### Alcance

**En Scope:**
- Res√∫menes individuales (lectura intensiva)
- Listas de res√∫menes recientes por usuario
- Resultados de b√∫squeda full-text
- Estad√≠sticas globales del sistema
- Estad√≠sticas por fuente

**Out of Scope:**
- Transcripciones completas (muy grandes, poco reutilizables)
- Datos de videos individuales (bajo hit rate esperado)
- Datos de usuarios de Telegram (bajo volumen, alta actualizaci√≥n)
- Suscripciones (datos cr√≠ticos, requieren consistencia inmediata)

---

## üèóÔ∏è Arquitectura de Cach√©

### Capa de Abstracci√≥n

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API REST / Bot Telegram / Workers    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CacheService (Abstracci√≥n)      ‚îÇ
‚îÇ  - get(key)         - get_or_set()      ‚îÇ
‚îÇ  - set(key, val)    - invalidate()      ‚îÇ
‚îÇ  - delete(key)      - get_many()        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Redis Cache ‚îÇ       ‚îÇ  PostgreSQL  ‚îÇ
‚îÇ  (Hot Data)  ‚îÇ       ‚îÇ  (Cold Data) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Lectura (Read-Through Cache)

```mermaid
graph TD
    A[Request] --> B{Cache Hit?}
    B -->|Yes| C[Return from Cache]
    B -->|No| D[Query Database]
    D --> E[Store in Cache]
    E --> F[Return Data]
    C --> G[Log Cache Hit Metric]
    F --> H[Log Cache Miss Metric]
```

### Flujo de Escritura (Cache-Aside + Invalidation)

```mermaid
graph TD
    A[Create/Update] --> B[Write to Database]
    B --> C[Invalidate Related Cache Keys]
    C --> D{Proactive Cache?}
    D -->|Yes| E[Warm Up Cache]
    D -->|No| F[Return Success]
    E --> F
```

---

## üß† Decisiones de Dise√±o

### 1. Patr√≥n: Cache-Aside + Read-Through

**Decisi√≥n:** Usar patr√≥n h√≠brido Cache-Aside para escrituras y Read-Through para lecturas.

**Justificaci√≥n:**
- **Cache-Aside:** Control expl√≠cito sobre qu√© cachear en escrituras
- **Read-Through:** Transparencia en lecturas, simplifica c√≥digo del repository
- **Invalidaci√≥n proactiva:** Garantiza consistencia en operaciones cr√≠ticas

**Alternativas Rechazadas:**
- ‚ùå **Write-Through:** Overhead innecesario, mayor√≠a de datos se leen m√∫ltiples veces antes de actualizarse
- ‚ùå **Write-Behind:** Riesgo de p√©rdida de datos en servidor con recursos limitados

### 2. Serializaci√≥n: JSON

**Decisi√≥n:** Usar JSON para serializaci√≥n de objetos Python.

**Justificaci√≥n:**
- ‚úÖ Compatible con m√∫ltiples lenguajes (futuro frontend)
- ‚úÖ Human-readable para debugging
- ‚úÖ Soportado nativamente por Redis (JSON strings)
- ‚ö†Ô∏è Overhead aceptable para tama√±o de datos (<10KB por resumen)

**Alternativas Rechazadas:**
- ‚ùå **Pickle:** No portable, riesgo de seguridad, no human-readable
- ‚ùå **MessagePack:** Mejor performance pero no human-readable

### 3. Base de Datos Redis: Separada (DB 1)

**Decisi√≥n:** Usar Redis DB 1 para cach√© (DB 0 para Celery broker).

**Justificaci√≥n:**
- ‚úÖ Aislamiento l√≥gico: cach√© vs. mensajer√≠a
- ‚úÖ Facilita flushing de cach√© sin afectar Celery
- ‚úÖ M√©tricas separadas por namespace
- ‚ö†Ô∏è Misma instancia Redis (l√≠mite de memoria compartido)

**Configuraci√≥n:**
```bash
REDIS_URL=redis://localhost:6379/0          # Celery Broker
REDIS_CACHE_URL=redis://localhost:6379/1    # Cache Layer
```

### 4. TTL: Conservador (5-24h)

**Decisi√≥n:** TTLs cortos a medios para balance freshness/performance.

**Justificaci√≥n:**
- Contenido mayormente est√°tico (res√∫menes no cambian)
- Listas din√°micas requieren TTL corto (nuevo contenido frecuente)
- Recursos limitados ‚Üí evitar memory pressure con TTL largo

### 5. Fallback: Graceful Degradation

**Decisi√≥n:** Sistema funciona sin cach√© si Redis no disponible.

**Justificaci√≥n:**
- ‚úÖ Resiliencia ante fallos de Redis
- ‚úÖ Permite mantenimiento sin downtime
- ‚ö†Ô∏è Performance degradado pero funcionalidad intacta

**Implementaci√≥n:**
```python
try:
    cached = cache_service.get(key)
    if cached:
        return cached
except RedisConnectionError:
    logger.warning("Redis unavailable, falling back to database")

# Fallback to DB
return database_query()
```

---

## üîë Claves y Estructuras de Datos

### Nomenclatura de Claves

**Formato:** `{namespace}:{entity}:{identifier}:{suffix}`

**Ejemplos:**
```
summary:detail:550e8400-e29b-41d4-a716-446655440000
user:12345:recent
search:a1b2c3d4:results
stats:global
stats:source:550e8400-e29b-41d4-a716-446655440000
```

### Tipos de Claves

#### 1. Res√∫menes Individuales

**Key:** `summary:detail:{summary_id}`

**Tipo Redis:** String (JSON serializado)

**Estructura:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "transcription_id": "660e8400-e29b-41d4-a716-446655440001",
  "summary_text": "FastAPI es un framework moderno...",
  "category": "framework",
  "keywords": ["fastapi", "python", "async"],
  "model_used": "deepseek-chat",
  "sent_to_telegram": true,
  "created_at": "2025-01-15T10:30:00Z",
  "sent_at": "2025-01-15T10:35:00Z"
}
```

**TTL:** 24 horas (86400s)

**Justificaci√≥n:** Contenido est√°tico, alta probabilidad de reutilizaci√≥n

---

#### 2. Listas de Res√∫menes Recientes por Usuario

**Key:** `user:{telegram_id}:recent`

**Tipo Redis:** String (JSON array de summary_ids)

**Estructura:**
```json
{
  "summary_ids": [
    "550e8400-e29b-41d4-a716-446655440000",
    "660e8400-e29b-41d4-a716-446655440001",
    "770e8400-e29b-41d4-a716-446655440002"
  ],
  "generated_at": "2025-01-15T10:30:00Z",
  "total_count": 10
}
```

**TTL:** 5 minutos (300s)

**Justificaci√≥n:** Datos din√°micos (nuevos res√∫menes frecuentes), comando frecuente en bot

**Optimizaci√≥n:** Solo IDs en cach√©, res√∫menes completos se cachean individualmente

---

#### 3. Resultados de B√∫squeda Full-Text

**Key:** `search:{query_hash}:results`

**Tipo Redis:** String (JSON array de summary_ids + metadata)

**Estructura:**
```json
{
  "query": "FastAPI async",
  "query_hash": "a1b2c3d4e5f6",
  "summary_ids": [
    "550e8400-e29b-41d4-a716-446655440000",
    "660e8400-e29b-41d4-a716-446655440001"
  ],
  "total_results": 25,
  "cached_at": "2025-01-15T10:30:00Z"
}
```

**Query Hash:** MD5 de query normalizada (lowercase, whitespace trimmed)

**TTL:** 10 minutos (600s)

**Justificaci√≥n:** Resultados semi-est√°ticos, b√∫squedas repetidas comunes

**L√≠mite:** Solo primeros 50 resultados cacheados (resto desde DB)

---

#### 4. Estad√≠sticas Globales del Sistema

**Key:** `stats:global`

**Tipo Redis:** Hash

**Estructura:**
```redis
HSET stats:global total_videos 1250
HSET stats:global total_transcriptions 980
HSET stats:global total_summaries 950
HSET stats:global total_sources 15
HSET stats:global total_telegram_users 42
HSET stats:global last_updated "2025-01-15T10:30:00Z"
```

**TTL:** 15 minutos (900s)

**Justificaci√≥n:** Estad√≠sticas cambian gradualmente, queries costosas (COUNT(*))

---

#### 5. Estad√≠sticas por Fuente

**Key:** `stats:source:{source_id}`

**Tipo Redis:** Hash

**Estructura:**
```redis
HSET stats:source:550e8400 total_videos 85
HSET stats:source:550e8400 total_transcriptions 82
HSET stats:source:550e8400 total_summaries 80
HSET stats:source:550e8400 avg_duration_seconds 1245
HSET stats:source:550e8400 last_updated "2025-01-15T10:30:00Z"
```

**TTL:** 15 minutos (900s)

**Justificaci√≥n:** Estad√≠sticas espec√≠ficas de fuente para dashboard

---

## ‚è∞ Pol√≠ticas de TTL

### Matriz de Decisi√≥n TTL

| Tipo de Dato | TTL | Justificaci√≥n | Tasa de Cambio | Hit Rate Esperado |
|--------------|-----|---------------|----------------|-------------------|
| **Res√∫menes individuales** | 24h | Contenido est√°tico, no cambia | Muy baja | >80% |
| **Listas de recientes (usuario)** | 5 min | Nuevos res√∫menes frecuentes | Alta | ~60% |
| **Resultados de b√∫squeda** | 10 min | Semi-est√°ticos, queries repetidas | Media | ~70% |
| **Estad√≠sticas globales** | 15 min | Cambios graduales, queries costosas | Media-baja | >85% |
| **Estad√≠sticas por fuente** | 15 min | Cambios graduales por fuente | Media-baja | >75% |

### Trade-offs por Tipo

#### Res√∫menes Individuales (24h)

**Pros:**
- ‚úÖ M√°ximo hit rate
- ‚úÖ M√≠nima carga en DB
- ‚úÖ Contenido no cambia (append-only)

**Contras:**
- ‚ö†Ô∏è Si se corrige un resumen, tardar√° 24h en reflejarse
- **Mitigaci√≥n:** Invalidaci√≥n manual v√≠a endpoint admin

---

#### Listas de Recientes (5 min)

**Pros:**
- ‚úÖ Balance entre freshness y performance
- ‚úÖ Nuevos res√∫menes visibles en <5 min

**Contras:**
- ‚ö†Ô∏è Hit rate moderado (~60%)
- ‚ö†Ô∏è M√°s cache churn (invalidaciones frecuentes)

**Alternativas Consideradas:**
- 1 minuto: Demasiado cache churn, hit rate <30%
- 15 minutos: Usuarios esperan contenido m√°s fresco

---

#### B√∫squedas (10 min)

**Pros:**
- ‚úÖ Queries frecuentes cacheadas (ej: "FastAPI", "Python")
- ‚úÖ Reduce carga en full-text search de PostgreSQL

**Contras:**
- ‚ö†Ô∏è Nuevos res√∫menes no aparecen hasta 10 min despu√©s
- **Mitigaci√≥n:** Invalidar cach√© de b√∫squedas populares al crear resumen

---

## üîÑ Estrategias de Invalidaci√≥n

### Eventos que Gatillan Invalidaci√≥n

| Evento | Claves a Invalidar | Estrategia | Prioridad |
|--------|-------------------|------------|-----------|
| **Crear resumen** | `user:*:recent`, `search:*:results`, `stats:*` | Invalidar listas | Alta |
| **Actualizar resumen** | `summary:detail:{id}`, `search:*:results` | Invalidar espec√≠fico + b√∫squedas | Media |
| **Borrar resumen (soft delete)** | `summary:detail:{id}`, `user:*:recent`, `search:*:results` | Invalidar todo relacionado | Alta |
| **Cambiar estado de video** | `stats:global`, `stats:source:{id}` | Invalidar estad√≠sticas | Baja |
| **Usuario se suscribe/desuscribe** | `user:{telegram_id}:recent` | Invalidar lista de ese usuario | Media |

### Implementaci√≥n de Invalidaci√≥n

#### 1. Invalidaci√≥n Espec√≠fica (Resumen Individual)

```python
def invalidate_summary(summary_id: UUID) -> None:
    """Invalida cach√© de un resumen espec√≠fico."""
    cache_service.delete(f"summary:detail:{summary_id}")
    logger.info(f"Cache invalidated for summary {summary_id}")
```

**Cu√°ndo:** Al actualizar o borrar un resumen

---

#### 2. Invalidaci√≥n por Patr√≥n (Listas de Usuario)

```python
def invalidate_user_recents(telegram_id: int | None = None) -> None:
    """Invalida listas de recientes (todos los usuarios o uno espec√≠fico)."""
    if telegram_id:
        cache_service.delete(f"user:{telegram_id}:recent")
    else:
        # Invalidar todas las listas de usuarios
        cache_service.invalidate_pattern("user:*:recent")

    logger.info(f"Cache invalidated for user recents: {telegram_id or 'all'}")
```

**Cu√°ndo:** Al crear nuevo resumen (todos) o al cambiar suscripciones (espec√≠fico)

**‚ö†Ô∏è Advertencia:** `invalidate_pattern()` usa `KEYS` de Redis, bloqueante en producci√≥n.

**Alternativa para producci√≥n:** Mantener Set de telegram_ids activos y iterar.

---

#### 3. Invalidaci√≥n de B√∫squedas (Selectiva)

```python
def invalidate_search_cache(keywords: list[str] | None = None) -> None:
    """Invalida cach√© de b√∫squedas (todas o queries relacionadas con keywords)."""
    if keywords:
        # Invalidar solo b√∫squedas que contienen estos keywords
        for keyword in keywords:
            hash_key = _hash_query(keyword)
            cache_service.delete(f"search:{hash_key}:results")
    else:
        # Invalidar todas las b√∫squedas
        cache_service.invalidate_pattern("search:*:results")

    logger.info(f"Cache invalidated for searches: {keywords or 'all'}")
```

**Cu√°ndo:** Al crear resumen con keywords populares (proactivo) o manualmente (admin)

**Optimizaci√≥n:** Lista de "keywords populares" en config para invalidaci√≥n selectiva

---

#### 4. Invalidaci√≥n de Estad√≠sticas (Lazy)

```python
def invalidate_stats(source_id: UUID | None = None) -> None:
    """Invalida estad√≠sticas globales y/o de fuente espec√≠fica."""
    cache_service.delete("stats:global")

    if source_id:
        cache_service.delete(f"stats:source:{source_id}")
    else:
        cache_service.invalidate_pattern("stats:source:*")

    logger.info(f"Cache invalidated for stats: {source_id or 'all'}")
```

**Cu√°ndo:** Al cambiar estado de video/transcripci√≥n/resumen

**Estrategia:** No invalidar inmediatamente, dejar expirar (TTL 15 min)

**Excepci√≥n:** Endpoint admin puede forzar invalidaci√≥n

---

### Hooks de Invalidaci√≥n en Repository

**Ejemplo en `SummaryRepository`:**

```python
def create(self, summary: Summary) -> Summary:
    """Crea resumen e invalida cach√© relacionado."""
    # Crear en DB
    created_summary = super().create(summary)

    # Invalidar cach√©
    cache_service.invalidate_pattern("user:*:recent")  # Listas de usuarios
    cache_service.invalidate_pattern("search:*:results")  # B√∫squedas
    cache_service.delete("stats:global")  # Estad√≠sticas

    # Log de invalidaci√≥n
    logger.info(
        f"Cache invalidated after creating summary {created_summary.id}",
        extra={"summary_id": str(created_summary.id)}
    )

    return created_summary
```

---

## üõ°Ô∏è Fallback y Resiliencia

### Estrategia de Degradaci√≥n Graceful

**Principio:** Sistema funciona sin cach√©, con performance degradado.

#### Niveles de Resiliencia

```python
# Nivel 1: Redis disponible ‚Üí Usar cach√© normal
try:
    cached = cache_service.get(key)
    if cached:
        return cached
except RedisConnectionError:
    logger.warning("Redis unavailable, falling back to DB")

# Nivel 2: Redis lento ‚Üí Timeout corto (100ms)
except RedisTimeoutError:
    logger.warning("Redis timeout, falling back to DB")

# Nivel 3: Cualquier error Redis ‚Üí Continuar sin cach√©
except Exception as e:
    logger.error(f"Unexpected cache error: {e}", exc_info=True)

# Fallback: Query directa a BD
return database_query()
```

---

### Health Check de Redis

**Endpoint:** `GET /health/redis`

**Implementaci√≥n:**
```python
def check_redis_health() -> dict:
    """Verifica estado de Redis."""
    try:
        start = time.time()
        redis_client.ping()
        latency_ms = (time.time() - start) * 1000

        return {
            "status": "healthy",
            "latency_ms": round(latency_ms, 2),
            "memory_used_mb": redis_client.info("memory")["used_memory"] / 1024 / 1024
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }
```

**Alertas:**
- ‚ö†Ô∏è Latency >50ms ‚Üí Warning
- ‚ùå Latency >200ms ‚Üí Critical
- ‚ùå Redis down ‚Üí Critical

---

### Circuit Breaker (Opcional - Fase 2)

**Concepto:** Desactivar cach√© autom√°ticamente si Redis falla repetidamente.

**Implementaci√≥n Futura:**
```python
class CacheCircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open

    def is_open(self) -> bool:
        if self.state == "open":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "half-open"
                return False
            return True
        return False

    def record_success(self):
        self.failure_count = 0
        self.state = "closed"

    def record_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = "open"
            logger.warning("Circuit breaker OPEN: Redis disabled temporarily")
```

---

## üìä M√©tricas y Monitoreo

### M√©tricas de Prometheus

#### Contadores

```python
from prometheus_client import Counter

cache_hits = Counter(
    'cache_hits_total',
    'Total cache hits',
    ['cache_type']  # summary, user_recent, search, stats
)

cache_misses = Counter(
    'cache_misses_total',
    'Total cache misses',
    ['cache_type']
)

cache_errors = Counter(
    'cache_errors_total',
    'Total cache operation errors',
    ['error_type']  # connection, timeout, serialization
)
```

#### Histogramas

```python
from prometheus_client import Histogram

cache_operation_duration = Histogram(
    'cache_operation_seconds',
    'Duration of cache operations',
    ['operation']  # get, set, delete, invalidate
)

cache_value_size = Histogram(
    'cache_value_size_bytes',
    'Size of cached values',
    ['cache_type'],
    buckets=[100, 500, 1000, 5000, 10000, 50000]
)
```

#### Gauges

```python
from prometheus_client import Gauge

cache_keys_count = Gauge(
    'cache_keys_total',
    'Total number of keys in cache',
    ['cache_type']
)

redis_memory_used = Gauge(
    'redis_memory_used_bytes',
    'Redis memory usage in bytes'
)
```

---

### C√°lculo de Cache Hit Rate

**F√≥rmula:**
```python
cache_hit_rate = cache_hits / (cache_hits + cache_misses)
```

**Objetivo:** >70% hit rate global

**Hit Rates Esperados por Tipo:**
- Res√∫menes individuales: >80%
- Listas de recientes: ~60%
- B√∫squedas: ~70%
- Estad√≠sticas: >85%

---

### Dashboard de Monitoreo (Grafana - Paso 23)

**Paneles a crear:**

1. **Cache Hit Rate (Global y por Tipo)**
   - Gr√°fica de l√≠nea temporal
   - Objetivo: >70% l√≠nea horizontal

2. **Cache Operations Duration**
   - Histograma de latencias
   - Objetivo: p95 <10ms

3. **Redis Memory Usage**
   - Gauge con l√≠mite 256MB
   - Alerta si >200MB (80%)

4. **Cache Errors**
   - Counter de errores por tipo
   - Alerta si >10 errores/min

5. **Cache Keys Count**
   - Distribuci√≥n por tipo
   - Detectar memory leaks

---

### Logs Estructurados

**Ejemplo de log de cache hit:**
```json
{
  "timestamp": "2025-01-15T10:30:00Z",
  "level": "INFO",
  "message": "Cache hit",
  "cache_type": "summary",
  "key": "summary:detail:550e8400-e29b-41d4-a716-446655440000",
  "duration_ms": 2.5
}
```

**Ejemplo de log de cache miss:**
```json
{
  "timestamp": "2025-01-15T10:30:05Z",
  "level": "INFO",
  "message": "Cache miss, querying database",
  "cache_type": "summary",
  "key": "summary:detail:660e8400-e29b-41d4-a716-446655440001",
  "duration_ms": 45.2
}
```

---

## üß™ Testing de Cach√©

### Categor√≠as de Tests

#### 1. Tests Unitarios (`tests/services/test_cache_service.py`)

**Cobertura:**
- Serializaci√≥n/deserializaci√≥n JSON
- TTL correcto en `set()`
- `get()` retorna None si key no existe
- `delete()` elimina key correctamente
- `get_or_set()` ejecuta fetcher solo en miss
- Manejo de errores Redis

**Mocks:**
- Redis client mockeado (no Redis real)

---

#### 2. Tests de Integraci√≥n (`tests/repositories/test_summary_cache.py`)

**Cobertura:**
- `get_by_id()` usa cach√© en segunda llamada
- `create()` invalida cach√© de listas
- `soft_delete()` invalida cach√© de resumen
- Fallback a DB si Redis no disponible
- Invalidaci√≥n por patr√≥n funciona

**Requerimientos:**
- Redis real en DB 15 (test DB)
- Flush DB antes de cada test

---

#### 3. Tests E2E (`tests/api/test_cache_headers.py`)

**Cobertura:**
- Endpoint `/summaries/{id}` retorna header `X-Cache-Status: HIT`
- Header `X-Cache-Bypass: true` fuerza lectura de DB
- Endpoint `/summaries/recent` cachea respuesta completa
- Bot `/recent` usa cach√© en segunda llamada

**Requerimientos:**
- API corriendo
- Redis corriendo
- DB con datos de prueba

---

#### 4. Tests de Performance (`tests/performance/test_query_optimization.py`)

**Cobertura:**
- Benchmark de endpoint sin cach√© (baseline)
- Benchmark de endpoint con cach√© (mejora esperada 3-5x)
- Benchmark de queries N+1 antes/despu√©s eager loading
- M√©tricas de cache hit rate bajo carga

**Herramientas:**
- `pytest-benchmark` para mediciones
- `locust` para carga concurrente (opcional)

---

## üìà Roadmap de Optimizaci√≥n

### Fase 1: Implementaci√≥n Base (Paso 19 - Actual)

- ‚úÖ CacheService con m√©todos b√°sicos
- ‚úÖ Cache en SummaryRepository
- ‚úÖ Cache en endpoints API
- ‚úÖ Cache en Bot de Telegram
- ‚úÖ M√©tricas de Prometheus
- ‚úÖ Tests >85% coverage

### Fase 2: Optimizaciones Avanzadas (Post-Paso 19)

- Cache de relaciones (eager loading + cache)
- Cache de agregaciones (top keywords, trending topics)
- Cache warming proactivo (precarga de datos populares)
- Circuit breaker para Redis
- Compresi√≥n de valores grandes (gzip)

### Fase 3: Escalabilidad (Futuro)

- Redis Cluster (sharding)
- Cache distribuido (m√∫ltiples instancias)
- Cache L2 (in-memory local + Redis remoto)
- Cache de CDN para API p√∫blica

---

## üîß Comandos de Debugging

### Inspeccionar Keys en Redis

```bash
# Conectar a Redis cache DB
redis-cli -n 1

# Listar todas las keys
KEYS *

# Listar keys de res√∫menes
KEYS summary:detail:*

# Listar keys de usuarios
KEYS user:*:recent

# Ver contenido de key
GET summary:detail:550e8400-e29b-41d4-a716-446655440000

# Ver TTL de key
TTL summary:detail:550e8400-e29b-41d4-a716-446655440000

# Ver info de memoria
INFO memory

# Contar keys por patr√≥n
KEYS summary:* | wc -l
```

### Invalidar Cach√© Manualmente

```bash
# Invalidar resumen espec√≠fico
redis-cli -n 1 DEL summary:detail:550e8400-e29b-41d4-a716-446655440000

# Invalidar todas las listas de recientes
redis-cli -n 1 --scan --pattern "user:*:recent" | xargs redis-cli -n 1 DEL

# Invalidar todas las b√∫squedas
redis-cli -n 1 --scan --pattern "search:*:results" | xargs redis-cli -n 1 DEL

# Flush completo del cache DB (¬°CUIDADO!)
redis-cli -n 1 FLUSHDB
```

### Monitorear Operaciones en Tiempo Real

```bash
# Ver comandos en tiempo real
redis-cli -n 1 MONITOR

# Ver estad√≠sticas de comandos
redis-cli -n 1 INFO stats

# Ver slowlog (comandos lentos)
redis-cli -n 1 SLOWLOG GET 10
```

---

## üìö Referencias

- [Redis Best Practices](https://redis.io/docs/management/optimization/)
- [Cache Patterns](https://docs.aws.amazon.com/whitepapers/latest/database-caching-strategies-using-redis/caching-patterns.html)
- [PostgreSQL + Redis Architecture](https://www.postgresql.org/docs/current/redis-fdw.html)
- Documentaci√≥n interna:
  - `docs/architecture.md` - Arquitectura general
  - `docs/clean-code.md` - Est√°ndares de c√≥digo
  - `CLAUDE.md` - Manifesto del proyecto

---

## ‚úÖ Criterios de Aceptaci√≥n - Paso 19

- [x] Documento de estrategia completo
- [ ] CacheService implementado con >85% coverage
- [ ] Cache integrado en SummaryRepository
- [ ] Cache en endpoints API con headers
- [ ] Cache en Bot de Telegram (/recent, /search)
- [ ] Queries N+1 optimizados con eager loading
- [ ] M√©tricas de Prometheus exportadas
- [ ] Benchmarks documentan mejora 3-5x
- [ ] Tests de resiliencia validan fallback
- [ ] Cache hit rate >70% validado

---

**√öltima actualizaci√≥n:** 2025-01-15
**Autor:** Pablo (prodelaya)
**Estado:** En desarrollo - Paso 19
