"""
Tests de integraciÃ³n para SummarizationService.

Estos tests realizan llamadas REALES a la API de ApyHub.
IMPORTANTE: Cada test consume 1 de tus 10 llamadas diarias.

Ejecutar con:
    pytest tests/integration/test_summarization_service.py -v

Skip si no hay token:
    pytest tests/integration/test_summarization_service.py -v -m "not integration"
"""

import asyncio

import pytest

from src.core.config import settings
from src.services.summarization_service import (
    ApyHubAPIError,
    InvalidResponseError,
    SummarizationService,
    SummarizationTimeoutError,
)

# Texto de prueba: corto pero con contenido suficiente para resumir
SAMPLE_TEXT = """
La inteligencia artificial estÃ¡ transformando el desarrollo de software de manera
profunda. Los modelos de lenguaje como GPT-4 y Claude permiten a los desarrolladores
escribir cÃ³digo mÃ¡s rÃ¡pido mediante autocompletado inteligente y generaciÃ³n de cÃ³digo.
Las herramientas de IA tambiÃ©n ayudan en la detecciÃ³n de bugs, revisiÃ³n de cÃ³digo
y optimizaciÃ³n de rendimiento. Sin embargo, es importante que los desarrolladores
mantengan un pensamiento crÃ­tico y no dependan completamente de estas herramientas.
La IA es un asistente poderoso, pero el conocimiento fundamental de programaciÃ³n
sigue siendo esencial para crear software robusto y mantenible.
"""


# ==================== FIXTURES ====================


@pytest.fixture
def skip_if_no_token():
    """
    Skip test si no hay token de ApyHub configurado.

    Ãštil para CI/CD donde no queremos consumir cuota en cada build.
    """
    if not settings.APYHUB_TOKEN or settings.APYHUB_TOKEN == "tu_token_de_apyhub_aqui":
        pytest.skip("ApyHub token no configurado, skip test de integraciÃ³n")


# ==================== TESTS ====================


@pytest.mark.asyncio
@pytest.mark.integration  # Marca para poder excluir con -m "not integration"
async def test_submit_summarization_job_success(skip_if_no_token):
    """
    Test: Enviar job de resumen devuelve job_id y status_url.

    Verifica que la API de ApyHub responde correctamente al enviar
    un texto para resumir.
    """
    async with SummarizationService() as service:
        # Enviar job
        job = await service.submit_summarization_job(
            content=SAMPLE_TEXT,
            voice_tone="neutral",
            max_length=100,
            language="Spanish",
        )

        # Verificar estructura de respuesta
        assert job.job_id is not None
        assert len(job.job_id) > 0
        assert job.status_url is not None
        assert "apyhub.com" in job.status_url

        print(f"\nâœ… Job enviado exitosamente:")
        print(f"   Job ID: {job.job_id}")
        print(f"   Status URL: {job.status_url}")


@pytest.mark.asyncio
@pytest.mark.integration
async def test_get_summary_result_success(skip_if_no_token):
    """
    Test: Proceso completo de generaciÃ³n de resumen.

    Este es el test mÃ¡s importante: verifica que todo el flujo
    funciona correctamente (submit + polling + resultado).

    NOTA: Puede tardar 10-30 segundos en completar.
    """
    async with SummarizationService() as service:
        # Generar resumen completo
        result = await service.get_summary_result(
            content=SAMPLE_TEXT,
            voice_tone="professional",
            max_length=80,
            language="Spanish",
            timeout=60,  # 1 minuto deberÃ­a ser suficiente
        )

        # Verificar resultado
        assert result.summary is not None
        assert len(result.summary) > 0
        assert result.summary_length > 0
        assert result.summary_length < len(SAMPLE_TEXT)  # Resumen mÃ¡s corto que original
        assert result.original_length == len(SAMPLE_TEXT)

        # Verificar que el resumen tiene sentido (contiene palabras clave)
        summary_lower = result.summary.lower()
        assert any(
            keyword in summary_lower
            for keyword in ["inteligencia", "artificial", "ia", "desarrollo", "software"]
        )

        print(f"\nâœ… Resumen generado exitosamente:")
        print(f"   Longitud original: {result.original_length} chars")
        print(f"   Longitud resumen: {result.summary_length} chars")
        print(f"   ReducciÃ³n: {100 - (result.summary_length * 100 / result.original_length):.1f}%")
        print(f"   Idioma: {result.language}")
        print(f"\nğŸ“„ Resumen:")
        print(f"   {result.summary}")


@pytest.mark.asyncio
@pytest.mark.integration
async def test_check_job_status_pending(skip_if_no_token):
    """
    Test: Consultar estado de un job reciÃ©n creado.

    Verifica que podemos consultar el estado de un job.
    El job deberÃ­a estar en estado 'pending' o 'processing'.
    """
    async with SummarizationService() as service:
        # Enviar job
        job = await service.submit_summarization_job(
            content=SAMPLE_TEXT[:200],  # Texto mÃ¡s corto
            max_length=50,
        )

        # Consultar estado inmediatamente (deberÃ­a estar pending/processing)
        status = await service.check_job_status(job.status_url)

        assert "status" in status
        assert status["status"] in ["pending", "processing", "completed"]

        print(f"\nâœ… Estado del job consultado:")
        print(f"   Job ID: {job.job_id}")
        print(f"   Estado: {status['status']}")


@pytest.mark.asyncio
async def test_submit_without_token_fails():
    """
    Test: Fallo al enviar sin token vÃ¡lido.

    Verifica que el servicio falla correctamente cuando
    el token no es vÃ¡lido.
    """
    # Usar token invÃ¡lido
    service = SummarizationService(api_token="token_invalido_123")

    async with service:
        with pytest.raises(ApyHubAPIError) as exc_info:
            await service.submit_summarization_job(
                content="Texto de prueba",
                max_length=50,
            )

        # Verificar que el error contiene informaciÃ³n Ãºtil
        assert exc_info.value.status_code in [401, 403]  # Unauthorized o Forbidden

        print(f"\nâœ… Error detectado correctamente:")
        print(f"   Status code: {exc_info.value.status_code}")
        print(f"   Mensaje: {str(exc_info.value)}")


@pytest.mark.asyncio
async def test_empty_content_fails():
    """
    Test: Fallo al enviar contenido vacÃ­o.

    Verifica que el servicio maneja correctamente errores
    de validaciÃ³n de entrada.
    """
    async with SummarizationService() as service:
        with pytest.raises((ApyHubAPIError, InvalidResponseError)):
            await service.submit_summarization_job(
                content="",  # Contenido vacÃ­o
                max_length=50,
            )

        print("\nâœ… Error de contenido vacÃ­o detectado correctamente")


# ==================== HELPER PARA PRUEBAS MANUALES ====================


async def manual_test():
    """
    FunciÃ³n helper para probar el servicio manualmente.

    Ejecutar con:
        python -c "import asyncio; from tests.integration.test_summarization_service import manual_test; asyncio.run(manual_test())"
    """
    print("ğŸ§ª Iniciando test manual del servicio de resÃºmenes...\n")

    async with SummarizationService() as service:
        print(f"ğŸ“ Texto original ({len(SAMPLE_TEXT)} caracteres):")
        print(f"{SAMPLE_TEXT}\n")

        print("â³ Generando resumen (esto puede tardar 10-30 segundos)...\n")

        result = await service.get_summary_result(
            content=SAMPLE_TEXT,
            voice_tone="professional",
            max_length=100,
            language="Spanish",
        )

        print("âœ… Resumen generado exitosamente!\n")
        print(f"ğŸ“Š EstadÃ­sticas:")
        print(f"   - Original: {result.original_length} caracteres")
        print(f"   - Resumen: {result.summary_length} caracteres")
        print(
            f"   - ReducciÃ³n: {100 - (result.summary_length * 100 / result.original_length):.1f}%"
        )
        print(f"   - Idioma: {result.language}\n")

        print(f"ğŸ“„ Resumen:")
        print(f"{result.summary}\n")


if __name__ == "__main__":
    # Permitir ejecutar directamente el test manual
    asyncio.run(manual_test())
